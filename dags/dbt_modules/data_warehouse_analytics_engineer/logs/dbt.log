

============================== 2023-02-02 13:54:17.731330 | f1b10c56-114b-4fb3-9bd4-7f56353b331e ==============================
13:54:17.731330 [info ] [MainThread]: Running with dbt=1.1.0
13:54:17.731330 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
13:54:17.731330 [debug] [MainThread]: Tracking: tracking
13:54:17.762694 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022E0B70DF90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022E0B70D4E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022E0B70C850>]}
13:54:17.778326 [info ] [MainThread]: Partial parse save file not found. Starting full parse.
13:54:17.778326 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f1b10c56-114b-4fb3-9bd4-7f56353b331e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022E0B70FEB0>]}
13:54:18.014709 [debug] [MainThread]: Parsing macros\adapters.sql
13:54:18.031047 [debug] [MainThread]: Parsing macros\catalog.sql
13:54:18.046725 [debug] [MainThread]: Parsing macros\etc.sql
13:54:18.047297 [debug] [MainThread]: Parsing macros\materializations\copy.sql
13:54:18.047297 [debug] [MainThread]: Parsing macros\materializations\incremental.sql
13:54:18.047297 [debug] [MainThread]: Parsing macros\materializations\seed.sql
13:54:18.061809 [debug] [MainThread]: Parsing macros\materializations\snapshot.sql
13:54:18.061809 [debug] [MainThread]: Parsing macros\materializations\table.sql
13:54:18.061809 [debug] [MainThread]: Parsing macros\materializations\view.sql
13:54:18.061809 [debug] [MainThread]: Parsing macros\adapters\columns.sql
13:54:18.061809 [debug] [MainThread]: Parsing macros\adapters\freshness.sql
13:54:18.061809 [debug] [MainThread]: Parsing macros\adapters\indexes.sql
13:54:18.077446 [debug] [MainThread]: Parsing macros\adapters\metadata.sql
13:54:18.077446 [debug] [MainThread]: Parsing macros\adapters\persist_docs.sql
13:54:18.077446 [debug] [MainThread]: Parsing macros\adapters\relation.sql
13:54:18.077446 [debug] [MainThread]: Parsing macros\adapters\schema.sql
13:54:18.077446 [debug] [MainThread]: Parsing macros\etc\datetime.sql
13:54:18.093956 [debug] [MainThread]: Parsing macros\etc\statement.sql
13:54:18.093956 [debug] [MainThread]: Parsing macros\generic_test_sql\accepted_values.sql
13:54:18.093956 [debug] [MainThread]: Parsing macros\generic_test_sql\not_null.sql
13:54:18.093956 [debug] [MainThread]: Parsing macros\generic_test_sql\relationships.sql
13:54:18.093956 [debug] [MainThread]: Parsing macros\generic_test_sql\unique.sql
13:54:18.093956 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_alias.sql
13:54:18.093956 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_database.sql
13:54:18.093956 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_schema.sql
13:54:18.109047 [debug] [MainThread]: Parsing macros\materializations\configs.sql
13:54:18.112053 [debug] [MainThread]: Parsing macros\materializations\hooks.sql
13:54:18.112053 [debug] [MainThread]: Parsing macros\materializations\models\incremental\column_helpers.sql
13:54:18.112053 [debug] [MainThread]: Parsing macros\materializations\models\incremental\incremental.sql
13:54:18.112053 [debug] [MainThread]: Parsing macros\materializations\models\incremental\is_incremental.sql
13:54:18.125158 [debug] [MainThread]: Parsing macros\materializations\models\incremental\merge.sql
13:54:18.125158 [debug] [MainThread]: Parsing macros\materializations\models\incremental\on_schema_change.sql
13:54:18.140885 [debug] [MainThread]: Parsing macros\materializations\models\table\create_table_as.sql
13:54:18.140885 [debug] [MainThread]: Parsing macros\materializations\models\table\table.sql
13:54:18.140885 [debug] [MainThread]: Parsing macros\materializations\models\view\create_or_replace_view.sql
13:54:18.140885 [debug] [MainThread]: Parsing macros\materializations\models\view\create_view_as.sql
13:54:18.140885 [debug] [MainThread]: Parsing macros\materializations\models\view\helpers.sql
13:54:18.140885 [debug] [MainThread]: Parsing macros\materializations\models\view\view.sql
13:54:18.156510 [debug] [MainThread]: Parsing macros\materializations\seeds\helpers.sql
13:54:18.172146 [debug] [MainThread]: Parsing macros\materializations\seeds\seed.sql
13:54:18.172146 [debug] [MainThread]: Parsing macros\materializations\snapshots\helpers.sql
13:54:18.172146 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot.sql
13:54:18.187782 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot_merge.sql
13:54:18.187782 [debug] [MainThread]: Parsing macros\materializations\snapshots\strategies.sql
13:54:18.203295 [debug] [MainThread]: Parsing macros\materializations\tests\helpers.sql
13:54:18.203295 [debug] [MainThread]: Parsing macros\materializations\tests\test.sql
13:54:18.203295 [debug] [MainThread]: Parsing macros\materializations\tests\where_subquery.sql
13:54:18.203295 [debug] [MainThread]: Parsing tests\generic\builtin.sql
13:54:18.349850 [debug] [MainThread]: 1699: static parser successfully parsed example\my_first_dbt_model.sql
13:54:18.381116 [debug] [MainThread]: 1699: static parser successfully parsed example\my_second_dbt_model.sql
13:54:18.412778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f1b10c56-114b-4fb3-9bd4-7f56353b331e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022E0B6D3220>]}
13:54:18.412778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f1b10c56-114b-4fb3-9bd4-7f56353b331e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022E0B6D2F50>]}
13:54:18.412778 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
13:54:18.412778 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f1b10c56-114b-4fb3-9bd4-7f56353b331e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022E0B7DA530>]}
13:54:18.412778 [info ] [MainThread]: 
13:54:18.412778 [debug] [MainThread]: Acquiring new bigquery connection "master"
13:54:18.428454 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
13:54:18.428454 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:54:20.575536 [debug] [ThreadPool]: Acquiring new bigquery connection "create_data-analytics-engineer_bigquery_example_dbt"
13:54:20.575536 [debug] [ThreadPool]: Acquiring new bigquery connection "create_data-analytics-engineer_bigquery_example_dbt"
13:54:20.575536 [debug] [ThreadPool]: BigQuery adapter: Creating schema "data-analytics-engineer.bigquery_example_dbt".
13:54:20.575536 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:54:22.257132 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
13:54:22.258831 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:54:24.131975 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f1b10c56-114b-4fb3-9bd4-7f56353b331e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022E0B7EBF40>]}
13:54:24.140343 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:54:24.140343 [info ] [MainThread]: 
13:54:24.225894 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_first_dbt_model
13:54:24.226901 [info ] [Thread-1 (]: 1 of 2 START table model bigquery_example_dbt.my_first_dbt_model ............... [RUN]
13:54:24.226901 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_first_dbt_model"
13:54:24.226901 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_first_dbt_model
13:54:24.226901 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_first_dbt_model
13:54:24.226901 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
13:54:24.226901 [debug] [Thread-1 (]: finished collecting timing info
13:54:24.226901 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_first_dbt_model
13:54:24.243973 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
13:54:24.243973 [debug] [Thread-1 (]: Opening a new connection, currently in state init
13:54:24.243973 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_first_dbt_model"} */


  create or replace table `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
13:54:28.170974 [debug] [Thread-1 (]: finished collecting timing info
13:54:28.170974 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1b10c56-114b-4fb3-9bd4-7f56353b331e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022E0ADA3BE0>]}
13:54:28.170974 [info ] [Thread-1 (]: 1 of 2 OK created table model bigquery_example_dbt.my_first_dbt_model .......... [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 3.94s]
13:54:28.170974 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_first_dbt_model
13:54:28.170974 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model
13:54:28.170974 [info ] [Thread-1 (]: 2 of 2 START view model bigquery_example_dbt.my_second_dbt_model ............... [RUN]
13:54:28.170974 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model"
13:54:28.170974 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model
13:54:28.170974 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model
13:54:28.186620 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
13:54:28.187219 [debug] [Thread-1 (]: finished collecting timing info
13:54:28.187219 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model
13:54:28.187219 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
13:54:28.205602 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
13:54:28.205602 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
where id = 1;


13:54:30.903878 [debug] [Thread-1 (]: finished collecting timing info
13:54:30.904963 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f1b10c56-114b-4fb3-9bd4-7f56353b331e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022E0B92ABC0>]}
13:54:30.904963 [info ] [Thread-1 (]: 2 of 2 OK created view model bigquery_example_dbt.my_second_dbt_model .......... [[32mOK[0m in 2.73s]
13:54:30.905890 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model
13:54:30.907019 [debug] [MainThread]: Acquiring new bigquery connection "master"
13:54:30.907019 [info ] [MainThread]: 
13:54:30.907019 [info ] [MainThread]: Finished running 1 table model, 1 view model in 12.49s.
13:54:30.907019 [debug] [MainThread]: Connection 'master' was properly closed.
13:54:30.907019 [debug] [MainThread]: Connection 'create_data-analytics-engineer_bigquery_example_dbt' was properly closed.
13:54:30.907019 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt' was properly closed.
13:54:30.907019 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_second_dbt_model' was properly closed.
13:54:30.916424 [info ] [MainThread]: 
13:54:30.916424 [info ] [MainThread]: [32mCompleted successfully[0m
13:54:30.916424 [info ] [MainThread]: 
13:54:30.916424 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
13:54:30.916424 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022E0B8F1AB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022E0B69EF80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022E0B6E3460>]}


============================== 2023-02-11 08:31:11.594785 | 9706bdc6-35aa-40eb-a1cd-bde783a86856 ==============================
08:31:11.594785 [info ] [MainThread]: Running with dbt=1.1.0
08:31:11.594785 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:31:11.594785 [debug] [MainThread]: Tracking: tracking
08:31:11.633676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225C1558F70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225C155B430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225C155AC20>]}
08:31:11.988532 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
08:31:11.988532 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
08:31:12.004666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9706bdc6-35aa-40eb-a1cd-bde783a86856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225C16B64A0>]}
08:31:12.004666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9706bdc6-35aa-40eb-a1cd-bde783a86856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225C168DED0>]}
08:31:12.004666 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
08:31:12.014729 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9706bdc6-35aa-40eb-a1cd-bde783a86856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225C168DDE0>]}
08:31:12.015865 [info ] [MainThread]: 
08:31:12.015865 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:31:12.017723 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
08:31:12.017723 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:31:13.089985 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
08:31:13.089985 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:31:14.019345 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9706bdc6-35aa-40eb-a1cd-bde783a86856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225C166FB50>]}
08:31:14.019345 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:31:14.019345 [info ] [MainThread]: 
08:31:14.050846 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_first_dbt_model
08:31:14.050846 [info ] [Thread-1 (]: 1 of 2 START table model bigquery_example_dbt.my_first_dbt_model ............... [RUN]
08:31:14.050846 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_first_dbt_model"
08:31:14.050846 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_first_dbt_model
08:31:14.050846 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_first_dbt_model
08:31:14.050846 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
08:31:14.050846 [debug] [Thread-1 (]: finished collecting timing info
08:31:14.050846 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_first_dbt_model
08:31:14.067232 [debug] [Thread-1 (]: Opening a new connection, currently in state init
08:31:14.962620 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
08:31:14.976934 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_first_dbt_model"} */


  create or replace table `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
08:31:18.148908 [debug] [Thread-1 (]: finished collecting timing info
08:31:18.148908 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9706bdc6-35aa-40eb-a1cd-bde783a86856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225C17810F0>]}
08:31:18.148908 [info ] [Thread-1 (]: 1 of 2 OK created table model bigquery_example_dbt.my_first_dbt_model .......... [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.10s]
08:31:18.152967 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_first_dbt_model
08:31:18.152967 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model
08:31:18.152967 [info ] [Thread-1 (]: 2 of 2 START view model bigquery_example_dbt.my_second_dbt_model ............... [RUN]
08:31:18.152967 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model"
08:31:18.152967 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model
08:31:18.152967 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model
08:31:18.152967 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
08:31:18.152967 [debug] [Thread-1 (]: finished collecting timing info
08:31:18.152967 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model
08:31:18.169133 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
08:31:18.169133 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
08:31:18.169133 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
where id = 1;


08:31:20.039775 [debug] [Thread-1 (]: finished collecting timing info
08:31:20.039775 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9706bdc6-35aa-40eb-a1cd-bde783a86856', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225C16B4130>]}
08:31:20.039775 [info ] [Thread-1 (]: 2 of 2 OK created view model bigquery_example_dbt.my_second_dbt_model .......... [[32mOK[0m in 1.89s]
08:31:20.039775 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model
08:31:20.039775 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:31:20.039775 [info ] [MainThread]: 
08:31:20.039775 [info ] [MainThread]: Finished running 1 table model, 1 view model in 8.02s.
08:31:20.039775 [debug] [MainThread]: Connection 'master' was properly closed.
08:31:20.039775 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
08:31:20.039775 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt' was properly closed.
08:31:20.039775 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_second_dbt_model' was properly closed.
08:31:20.055977 [info ] [MainThread]: 
08:31:20.055977 [info ] [MainThread]: [32mCompleted successfully[0m
08:31:20.055977 [info ] [MainThread]: 
08:31:20.055977 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
08:31:20.055977 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225C1757A00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225C168DD20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000225C16B7D00>]}


============================== 2023-02-11 08:54:38.107235 | 53126f86-2cbc-4286-adc7-a7d1d7396f0a ==============================
08:54:38.107235 [info ] [MainThread]: Running with dbt=1.1.0
08:54:38.107235 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
08:54:38.107235 [debug] [MainThread]: Tracking: tracking
08:54:38.158049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFDE4FA590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFDE4F9E10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFDE4FAD40>]}
08:54:38.202662 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
08:54:38.202662 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
08:54:38.217719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '53126f86-2cbc-4286-adc7-a7d1d7396f0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFDE656500>]}
08:54:38.217719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '53126f86-2cbc-4286-adc7-a7d1d7396f0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFDE629F30>]}
08:54:38.217719 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 0 seed files, 0 sources, 0 exposures, 0 metrics
08:54:38.217719 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53126f86-2cbc-4286-adc7-a7d1d7396f0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFDE629E40>]}
08:54:38.217719 [info ] [MainThread]: 
08:54:38.217719 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:54:38.217719 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
08:54:38.217719 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:54:39.200905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '53126f86-2cbc-4286-adc7-a7d1d7396f0a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFDE629C00>]}
08:54:39.200905 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:54:39.200905 [info ] [MainThread]: 
08:54:39.209963 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_first_dbt_model
08:54:39.209963 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_first_dbt_model"
08:54:39.209963 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_first_dbt_model
08:54:39.209963 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_first_dbt_model
08:54:39.209963 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
08:54:39.209963 [debug] [Thread-1 (]: finished collecting timing info
08:54:39.209963 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_first_dbt_model
08:54:39.209963 [debug] [Thread-1 (]: finished collecting timing info
08:54:39.209963 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_first_dbt_model
08:54:39.209963 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model
08:54:39.209963 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model"
08:54:39.209963 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model
08:54:39.209963 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model
08:54:39.209963 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
08:54:39.209963 [debug] [Thread-1 (]: finished collecting timing info
08:54:39.209963 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model
08:54:39.209963 [debug] [Thread-1 (]: finished collecting timing info
08:54:39.209963 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model
08:54:39.209963 [debug] [Thread-1 (]: Began running node test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710
08:54:39.209963 [debug] [Thread-1 (]: Acquiring new bigquery connection "test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710"
08:54:39.225733 [debug] [Thread-1 (]: Began compiling node test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710
08:54:39.225733 [debug] [Thread-1 (]: Compiling test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710
08:54:39.225733 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710"
08:54:39.225733 [debug] [Thread-1 (]: finished collecting timing info
08:54:39.225733 [debug] [Thread-1 (]: Began executing node test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710
08:54:39.225733 [debug] [Thread-1 (]: finished collecting timing info
08:54:39.225733 [debug] [Thread-1 (]: Finished running node test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710
08:54:39.225733 [debug] [Thread-1 (]: Began running node test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321
08:54:39.225733 [debug] [Thread-1 (]: Acquiring new bigquery connection "test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321"
08:54:39.225733 [debug] [Thread-1 (]: Began compiling node test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321
08:54:39.225733 [debug] [Thread-1 (]: Compiling test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321
08:54:39.241331 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321"
08:54:39.241331 [debug] [Thread-1 (]: finished collecting timing info
08:54:39.241331 [debug] [Thread-1 (]: Began executing node test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321
08:54:39.241331 [debug] [Thread-1 (]: finished collecting timing info
08:54:39.241331 [debug] [Thread-1 (]: Finished running node test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321
08:54:39.241331 [debug] [Thread-1 (]: Began running node test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778
08:54:39.241331 [debug] [Thread-1 (]: Acquiring new bigquery connection "test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778"
08:54:39.241331 [debug] [Thread-1 (]: Began compiling node test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778
08:54:39.241331 [debug] [Thread-1 (]: Compiling test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778
08:54:39.241331 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778"
08:54:39.241331 [debug] [Thread-1 (]: finished collecting timing info
08:54:39.241331 [debug] [Thread-1 (]: Began executing node test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778
08:54:39.241331 [debug] [Thread-1 (]: finished collecting timing info
08:54:39.241331 [debug] [Thread-1 (]: Finished running node test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778
08:54:39.241331 [debug] [Thread-1 (]: Began running node test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493
08:54:39.241331 [debug] [Thread-1 (]: Acquiring new bigquery connection "test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493"
08:54:39.241331 [debug] [Thread-1 (]: Began compiling node test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493
08:54:39.241331 [debug] [Thread-1 (]: Compiling test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493
08:54:39.256865 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493"
08:54:39.256865 [debug] [Thread-1 (]: finished collecting timing info
08:54:39.256865 [debug] [Thread-1 (]: Began executing node test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493
08:54:39.256865 [debug] [Thread-1 (]: finished collecting timing info
08:54:39.256865 [debug] [Thread-1 (]: Finished running node test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493
08:54:39.256865 [debug] [MainThread]: Connection 'master' was properly closed.
08:54:39.256865 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt' was properly closed.
08:54:39.256865 [debug] [MainThread]: Connection 'test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
08:54:39.256865 [info ] [MainThread]: Done.
08:54:39.509505 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
08:54:39.509505 [info ] [MainThread]: Building catalog
08:54:39.509505 [debug] [MainThread]: Opening a new connection, currently in state init
08:54:40.375708 [debug] [ThreadPool]: Acquiring new bigquery connection "data-analytics-engineer.information_schema"
08:54:40.391473 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:54:40.391473 [debug] [ThreadPool]: On data-analytics-engineer.information_schema: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "connection_name": "data-analytics-engineer.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `data-analytics-engineer`.`bigquery_example_dbt`.__TABLES__
        where (upper(dataset_id) = upper('bigquery_example_dbt'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `data-analytics-engineer`.`bigquery_example_dbt`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `data-analytics-engineer`.`bigquery_example_dbt`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
08:54:44.282992 [info ] [MainThread]: Catalog written to C:\Users\HP\Documents\Project\data-analytics-engineer-dbt\data_warehouse_analytics_engineer\target\catalog.json
08:54:44.282992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFDE4FA590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFDE6F5990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FFDE739A20>]}
08:54:45.377423 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
08:54:45.377423 [debug] [MainThread]: Connection 'data-analytics-engineer.information_schema' was properly closed.


============================== 2023-02-11 08:57:16.609621 | 57953547-3655-48d0-8823-207f010f86a2 ==============================
08:57:16.609621 [info ] [MainThread]: Running with dbt=1.1.0
08:57:16.609621 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'port': 8081, 'open_browser': True, 'which': 'serve', 'indirect_selection': 'eager'}
08:57:16.609621 [debug] [MainThread]: Tracking: tracking
08:57:16.649369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E904A8D240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E904A8DF60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001E904A8E800>]}
08:57:16.655630 [info ] [MainThread]: Serving docs at 0.0.0.0:8081
08:57:16.657139 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:8081
08:57:16.657139 [info ] [MainThread]: 
08:57:16.657139 [info ] [MainThread]: 
08:57:16.657139 [info ] [MainThread]: Press Ctrl+C to exit.


============================== 2023-02-18 08:12:22.237050 | 057695ba-4736-48ab-8d7f-3e247bd3e58b ==============================
08:12:22.237050 [info ] [MainThread]: Running with dbt=1.1.0
08:12:22.243497 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['vn_provinces'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:12:22.243497 [debug] [MainThread]: Tracking: tracking
08:12:22.272229 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85AA0FA90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85AA0D090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85AA0F760>]}
08:12:22.473332 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
08:12:22.473332 [debug] [MainThread]: Partial parsing: added file: data_warehouse_analytics_engineer://seeds\vn_provinces.csv
08:12:22.513973 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '057695ba-4736-48ab-8d7f-3e247bd3e58b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85AB8C0D0>]}
08:12:22.521932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '057695ba-4736-48ab-8d7f-3e247bd3e58b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85AB1FEE0>]}
08:12:22.521932 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 0 sources, 0 exposures, 0 metrics
08:12:22.521932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '057695ba-4736-48ab-8d7f-3e247bd3e58b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85AB1FF70>]}
08:12:22.521932 [info ] [MainThread]: 
08:12:22.521932 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
08:12:22.531790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85AB59A50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85AB5A710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F85AB580A0>]}


============================== 2023-02-18 08:12:57.962914 | fa7e58f6-50f8-4d94-bd57-bc3756b83ef5 ==============================
08:12:57.962914 [info ] [MainThread]: Running with dbt=1.1.0
08:12:57.962914 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'show': False, 'select': ['vn_provinces'], 'which': 'seed', 'rpc_method': 'seed', 'indirect_selection': 'eager'}
08:12:57.962914 [debug] [MainThread]: Tracking: tracking
08:12:57.989469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028F2178F130>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028F2178C250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028F2178F940>]}
08:12:58.030714 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
08:12:58.030714 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
08:12:58.036724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fa7e58f6-50f8-4d94-bd57-bc3756b83ef5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028F218F2A70>]}
08:12:58.038623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fa7e58f6-50f8-4d94-bd57-bc3756b83ef5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028F218BE380>]}
08:12:58.038623 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 0 sources, 0 exposures, 0 metrics
08:12:58.038623 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fa7e58f6-50f8-4d94-bd57-bc3756b83ef5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028F218BE560>]}
08:12:58.038623 [info ] [MainThread]: 
08:12:58.038623 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:12:58.051975 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
08:12:58.051975 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:12:58.324472 [debug] [MainThread]: Connection 'master' was properly closed.
08:12:58.324472 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
08:12:58.324472 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028F218BE080>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028F218BE6E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000028F218A7D30>]}


============================== 2023-02-18 08:14:09.577762 | ac0a06e9-6405-45be-89e0-b6e25a92d3f1 ==============================
08:14:09.577762 [info ] [MainThread]: Running with dbt=1.1.0
08:14:09.593383 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:14:09.593383 [debug] [MainThread]: Tracking: tracking
08:14:09.608922 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C29A16CE80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C29A16EB90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C29A16CAC0>]}
08:14:09.640216 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
08:14:09.640216 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
08:14:09.640216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ac0a06e9-6405-45be-89e0-b6e25a92d3f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C29A29E680>]}
08:14:09.656349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ac0a06e9-6405-45be-89e0-b6e25a92d3f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C29A269F90>]}
08:14:09.656349 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 0 sources, 0 exposures, 0 metrics
08:14:09.656349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac0a06e9-6405-45be-89e0-b6e25a92d3f1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C29A26A170>]}
08:14:09.656349 [info ] [MainThread]: 
08:14:09.656349 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:14:09.656349 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
08:14:09.656349 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:14:09.907771 [debug] [MainThread]: Connection 'master' was properly closed.
08:14:09.907771 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
08:14:09.907771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C29A269C90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C29A269AB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C29A25B970>]}


============================== 2023-02-18 08:16:15.927283 | 449eb30b-d5f2-4475-8e31-2fa0f8df918d ==============================
08:16:15.927283 [info ] [MainThread]: Running with dbt=1.1.0
08:16:15.929304 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:16:15.929304 [debug] [MainThread]: Tracking: tracking
08:16:15.954183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F30B5FD060>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F30B5FE620>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F30B5FF940>]}
08:16:15.966870 [info ] [MainThread]: Unable to do partial parsing because profile has changed
08:16:15.966870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '449eb30b-d5f2-4475-8e31-2fa0f8df918d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F30B5FE0B0>]}
08:16:16.011823 [debug] [MainThread]: Parsing macros\adapters.sql
08:16:16.032025 [debug] [MainThread]: Parsing macros\catalog.sql
08:16:16.041043 [debug] [MainThread]: Parsing macros\etc.sql
08:16:16.046657 [debug] [MainThread]: Parsing macros\materializations\copy.sql
08:16:16.050185 [debug] [MainThread]: Parsing macros\materializations\incremental.sql
08:16:16.068808 [debug] [MainThread]: Parsing macros\materializations\seed.sql
08:16:16.068808 [debug] [MainThread]: Parsing macros\materializations\snapshot.sql
08:16:16.068808 [debug] [MainThread]: Parsing macros\materializations\table.sql
08:16:16.078318 [debug] [MainThread]: Parsing macros\materializations\view.sql
08:16:16.078318 [debug] [MainThread]: Parsing macros\adapters\columns.sql
08:16:16.086058 [debug] [MainThread]: Parsing macros\adapters\freshness.sql
08:16:16.088583 [debug] [MainThread]: Parsing macros\adapters\indexes.sql
08:16:16.088583 [debug] [MainThread]: Parsing macros\adapters\metadata.sql
08:16:16.094093 [debug] [MainThread]: Parsing macros\adapters\persist_docs.sql
08:16:16.094093 [debug] [MainThread]: Parsing macros\adapters\relation.sql
08:16:16.111073 [debug] [MainThread]: Parsing macros\adapters\schema.sql
08:16:16.111073 [debug] [MainThread]: Parsing macros\etc\datetime.sql
08:16:16.124098 [debug] [MainThread]: Parsing macros\etc\statement.sql
08:16:16.138910 [debug] [MainThread]: Parsing macros\generic_test_sql\accepted_values.sql
08:16:16.139933 [debug] [MainThread]: Parsing macros\generic_test_sql\not_null.sql
08:16:16.139933 [debug] [MainThread]: Parsing macros\generic_test_sql\relationships.sql
08:16:16.142653 [debug] [MainThread]: Parsing macros\generic_test_sql\unique.sql
08:16:16.142653 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_alias.sql
08:16:16.142653 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_database.sql
08:16:16.142653 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_schema.sql
08:16:16.142653 [debug] [MainThread]: Parsing macros\materializations\configs.sql
08:16:16.142653 [debug] [MainThread]: Parsing macros\materializations\hooks.sql
08:16:16.142653 [debug] [MainThread]: Parsing macros\materializations\models\incremental\column_helpers.sql
08:16:16.142653 [debug] [MainThread]: Parsing macros\materializations\models\incremental\incremental.sql
08:16:16.161195 [debug] [MainThread]: Parsing macros\materializations\models\incremental\is_incremental.sql
08:16:16.161195 [debug] [MainThread]: Parsing macros\materializations\models\incremental\merge.sql
08:16:16.179489 [debug] [MainThread]: Parsing macros\materializations\models\incremental\on_schema_change.sql
08:16:16.189180 [debug] [MainThread]: Parsing macros\materializations\models\table\create_table_as.sql
08:16:16.189180 [debug] [MainThread]: Parsing macros\materializations\models\table\table.sql
08:16:16.194906 [debug] [MainThread]: Parsing macros\materializations\models\view\create_or_replace_view.sql
08:16:16.201433 [debug] [MainThread]: Parsing macros\materializations\models\view\create_view_as.sql
08:16:16.201433 [debug] [MainThread]: Parsing macros\materializations\models\view\helpers.sql
08:16:16.204961 [debug] [MainThread]: Parsing macros\materializations\models\view\view.sql
08:16:16.215027 [debug] [MainThread]: Parsing macros\materializations\seeds\helpers.sql
08:16:16.237676 [debug] [MainThread]: Parsing macros\materializations\seeds\seed.sql
08:16:16.241539 [debug] [MainThread]: Parsing macros\materializations\snapshots\helpers.sql
08:16:16.241539 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot.sql
08:16:16.256761 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot_merge.sql
08:16:16.256761 [debug] [MainThread]: Parsing macros\materializations\snapshots\strategies.sql
08:16:16.270797 [debug] [MainThread]: Parsing macros\materializations\tests\helpers.sql
08:16:16.274997 [debug] [MainThread]: Parsing macros\materializations\tests\test.sql
08:16:16.274997 [debug] [MainThread]: Parsing macros\materializations\tests\where_subquery.sql
08:16:16.274997 [debug] [MainThread]: Parsing tests\generic\builtin.sql
08:16:16.474208 [debug] [MainThread]: 1699: static parser successfully parsed example\my_first_dbt_model.sql
08:16:16.474208 [debug] [MainThread]: 1699: static parser successfully parsed example\my_second_dbt_model.sql
08:16:16.522343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '449eb30b-d5f2-4475-8e31-2fa0f8df918d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F30B5FD6F0>]}
08:16:16.522343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '449eb30b-d5f2-4475-8e31-2fa0f8df918d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F30B5FDBD0>]}
08:16:16.522343 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 0 sources, 0 exposures, 0 metrics
08:16:16.522343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '449eb30b-d5f2-4475-8e31-2fa0f8df918d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F30B738580>]}
08:16:16.522343 [info ] [MainThread]: 
08:16:16.522343 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:16:16.522343 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
08:16:16.522343 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:16:17.381770 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
08:16:17.381770 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:16:18.130542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '449eb30b-d5f2-4475-8e31-2fa0f8df918d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F30B701D20>]}
08:16:18.130542 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:16:18.130542 [info ] [MainThread]: 
08:16:18.147177 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_first_dbt_model
08:16:18.147177 [info ] [Thread-1 (]: 1 of 2 START table model bigquery_example_dbt.my_first_dbt_model ............... [RUN]
08:16:18.147177 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_first_dbt_model"
08:16:18.147177 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_first_dbt_model
08:16:18.147177 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_first_dbt_model
08:16:18.147177 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
08:16:18.147177 [debug] [Thread-1 (]: finished collecting timing info
08:16:18.147177 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_first_dbt_model
08:16:18.166518 [debug] [Thread-1 (]: Opening a new connection, currently in state init
08:16:18.944759 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
08:16:18.944759 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_first_dbt_model"} */


  create or replace table `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
08:16:21.847475 [debug] [Thread-1 (]: finished collecting timing info
08:16:21.847475 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '449eb30b-d5f2-4475-8e31-2fa0f8df918d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F30B709450>]}
08:16:21.847475 [info ] [Thread-1 (]: 1 of 2 OK created table model bigquery_example_dbt.my_first_dbt_model .......... [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 3.70s]
08:16:21.861683 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_first_dbt_model
08:16:21.862190 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model
08:16:21.862969 [info ] [Thread-1 (]: 2 of 2 START view model bigquery_example_dbt.my_second_dbt_model ............... [RUN]
08:16:21.862969 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model"
08:16:21.864059 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model
08:16:21.864059 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model
08:16:21.866540 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
08:16:21.866540 [debug] [Thread-1 (]: finished collecting timing info
08:16:21.866540 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model
08:16:21.878270 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
08:16:21.893300 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
08:16:21.895544 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
where id = 1;


08:16:23.516772 [debug] [Thread-1 (]: finished collecting timing info
08:16:23.516772 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '449eb30b-d5f2-4475-8e31-2fa0f8df918d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F30B7096C0>]}
08:16:23.516772 [info ] [Thread-1 (]: 2 of 2 OK created view model bigquery_example_dbt.my_second_dbt_model .......... [[32mOK[0m in 1.65s]
08:16:23.516772 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model
08:16:23.521800 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:16:23.521800 [info ] [MainThread]: 
08:16:23.521800 [info ] [MainThread]: Finished running 1 table model, 1 view model in 7.00s.
08:16:23.521800 [debug] [MainThread]: Connection 'master' was properly closed.
08:16:23.521800 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
08:16:23.521800 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt' was properly closed.
08:16:23.521800 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_second_dbt_model' was properly closed.
08:16:23.521800 [info ] [MainThread]: 
08:16:23.521800 [info ] [MainThread]: [32mCompleted successfully[0m
08:16:23.521800 [info ] [MainThread]: 
08:16:23.521800 [info ] [MainThread]: Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
08:16:23.521800 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F30B6B3460>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F30B50B4C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F30B709CF0>]}


============================== 2023-02-18 08:17:51.387743 | e312dac0-d246-4a65-9fbd-78ba500e1ffe ==============================
08:17:51.387743 [info ] [MainThread]: Running with dbt=1.1.0
08:17:51.393255 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'show': False, 'select': ['vn_provinces'], 'which': 'seed', 'rpc_method': 'seed', 'indirect_selection': 'eager'}
08:17:51.393255 [debug] [MainThread]: Tracking: tracking
08:17:51.420519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F608F2C430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F608F2FD30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F608F2F4F0>]}
08:17:51.477180 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
08:17:51.477180 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
08:17:51.486602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e312dac0-d246-4a65-9fbd-78ba500e1ffe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F6090929E0>]}
08:17:51.496218 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e312dac0-d246-4a65-9fbd-78ba500e1ffe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F60905E2F0>]}
08:17:51.496218 [info ] [MainThread]: Found 2 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 0 sources, 0 exposures, 0 metrics
08:17:51.499811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e312dac0-d246-4a65-9fbd-78ba500e1ffe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F60905E4D0>]}
08:17:51.499811 [info ] [MainThread]: 
08:17:51.499811 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:17:51.499811 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
08:17:51.499811 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:17:52.253835 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
08:17:52.253835 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:17:52.965195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e312dac0-d246-4a65-9fbd-78ba500e1ffe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F60905D750>]}
08:17:52.965195 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:17:52.965195 [info ] [MainThread]: 
08:17:52.965195 [debug] [Thread-1 (]: Began running node seed.data_warehouse_analytics_engineer.vn_provinces
08:17:52.965195 [info ] [Thread-1 (]: 1 of 1 START seed file bigquery_example_dbt.vn_provinces ....................... [RUN]
08:17:52.965195 [debug] [Thread-1 (]: Acquiring new bigquery connection "seed.data_warehouse_analytics_engineer.vn_provinces"
08:17:52.965195 [debug] [Thread-1 (]: Began compiling node seed.data_warehouse_analytics_engineer.vn_provinces
08:17:52.965195 [debug] [Thread-1 (]: finished collecting timing info
08:17:52.965195 [debug] [Thread-1 (]: Began executing node seed.data_warehouse_analytics_engineer.vn_provinces
08:17:53.012021 [debug] [Thread-1 (]: Opening a new connection, currently in state init
08:17:58.274385 [debug] [Thread-1 (]: Writing runtime SQL for node "seed.data_warehouse_analytics_engineer.vn_provinces"
08:17:58.281806 [debug] [Thread-1 (]: finished collecting timing info
08:17:58.281806 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e312dac0-d246-4a65-9fbd-78ba500e1ffe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F609080AC0>]}
08:17:58.281806 [info ] [Thread-1 (]: 1 of 1 OK loaded seed file bigquery_example_dbt.vn_provinces ................... [[32mINSERT 610[0m in 5.32s]
08:17:58.281806 [debug] [Thread-1 (]: Finished running node seed.data_warehouse_analytics_engineer.vn_provinces
08:17:58.281806 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:17:58.281806 [info ] [MainThread]: 
08:17:58.281806 [info ] [MainThread]: Finished running 1 seed in 6.78s.
08:17:58.281806 [debug] [MainThread]: Connection 'master' was properly closed.
08:17:58.289315 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
08:17:58.289315 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt' was properly closed.
08:17:58.289315 [debug] [MainThread]: Connection 'seed.data_warehouse_analytics_engineer.vn_provinces' was properly closed.
08:17:58.295700 [info ] [MainThread]: 
08:17:58.295700 [info ] [MainThread]: [32mCompleted successfully[0m
08:17:58.295700 [info ] [MainThread]: 
08:17:58.295700 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
08:17:58.295700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F60905E1D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F60905DFF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F60907B400>]}


============================== 2023-02-18 08:23:01.382989 | e381014d-4e75-47a8-b98d-8567fb81b7a5 ==============================
08:23:01.382989 [info ] [MainThread]: Running with dbt=1.1.0
08:23:01.382989 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['my_first_dbt_model_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:23:01.382989 [debug] [MainThread]: Tracking: tracking
08:23:01.410060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C11B15C8B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C11B15E2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C11B15E290>]}
08:23:01.426141 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
08:23:01.426141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'e381014d-4e75-47a8-b98d-8567fb81b7a5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C11B15D300>]}
08:23:01.452499 [debug] [MainThread]: Parsing macros\adapters.sql
08:23:01.457612 [debug] [MainThread]: Parsing macros\catalog.sql
08:23:01.474255 [debug] [MainThread]: Parsing macros\etc.sql
08:23:01.474255 [debug] [MainThread]: Parsing macros\materializations\copy.sql
08:23:01.474255 [debug] [MainThread]: Parsing macros\materializations\incremental.sql
08:23:01.489287 [debug] [MainThread]: Parsing macros\materializations\seed.sql
08:23:01.489287 [debug] [MainThread]: Parsing macros\materializations\snapshot.sql
08:23:01.489287 [debug] [MainThread]: Parsing macros\materializations\table.sql
08:23:01.489287 [debug] [MainThread]: Parsing macros\materializations\view.sql
08:23:01.489287 [debug] [MainThread]: Parsing macros\adapters\columns.sql
08:23:01.498849 [debug] [MainThread]: Parsing macros\adapters\freshness.sql
08:23:01.505425 [debug] [MainThread]: Parsing macros\adapters\indexes.sql
08:23:01.505425 [debug] [MainThread]: Parsing macros\adapters\metadata.sql
08:23:01.515436 [debug] [MainThread]: Parsing macros\adapters\persist_docs.sql
08:23:01.519476 [debug] [MainThread]: Parsing macros\adapters\relation.sql
08:23:01.525520 [debug] [MainThread]: Parsing macros\adapters\schema.sql
08:23:01.525520 [debug] [MainThread]: Parsing macros\etc\datetime.sql
08:23:01.532413 [debug] [MainThread]: Parsing macros\etc\statement.sql
08:23:01.538933 [debug] [MainThread]: Parsing macros\generic_test_sql\accepted_values.sql
08:23:01.538933 [debug] [MainThread]: Parsing macros\generic_test_sql\not_null.sql
08:23:01.538933 [debug] [MainThread]: Parsing macros\generic_test_sql\relationships.sql
08:23:01.543466 [debug] [MainThread]: Parsing macros\generic_test_sql\unique.sql
08:23:01.543466 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_alias.sql
08:23:01.543466 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_database.sql
08:23:01.543466 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_schema.sql
08:23:01.543466 [debug] [MainThread]: Parsing macros\materializations\configs.sql
08:23:01.543466 [debug] [MainThread]: Parsing macros\materializations\hooks.sql
08:23:01.543466 [debug] [MainThread]: Parsing macros\materializations\models\incremental\column_helpers.sql
08:23:01.552989 [debug] [MainThread]: Parsing macros\materializations\models\incremental\incremental.sql
08:23:01.552989 [debug] [MainThread]: Parsing macros\materializations\models\incremental\is_incremental.sql
08:23:01.552989 [debug] [MainThread]: Parsing macros\materializations\models\incremental\merge.sql
08:23:01.568633 [debug] [MainThread]: Parsing macros\materializations\models\incremental\on_schema_change.sql
08:23:01.584344 [debug] [MainThread]: Parsing macros\materializations\models\table\create_table_as.sql
08:23:01.584344 [debug] [MainThread]: Parsing macros\materializations\models\table\table.sql
08:23:01.584344 [debug] [MainThread]: Parsing macros\materializations\models\view\create_or_replace_view.sql
08:23:01.584344 [debug] [MainThread]: Parsing macros\materializations\models\view\create_view_as.sql
08:23:01.584344 [debug] [MainThread]: Parsing macros\materializations\models\view\helpers.sql
08:23:01.584344 [debug] [MainThread]: Parsing macros\materializations\models\view\view.sql
08:23:01.599970 [debug] [MainThread]: Parsing macros\materializations\seeds\helpers.sql
08:23:01.610000 [debug] [MainThread]: Parsing macros\materializations\seeds\seed.sql
08:23:01.616038 [debug] [MainThread]: Parsing macros\materializations\snapshots\helpers.sql
08:23:01.616038 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot.sql
08:23:01.632076 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot_merge.sql
08:23:01.632076 [debug] [MainThread]: Parsing macros\materializations\snapshots\strategies.sql
08:23:01.636583 [debug] [MainThread]: Parsing macros\materializations\tests\helpers.sql
08:23:01.636583 [debug] [MainThread]: Parsing macros\materializations\tests\test.sql
08:23:01.648198 [debug] [MainThread]: Parsing macros\materializations\tests\where_subquery.sql
08:23:01.648198 [debug] [MainThread]: Parsing tests\generic\builtin.sql
08:23:01.821922 [debug] [MainThread]: 1699: static parser successfully parsed example\my_first_dbt_model.sql
08:23:01.833946 [debug] [MainThread]: 1699: static parser successfully parsed example\my_second_dbt_model.sql
08:23:01.833946 [debug] [MainThread]: 1699: static parser successfully parsed example_1\my_first_dbt_model_1.sql
08:23:01.839323 [debug] [MainThread]: 1699: static parser successfully parsed example_1\my_second_dbt_model_1.sql
08:23:01.869432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C11B26F2E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C11B2945B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C11B2964D0>]}


============================== 2023-02-18 08:23:46.278250 | 6ca6d923-c998-4986-8df8-1b4321cb69a0 ==============================
08:23:46.278250 [info ] [MainThread]: Running with dbt=1.1.0
08:23:46.278250 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['my_first_dbt_model_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:23:46.278250 [debug] [MainThread]: Tracking: tracking
08:23:46.311542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E57DDA20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E57DE0B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E57DE290>]}
08:23:46.311542 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
08:23:46.311542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6ca6d923-c998-4986-8df8-1b4321cb69a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E57DD2D0>]}
08:23:46.341380 [debug] [MainThread]: Parsing macros\adapters.sql
08:23:46.357006 [debug] [MainThread]: Parsing macros\catalog.sql
08:23:46.357006 [debug] [MainThread]: Parsing macros\etc.sql
08:23:46.357006 [debug] [MainThread]: Parsing macros\materializations\copy.sql
08:23:46.357006 [debug] [MainThread]: Parsing macros\materializations\incremental.sql
08:23:46.372522 [debug] [MainThread]: Parsing macros\materializations\seed.sql
08:23:46.372522 [debug] [MainThread]: Parsing macros\materializations\snapshot.sql
08:23:46.372522 [debug] [MainThread]: Parsing macros\materializations\table.sql
08:23:46.372522 [debug] [MainThread]: Parsing macros\materializations\view.sql
08:23:46.372522 [debug] [MainThread]: Parsing macros\adapters\columns.sql
08:23:46.388147 [debug] [MainThread]: Parsing macros\adapters\freshness.sql
08:23:46.388147 [debug] [MainThread]: Parsing macros\adapters\indexes.sql
08:23:46.388147 [debug] [MainThread]: Parsing macros\adapters\metadata.sql
08:23:46.388147 [debug] [MainThread]: Parsing macros\adapters\persist_docs.sql
08:23:46.388147 [debug] [MainThread]: Parsing macros\adapters\relation.sql
08:23:46.403772 [debug] [MainThread]: Parsing macros\adapters\schema.sql
08:23:46.403772 [debug] [MainThread]: Parsing macros\etc\datetime.sql
08:23:46.411786 [debug] [MainThread]: Parsing macros\etc\statement.sql
08:23:46.411786 [debug] [MainThread]: Parsing macros\generic_test_sql\accepted_values.sql
08:23:46.411786 [debug] [MainThread]: Parsing macros\generic_test_sql\not_null.sql
08:23:46.411786 [debug] [MainThread]: Parsing macros\generic_test_sql\relationships.sql
08:23:46.411786 [debug] [MainThread]: Parsing macros\generic_test_sql\unique.sql
08:23:46.411786 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_alias.sql
08:23:46.411786 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_database.sql
08:23:46.419800 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_schema.sql
08:23:46.419800 [debug] [MainThread]: Parsing macros\materializations\configs.sql
08:23:46.419800 [debug] [MainThread]: Parsing macros\materializations\hooks.sql
08:23:46.419800 [debug] [MainThread]: Parsing macros\materializations\models\incremental\column_helpers.sql
08:23:46.419800 [debug] [MainThread]: Parsing macros\materializations\models\incremental\incremental.sql
08:23:46.419800 [debug] [MainThread]: Parsing macros\materializations\models\incremental\is_incremental.sql
08:23:46.435439 [debug] [MainThread]: Parsing macros\materializations\models\incremental\merge.sql
08:23:46.435439 [debug] [MainThread]: Parsing macros\materializations\models\incremental\on_schema_change.sql
08:23:46.451069 [debug] [MainThread]: Parsing macros\materializations\models\table\create_table_as.sql
08:23:46.456277 [debug] [MainThread]: Parsing macros\materializations\models\table\table.sql
08:23:46.460283 [debug] [MainThread]: Parsing macros\materializations\models\view\create_or_replace_view.sql
08:23:46.465750 [debug] [MainThread]: Parsing macros\materializations\models\view\create_view_as.sql
08:23:46.466883 [debug] [MainThread]: Parsing macros\materializations\models\view\helpers.sql
08:23:46.467941 [debug] [MainThread]: Parsing macros\materializations\models\view\view.sql
08:23:46.468944 [debug] [MainThread]: Parsing macros\materializations\seeds\helpers.sql
08:23:46.482452 [debug] [MainThread]: Parsing macros\materializations\seeds\seed.sql
08:23:46.482452 [debug] [MainThread]: Parsing macros\materializations\snapshots\helpers.sql
08:23:46.482452 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot.sql
08:23:46.498646 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot_merge.sql
08:23:46.498646 [debug] [MainThread]: Parsing macros\materializations\snapshots\strategies.sql
08:23:46.512158 [debug] [MainThread]: Parsing macros\materializations\tests\helpers.sql
08:23:46.512158 [debug] [MainThread]: Parsing macros\materializations\tests\test.sql
08:23:46.514163 [debug] [MainThread]: Parsing macros\materializations\tests\where_subquery.sql
08:23:46.514163 [debug] [MainThread]: Parsing tests\generic\builtin.sql
08:23:46.656145 [debug] [MainThread]: 1699: static parser successfully parsed example\my_first_dbt_model.sql
08:23:46.674043 [debug] [MainThread]: 1699: static parser successfully parsed example\my_second_dbt_model.sql
08:23:46.674043 [debug] [MainThread]: 1699: static parser successfully parsed example_1\my_first_dbt_model_1.sql
08:23:46.674043 [debug] [MainThread]: 1699: static parser successfully parsed example_1\my_second_dbt_model_1.sql
08:23:46.718919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6ca6d923-c998-4986-8df8-1b4321cb69a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E585D1B0>]}
08:23:46.718919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6ca6d923-c998-4986-8df8-1b4321cb69a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E5773E80>]}
08:23:46.718919 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 0 sources, 0 exposures, 0 metrics
08:23:46.718919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6ca6d923-c998-4986-8df8-1b4321cb69a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E57DE080>]}
08:23:46.718919 [info ] [MainThread]: 
08:23:46.718919 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:23:46.718919 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
08:23:46.718919 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:23:47.535930 [debug] [ThreadPool]: Acquiring new bigquery connection "create_data-analytics-engineer_bigquery_example_dbt_bigquery_example_dbt_1"
08:23:47.535930 [debug] [ThreadPool]: Acquiring new bigquery connection "create_data-analytics-engineer_bigquery_example_dbt_bigquery_example_dbt_1"
08:23:47.535930 [debug] [ThreadPool]: BigQuery adapter: Creating schema "data-analytics-engineer.bigquery_example_dbt_bigquery_example_dbt_1".
08:23:47.535930 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:23:48.682720 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
08:23:48.682720 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:23:49.455401 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt_bigquery_example_dbt_1"
08:23:49.455401 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:23:50.244532 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6ca6d923-c998-4986-8df8-1b4321cb69a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E585D930>]}
08:23:50.244532 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:23:50.244532 [info ] [MainThread]: 
08:23:50.249541 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_first_dbt_model_1
08:23:50.252306 [info ] [Thread-1 (]: 1 of 1 START table model bigquery_example_dbt_bigquery_example_dbt_1.my_first_dbt_model_1  [RUN]
08:23:50.252306 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_first_dbt_model_1"
08:23:50.252306 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_first_dbt_model_1
08:23:50.252306 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_first_dbt_model_1
08:23:50.254006 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model_1"
08:23:50.254006 [debug] [Thread-1 (]: finished collecting timing info
08:23:50.254006 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_first_dbt_model_1
08:23:50.281248 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model_1"
08:23:50.281248 [debug] [Thread-1 (]: Opening a new connection, currently in state init
08:23:50.281248 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_first_dbt_model_1: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_first_dbt_model_1"} */


  create or replace table `data-analytics-engineer`.`bigquery_example_dbt_bigquery_example_dbt_1`.`my_first_dbt_model_1`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
08:23:53.588114 [debug] [Thread-1 (]: finished collecting timing info
08:23:53.588114 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6ca6d923-c998-4986-8df8-1b4321cb69a0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E58AA800>]}
08:23:53.588114 [info ] [Thread-1 (]: 1 of 1 OK created table model bigquery_example_dbt_bigquery_example_dbt_1.my_first_dbt_model_1  [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 3.34s]
08:23:53.588114 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_first_dbt_model_1
08:23:53.588114 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:23:53.588114 [info ] [MainThread]: 
08:23:53.588114 [info ] [MainThread]: Finished running 1 table model in 6.87s.
08:23:53.588114 [debug] [MainThread]: Connection 'master' was properly closed.
08:23:53.588114 [debug] [MainThread]: Connection 'create_data-analytics-engineer_bigquery_example_dbt_bigquery_example_dbt_1' was properly closed.
08:23:53.588114 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt_bigquery_example_dbt_1' was properly closed.
08:23:53.588114 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_first_dbt_model_1' was properly closed.
08:23:53.588114 [info ] [MainThread]: 
08:23:53.588114 [info ] [MainThread]: [32mCompleted successfully[0m
08:23:53.588114 [info ] [MainThread]: 
08:23:53.603732 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
08:23:53.603732 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E5853430>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E58533A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001C8E58A94B0>]}


============================== 2023-02-18 08:25:13.381720 | 59262f66-c1fa-4bdf-8219-59b850122d63 ==============================
08:25:13.381720 [info ] [MainThread]: Running with dbt=1.1.0
08:25:13.381720 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['my_first_dbt_model_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:25:13.381720 [debug] [MainThread]: Tracking: tracking
08:25:13.407045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020F17C70AF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020F17C73CA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020F17C714B0>]}
08:25:13.413062 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
08:25:13.413062 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '59262f66-c1fa-4bdf-8219-59b850122d63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020F17C70190>]}
08:25:13.446092 [debug] [MainThread]: Parsing macros\adapters.sql
08:25:13.460609 [debug] [MainThread]: Parsing macros\catalog.sql
08:25:13.478678 [debug] [MainThread]: Parsing macros\etc.sql
08:25:13.480326 [debug] [MainThread]: Parsing macros\materializations\copy.sql
08:25:13.483636 [debug] [MainThread]: Parsing macros\materializations\incremental.sql
08:25:13.492118 [debug] [MainThread]: Parsing macros\materializations\seed.sql
08:25:13.492118 [debug] [MainThread]: Parsing macros\materializations\snapshot.sql
08:25:13.492118 [debug] [MainThread]: Parsing macros\materializations\table.sql
08:25:13.492118 [debug] [MainThread]: Parsing macros\materializations\view.sql
08:25:13.492118 [debug] [MainThread]: Parsing macros\adapters\columns.sql
08:25:13.507640 [debug] [MainThread]: Parsing macros\adapters\freshness.sql
08:25:13.507640 [debug] [MainThread]: Parsing macros\adapters\indexes.sql
08:25:13.507640 [debug] [MainThread]: Parsing macros\adapters\metadata.sql
08:25:13.507640 [debug] [MainThread]: Parsing macros\adapters\persist_docs.sql
08:25:13.524556 [debug] [MainThread]: Parsing macros\adapters\relation.sql
08:25:13.524556 [debug] [MainThread]: Parsing macros\adapters\schema.sql
08:25:13.524556 [debug] [MainThread]: Parsing macros\etc\datetime.sql
08:25:13.539102 [debug] [MainThread]: Parsing macros\etc\statement.sql
08:25:13.540717 [debug] [MainThread]: Parsing macros\generic_test_sql\accepted_values.sql
08:25:13.540717 [debug] [MainThread]: Parsing macros\generic_test_sql\not_null.sql
08:25:13.540717 [debug] [MainThread]: Parsing macros\generic_test_sql\relationships.sql
08:25:13.540717 [debug] [MainThread]: Parsing macros\generic_test_sql\unique.sql
08:25:13.540717 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_alias.sql
08:25:13.540717 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_database.sql
08:25:13.540717 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_schema.sql
08:25:13.540717 [debug] [MainThread]: Parsing macros\materializations\configs.sql
08:25:13.540717 [debug] [MainThread]: Parsing macros\materializations\hooks.sql
08:25:13.540717 [debug] [MainThread]: Parsing macros\materializations\models\incremental\column_helpers.sql
08:25:13.555265 [debug] [MainThread]: Parsing macros\materializations\models\incremental\incremental.sql
08:25:13.555265 [debug] [MainThread]: Parsing macros\materializations\models\incremental\is_incremental.sql
08:25:13.555265 [debug] [MainThread]: Parsing macros\materializations\models\incremental\merge.sql
08:25:13.578405 [debug] [MainThread]: Parsing macros\materializations\models\incremental\on_schema_change.sql
08:25:13.586919 [debug] [MainThread]: Parsing macros\materializations\models\table\create_table_as.sql
08:25:13.586919 [debug] [MainThread]: Parsing macros\materializations\models\table\table.sql
08:25:13.586919 [debug] [MainThread]: Parsing macros\materializations\models\view\create_or_replace_view.sql
08:25:13.602571 [debug] [MainThread]: Parsing macros\materializations\models\view\create_view_as.sql
08:25:13.602571 [debug] [MainThread]: Parsing macros\materializations\models\view\helpers.sql
08:25:13.602571 [debug] [MainThread]: Parsing macros\materializations\models\view\view.sql
08:25:13.602571 [debug] [MainThread]: Parsing macros\materializations\seeds\helpers.sql
08:25:13.618257 [debug] [MainThread]: Parsing macros\materializations\seeds\seed.sql
08:25:13.618257 [debug] [MainThread]: Parsing macros\materializations\snapshots\helpers.sql
08:25:13.618257 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot.sql
08:25:13.640831 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot_merge.sql
08:25:13.643519 [debug] [MainThread]: Parsing macros\materializations\snapshots\strategies.sql
08:25:13.665225 [debug] [MainThread]: Parsing macros\materializations\tests\helpers.sql
08:25:13.672238 [debug] [MainThread]: Parsing macros\materializations\tests\test.sql
08:25:13.672238 [debug] [MainThread]: Parsing macros\materializations\tests\where_subquery.sql
08:25:13.672238 [debug] [MainThread]: Parsing tests\generic\builtin.sql
08:25:13.883026 [debug] [MainThread]: 1699: static parser successfully parsed example\my_first_dbt_model.sql
08:25:13.894617 [debug] [MainThread]: 1699: static parser successfully parsed example\my_second_dbt_model.sql
08:25:13.894617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020F17C32E90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020F17C6BB20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020F17C686D0>]}


============================== 2023-02-18 08:25:30.249889 | c4454bce-260f-4553-a4f0-f1eadb250885 ==============================
08:25:30.249889 [info ] [MainThread]: Running with dbt=1.1.0
08:25:30.249889 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['my_first_dbt_model_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:25:30.249889 [debug] [MainThread]: Tracking: tracking
08:25:30.265412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8E830C760>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8E830D180>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8E830E290>]}
08:25:30.278455 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
08:25:30.278455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'c4454bce-260f-4553-a4f0-f1eadb250885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8E830D1B0>]}
08:25:30.310266 [debug] [MainThread]: Parsing macros\adapters.sql
08:25:30.325276 [debug] [MainThread]: Parsing macros\catalog.sql
08:25:30.325276 [debug] [MainThread]: Parsing macros\etc.sql
08:25:30.325276 [debug] [MainThread]: Parsing macros\materializations\copy.sql
08:25:30.325276 [debug] [MainThread]: Parsing macros\materializations\incremental.sql
08:25:30.340911 [debug] [MainThread]: Parsing macros\materializations\seed.sql
08:25:30.340911 [debug] [MainThread]: Parsing macros\materializations\snapshot.sql
08:25:30.356544 [debug] [MainThread]: Parsing macros\materializations\table.sql
08:25:30.356544 [debug] [MainThread]: Parsing macros\materializations\view.sql
08:25:30.356544 [debug] [MainThread]: Parsing macros\adapters\columns.sql
08:25:30.365556 [debug] [MainThread]: Parsing macros\adapters\freshness.sql
08:25:30.365556 [debug] [MainThread]: Parsing macros\adapters\indexes.sql
08:25:30.372565 [debug] [MainThread]: Parsing macros\adapters\metadata.sql
08:25:30.372565 [debug] [MainThread]: Parsing macros\adapters\persist_docs.sql
08:25:30.372565 [debug] [MainThread]: Parsing macros\adapters\relation.sql
08:25:30.390338 [debug] [MainThread]: Parsing macros\adapters\schema.sql
08:25:30.390338 [debug] [MainThread]: Parsing macros\etc\datetime.sql
08:25:30.390338 [debug] [MainThread]: Parsing macros\etc\statement.sql
08:25:30.390338 [debug] [MainThread]: Parsing macros\generic_test_sql\accepted_values.sql
08:25:30.390338 [debug] [MainThread]: Parsing macros\generic_test_sql\not_null.sql
08:25:30.390338 [debug] [MainThread]: Parsing macros\generic_test_sql\relationships.sql
08:25:30.390338 [debug] [MainThread]: Parsing macros\generic_test_sql\unique.sql
08:25:30.390338 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_alias.sql
08:25:30.404441 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_database.sql
08:25:30.404441 [debug] [MainThread]: Parsing macros\get_custom_name\get_custom_schema.sql
08:25:30.404441 [debug] [MainThread]: Parsing macros\materializations\configs.sql
08:25:30.404441 [debug] [MainThread]: Parsing macros\materializations\hooks.sql
08:25:30.404441 [debug] [MainThread]: Parsing macros\materializations\models\incremental\column_helpers.sql
08:25:30.404441 [debug] [MainThread]: Parsing macros\materializations\models\incremental\incremental.sql
08:25:30.420803 [debug] [MainThread]: Parsing macros\materializations\models\incremental\is_incremental.sql
08:25:30.420803 [debug] [MainThread]: Parsing macros\materializations\models\incremental\merge.sql
08:25:30.420803 [debug] [MainThread]: Parsing macros\materializations\models\incremental\on_schema_change.sql
08:25:30.435894 [debug] [MainThread]: Parsing macros\materializations\models\table\create_table_as.sql
08:25:30.435894 [debug] [MainThread]: Parsing macros\materializations\models\table\table.sql
08:25:30.435894 [debug] [MainThread]: Parsing macros\materializations\models\view\create_or_replace_view.sql
08:25:30.435894 [debug] [MainThread]: Parsing macros\materializations\models\view\create_view_as.sql
08:25:30.451527 [debug] [MainThread]: Parsing macros\materializations\models\view\helpers.sql
08:25:30.451527 [debug] [MainThread]: Parsing macros\materializations\models\view\view.sql
08:25:30.451527 [debug] [MainThread]: Parsing macros\materializations\seeds\helpers.sql
08:25:30.467727 [debug] [MainThread]: Parsing macros\materializations\seeds\seed.sql
08:25:30.467727 [debug] [MainThread]: Parsing macros\materializations\snapshots\helpers.sql
08:25:30.467727 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot.sql
08:25:30.483449 [debug] [MainThread]: Parsing macros\materializations\snapshots\snapshot_merge.sql
08:25:30.483449 [debug] [MainThread]: Parsing macros\materializations\snapshots\strategies.sql
08:25:30.499063 [debug] [MainThread]: Parsing macros\materializations\tests\helpers.sql
08:25:30.499063 [debug] [MainThread]: Parsing macros\materializations\tests\test.sql
08:25:30.499063 [debug] [MainThread]: Parsing macros\materializations\tests\where_subquery.sql
08:25:30.499063 [debug] [MainThread]: Parsing tests\generic\builtin.sql
08:25:30.656314 [debug] [MainThread]: 1699: static parser successfully parsed example\my_first_dbt_model.sql
08:25:30.665689 [debug] [MainThread]: 1699: static parser successfully parsed example\my_second_dbt_model.sql
08:25:30.665689 [debug] [MainThread]: 1699: static parser successfully parsed example_1\my_first_dbt_model_1.sql
08:25:30.665689 [debug] [MainThread]: 1699: static parser successfully parsed example_1\my_second_dbt_model_1.sql
08:25:30.703617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c4454bce-260f-4553-a4f0-f1eadb250885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8E82A05B0>]}
08:25:30.703617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c4454bce-260f-4553-a4f0-f1eadb250885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8E830E170>]}
08:25:30.703617 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 0 sources, 0 exposures, 0 metrics
08:25:30.703617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c4454bce-260f-4553-a4f0-f1eadb250885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8E830E080>]}
08:25:30.703617 [info ] [MainThread]: 
08:25:30.703617 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:25:30.703617 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
08:25:30.703617 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:25:31.476464 [debug] [ThreadPool]: Acquiring new bigquery connection "create_data-analytics-engineer_bigquery_example_dbt_1"
08:25:31.476464 [debug] [ThreadPool]: Acquiring new bigquery connection "create_data-analytics-engineer_bigquery_example_dbt_1"
08:25:31.476464 [debug] [ThreadPool]: BigQuery adapter: Creating schema "data-analytics-engineer.bigquery_example_dbt_1".
08:25:31.476464 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:25:32.513331 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
08:25:32.513331 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:25:33.289439 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt_1"
08:25:33.289439 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:25:34.013551 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c4454bce-260f-4553-a4f0-f1eadb250885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8E82A2170>]}
08:25:34.013551 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:25:34.029157 [info ] [MainThread]: 
08:25:34.032608 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_first_dbt_model_1
08:25:34.032608 [info ] [Thread-1 (]: 1 of 1 START table model bigquery_example_dbt_1.my_first_dbt_model_1 ........... [RUN]
08:25:34.032608 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_first_dbt_model_1"
08:25:34.032608 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_first_dbt_model_1
08:25:34.032608 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_first_dbt_model_1
08:25:34.032608 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model_1"
08:25:34.032608 [debug] [Thread-1 (]: finished collecting timing info
08:25:34.032608 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_first_dbt_model_1
08:25:34.077936 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model_1"
08:25:34.077936 [debug] [Thread-1 (]: Opening a new connection, currently in state init
08:25:34.077936 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_first_dbt_model_1: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_first_dbt_model_1"} */


  create or replace table `data-analytics-engineer`.`bigquery_example_dbt_1`.`my_first_dbt_model_1`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
08:25:37.326024 [debug] [Thread-1 (]: finished collecting timing info
08:25:37.326024 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c4454bce-260f-4553-a4f0-f1eadb250885', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8E836F520>]}
08:25:37.326024 [info ] [Thread-1 (]: 1 of 1 OK created table model bigquery_example_dbt_1.my_first_dbt_model_1 ...... [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 3.29s]
08:25:37.326024 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_first_dbt_model_1
08:25:37.326024 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:25:37.326024 [info ] [MainThread]: 
08:25:37.326024 [info ] [MainThread]: Finished running 1 table model in 6.62s.
08:25:37.326024 [debug] [MainThread]: Connection 'master' was properly closed.
08:25:37.326024 [debug] [MainThread]: Connection 'create_data-analytics-engineer_bigquery_example_dbt_1' was properly closed.
08:25:37.326024 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt_1' was properly closed.
08:25:37.326024 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_first_dbt_model_1' was properly closed.
08:25:37.334642 [info ] [MainThread]: 
08:25:37.334642 [info ] [MainThread]: [32mCompleted successfully[0m
08:25:37.334642 [info ] [MainThread]: 
08:25:37.334642 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
08:25:37.334642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8E82A2DA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8E82A1270>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D8E82A3C70>]}


============================== 2023-02-18 08:30:00.281351 | b8a0a527-d8d3-4ad0-b695-940e7d8e0961 ==============================
08:30:00.281351 [info ] [MainThread]: Running with dbt=1.1.0
08:30:00.281351 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['my_second_dbt_model_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:30:00.281351 [debug] [MainThread]: Tracking: tracking
08:30:00.302018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFB547EEC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFB547D4E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFB547E290>]}
08:30:00.348966 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:30:00.351512 [debug] [MainThread]: Partial parsing: updated file: data_warehouse_analytics_engineer://models\example_1\my_second_dbt_model_1.sql
08:30:00.351512 [debug] [MainThread]: 1699: static parser successfully parsed example_1\my_second_dbt_model_1.sql
08:30:00.383925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b8a0a527-d8d3-4ad0-b695-940e7d8e0961', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFB55F00D0>]}
08:30:00.383925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b8a0a527-d8d3-4ad0-b695-940e7d8e0961', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFB559E230>]}
08:30:00.383925 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 0 sources, 0 exposures, 0 metrics
08:30:00.392436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b8a0a527-d8d3-4ad0-b695-940e7d8e0961', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFB5483FD0>]}
08:30:00.392436 [info ] [MainThread]: 
08:30:00.392436 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:30:00.396450 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
08:30:00.396450 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:30:01.338340 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt_1"
08:30:01.338340 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:30:02.057677 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
08:30:02.057677 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:30:02.787125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b8a0a527-d8d3-4ad0-b695-940e7d8e0961', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFB559EBF0>]}
08:30:02.787125 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:30:02.787125 [info ] [MainThread]: 
08:30:02.787125 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:30:02.787125 [info ] [Thread-1 (]: 1 of 1 START view model bigquery_example_dbt_1.my_second_dbt_model_1 ........... [RUN]
08:30:02.802773 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:30:02.802773 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:30:02.803841 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:30:02.803841 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:30:02.803841 [debug] [Thread-1 (]: finished collecting timing info
08:30:02.803841 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:30:02.818851 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:30:02.818851 [debug] [Thread-1 (]: Opening a new connection, currently in state init
08:30:02.818851 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_second_dbt_model_1: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt_1`.`my_second_dbt_model_1`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_example_dbt`.`vn_provinces`
where id = 1;


08:30:04.395357 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: id at [10:7]')
08:30:05.983766 [debug] [Thread-1 (]: finished collecting timing info
08:30:05.983766 [debug] [Thread-1 (]: Database Error in model my_second_dbt_model_1 (models\example_1\my_second_dbt_model_1.sql)
  Unrecognized name: id at [10:7]
  compiled SQL at target\run\data_warehouse_analytics_engineer\models\example_1\my_second_dbt_model_1.sql
08:30:05.983766 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b8a0a527-d8d3-4ad0-b695-940e7d8e0961', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFB568FE50>]}
08:30:05.983766 [error] [Thread-1 (]: 1 of 1 ERROR creating view model bigquery_example_dbt_1.my_second_dbt_model_1 .. [[31mERROR[0m in 3.18s]
08:30:05.983766 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:30:05.983766 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:30:05.983766 [info ] [MainThread]: 
08:30:05.983766 [info ] [MainThread]: Finished running 1 view model in 5.59s.
08:30:05.983766 [debug] [MainThread]: Connection 'master' was properly closed.
08:30:05.999375 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
08:30:05.999375 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt' was properly closed.
08:30:05.999375 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_second_dbt_model_1' was properly closed.
08:30:05.999375 [info ] [MainThread]: 
08:30:05.999375 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:30:05.999375 [info ] [MainThread]: 
08:30:05.999375 [error] [MainThread]: [33mDatabase Error in model my_second_dbt_model_1 (models\example_1\my_second_dbt_model_1.sql)[0m
08:30:05.999375 [error] [MainThread]:   Unrecognized name: id at [10:7]
08:30:05.999375 [error] [MainThread]:   compiled SQL at target\run\data_warehouse_analytics_engineer\models\example_1\my_second_dbt_model_1.sql
08:30:05.999375 [info ] [MainThread]: 
08:30:05.999375 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
08:30:05.999375 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFB547F4C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFB559DDB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001DFB5591270>]}


============================== 2023-02-18 08:31:33.778900 | 28e8d4c3-a035-409a-8aa4-bff5c2c388e0 ==============================
08:31:33.778900 [info ] [MainThread]: Running with dbt=1.1.0
08:31:33.779847 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['my_second_dbt_model_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:31:33.779847 [debug] [MainThread]: Tracking: tracking
08:31:33.806473 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B17502470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B17502200>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B175017E0>]}
08:31:33.842755 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:31:33.843727 [debug] [MainThread]: Partial parsing: updated file: data_warehouse_analytics_engineer://models\example_1\my_second_dbt_model_1.sql
08:31:33.850727 [debug] [MainThread]: 1699: static parser successfully parsed example_1\my_second_dbt_model_1.sql
08:31:33.866286 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '28e8d4c3-a035-409a-8aa4-bff5c2c388e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B176A00D0>]}
08:31:33.871514 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '28e8d4c3-a035-409a-8aa4-bff5c2c388e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1764F0A0>]}
08:31:33.871514 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 0 sources, 0 exposures, 0 metrics
08:31:33.872509 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '28e8d4c3-a035-409a-8aa4-bff5c2c388e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1764E980>]}
08:31:33.873512 [info ] [MainThread]: 
08:31:33.874517 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:31:33.876023 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
08:31:33.876023 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:31:34.640528 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
08:31:34.641527 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:31:35.397467 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt_1"
08:31:35.397986 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:31:36.129081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '28e8d4c3-a035-409a-8aa4-bff5c2c388e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1764F7C0>]}
08:31:36.130082 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:31:36.131169 [info ] [MainThread]: 
08:31:36.141127 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:31:36.142127 [info ] [Thread-1 (]: 1 of 1 START view model bigquery_example_dbt_1.my_second_dbt_model_1 ........... [RUN]
08:31:36.143132 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:31:36.143132 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:31:36.144128 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:31:36.146125 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:31:36.147126 [debug] [Thread-1 (]: finished collecting timing info
08:31:36.147126 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:31:36.166125 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:31:36.166125 [debug] [Thread-1 (]: Opening a new connection, currently in state init
08:31:36.167125 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_second_dbt_model_1: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt_1`.`my_second_dbt_model_1`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_example_dbt_1`.`my_first_dbt_model_1`
where id = 1;


08:31:37.785850 [debug] [Thread-1 (]: finished collecting timing info
08:31:37.785850 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '28e8d4c3-a035-409a-8aa4-bff5c2c388e0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1764F820>]}
08:31:37.786854 [info ] [Thread-1 (]: 1 of 1 OK created view model bigquery_example_dbt_1.my_second_dbt_model_1 ...... [[32mOK[0m in 1.64s]
08:31:37.787610 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:31:37.788132 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:31:37.789172 [info ] [MainThread]: 
08:31:37.789639 [info ] [MainThread]: Finished running 1 view model in 3.91s.
08:31:37.790116 [debug] [MainThread]: Connection 'master' was properly closed.
08:31:37.790116 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
08:31:37.790116 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt_1' was properly closed.
08:31:37.790116 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_second_dbt_model_1' was properly closed.
08:31:37.793122 [info ] [MainThread]: 
08:31:37.794122 [info ] [MainThread]: [32mCompleted successfully[0m
08:31:37.794122 [info ] [MainThread]: 
08:31:37.795444 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
08:31:37.795444 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1764EB00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B1764FE20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000021B176411B0>]}


============================== 2023-02-18 08:33:26.711603 | 0dd17a22-11d1-4633-94f1-9381dec04152 ==============================
08:33:26.711603 [info ] [MainThread]: Running with dbt=1.1.0
08:33:26.711603 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['my_second_dbt_model_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:33:26.711603 [debug] [MainThread]: Tracking: tracking
08:33:26.727384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D6BC61F7C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D6BC61E2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D6BC61E290>]}
08:33:26.774401 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:33:26.774401 [debug] [MainThread]: Partial parsing: updated file: data_warehouse_analytics_engineer://models\example_1\my_second_dbt_model_1.sql
08:33:26.774401 [debug] [MainThread]: 1699: static parser successfully parsed example_1\my_second_dbt_model_1.sql
08:33:26.790032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0dd17a22-11d1-4633-94f1-9381dec04152', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D6BC7900D0>]}
08:33:26.790032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0dd17a22-11d1-4633-94f1-9381dec04152', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D6BC73F190>]}
08:33:26.790032 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 0 sources, 0 exposures, 0 metrics
08:33:26.790032 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0dd17a22-11d1-4633-94f1-9381dec04152', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D6BC623FD0>]}
08:33:26.790032 [info ] [MainThread]: 
08:33:26.790032 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:33:26.805663 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
08:33:26.805663 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:33:27.655184 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt_1"
08:33:27.655184 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:33:28.378381 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
08:33:28.378381 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:33:29.109191 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0dd17a22-11d1-4633-94f1-9381dec04152', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D6BC73F2B0>]}
08:33:29.109191 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:33:29.109191 [info ] [MainThread]: 
08:33:29.118205 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:33:29.118205 [info ] [Thread-1 (]: 1 of 1 START view model bigquery_example_dbt_1.my_second_dbt_model_1 ........... [RUN]
08:33:29.118205 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:33:29.118205 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:33:29.118205 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:33:29.118205 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:33:29.118205 [debug] [Thread-1 (]: finished collecting timing info
08:33:29.118205 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:33:29.149909 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:33:29.149909 [debug] [Thread-1 (]: Opening a new connection, currently in state init
08:33:29.149909 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_second_dbt_model_1: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt_1`.`my_second_dbt_model_1`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_example_dbt`.`vn_provinces`
where id = 1;


08:33:30.676240 [debug] [Thread-1 (]: BigQuery adapter: Retry attempt 1 of 1 after error: BadRequest('Unrecognized name: id at [10:7]')
08:33:32.547878 [debug] [Thread-1 (]: finished collecting timing info
08:33:32.547878 [debug] [Thread-1 (]: Database Error in model my_second_dbt_model_1 (models\example_1\my_second_dbt_model_1.sql)
  Unrecognized name: id at [10:7]
  compiled SQL at target\run\data_warehouse_analytics_engineer\models\example_1\my_second_dbt_model_1.sql
08:33:32.547878 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0dd17a22-11d1-4633-94f1-9381dec04152', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D6BC833E50>]}
08:33:32.547878 [error] [Thread-1 (]: 1 of 1 ERROR creating view model bigquery_example_dbt_1.my_second_dbt_model_1 .. [[31mERROR[0m in 3.43s]
08:33:32.547878 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:33:32.547878 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:33:32.547878 [info ] [MainThread]: 
08:33:32.547878 [info ] [MainThread]: Finished running 1 view model in 5.76s.
08:33:32.547878 [debug] [MainThread]: Connection 'master' was properly closed.
08:33:32.547878 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
08:33:32.547878 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt' was properly closed.
08:33:32.547878 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_second_dbt_model_1' was properly closed.
08:33:32.560972 [info ] [MainThread]: 
08:33:32.560972 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
08:33:32.564013 [info ] [MainThread]: 
08:33:32.564013 [error] [MainThread]: [33mDatabase Error in model my_second_dbt_model_1 (models\example_1\my_second_dbt_model_1.sql)[0m
08:33:32.564013 [error] [MainThread]:   Unrecognized name: id at [10:7]
08:33:32.564013 [error] [MainThread]:   compiled SQL at target\run\data_warehouse_analytics_engineer\models\example_1\my_second_dbt_model_1.sql
08:33:32.564013 [info ] [MainThread]: 
08:33:32.564013 [info ] [MainThread]: Done. PASS=0 WARN=0 ERROR=1 SKIP=0 TOTAL=1
08:33:32.564013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D6BC61F4C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D6BC73E9B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002D6BC731F00>]}


============================== 2023-02-18 08:34:18.221332 | 62151b2f-3de9-4a68-ae96-ba41b754dc62 ==============================
08:34:18.221332 [info ] [MainThread]: Running with dbt=1.1.0
08:34:18.221332 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['my_second_dbt_model_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:34:18.221332 [debug] [MainThread]: Tracking: tracking
08:34:18.253096 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022980FEEEF0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022980FEE2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022980FEE290>]}
08:34:18.284448 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:34:18.284448 [debug] [MainThread]: Partial parsing: updated file: data_warehouse_analytics_engineer://models\example_1\my_second_dbt_model_1.sql
08:34:18.300095 [debug] [MainThread]: 1699: static parser successfully parsed example_1\my_second_dbt_model_1.sql
08:34:18.300095 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '62151b2f-3de9-4a68-ae96-ba41b754dc62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229811600D0>]}
08:34:18.315692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '62151b2f-3de9-4a68-ae96-ba41b754dc62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229811095A0>]}
08:34:18.315692 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 0 sources, 0 exposures, 0 metrics
08:34:18.315692 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62151b2f-3de9-4a68-ae96-ba41b754dc62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022980FF3D00>]}
08:34:18.315692 [info ] [MainThread]: 
08:34:18.315692 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:34:18.315692 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
08:34:18.315692 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:34:19.071636 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
08:34:19.071636 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:34:19.827368 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt_1"
08:34:19.827368 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:34:20.582429 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '62151b2f-3de9-4a68-ae96-ba41b754dc62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002298110B5E0>]}
08:34:20.582429 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:34:20.582429 [info ] [MainThread]: 
08:34:20.582429 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:34:20.582429 [info ] [Thread-1 (]: 1 of 1 START view model bigquery_example_dbt_1.my_second_dbt_model_1 ........... [RUN]
08:34:20.582429 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:34:20.582429 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:34:20.582429 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:34:20.582429 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:34:20.582429 [debug] [Thread-1 (]: finished collecting timing info
08:34:20.582429 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:34:20.613752 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:34:20.613752 [debug] [Thread-1 (]: Opening a new connection, currently in state init
08:34:20.613752 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_second_dbt_model_1: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt_1`.`my_second_dbt_model_1`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_example_dbt`.`vn_provinces`
LIMIT 10;


08:34:22.250299 [debug] [Thread-1 (]: finished collecting timing info
08:34:22.250299 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '62151b2f-3de9-4a68-ae96-ba41b754dc62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002298110ADD0>]}
08:34:22.250299 [info ] [Thread-1 (]: 1 of 1 OK created view model bigquery_example_dbt_1.my_second_dbt_model_1 ...... [[32mOK[0m in 1.67s]
08:34:22.250299 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:34:22.250299 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:34:22.250299 [info ] [MainThread]: 
08:34:22.250299 [info ] [MainThread]: Finished running 1 view model in 3.93s.
08:34:22.250299 [debug] [MainThread]: Connection 'master' was properly closed.
08:34:22.250299 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
08:34:22.250299 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt_1' was properly closed.
08:34:22.250299 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_second_dbt_model_1' was properly closed.
08:34:22.250299 [info ] [MainThread]: 
08:34:22.250299 [info ] [MainThread]: [32mCompleted successfully[0m
08:34:22.250299 [info ] [MainThread]: 
08:34:22.250299 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
08:34:22.250299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000022980FEF4C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229810FD870>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000229810FD6C0>]}


============================== 2023-02-18 08:50:20.257237 | 40984e93-46b1-4a03-877c-15aa44741a0d ==============================
08:50:20.257237 [info ] [MainThread]: Running with dbt=1.1.0
08:50:20.257237 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['my_second_dbt_model_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:50:20.257237 [debug] [MainThread]: Tracking: tracking
08:50:20.272693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002352F9ACAC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002352F9AECB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002352F9AF4F0>]}
08:50:20.334000 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
08:50:20.334000 [debug] [MainThread]: Partial parsing: updated file: data_warehouse_analytics_engineer://models\example_1\my_second_dbt_model_1.sql
08:50:20.351014 [debug] [MainThread]: 1699: static parser successfully parsed example_1\my_second_dbt_model_1.sql
08:50:20.365524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '40984e93-46b1-4a03-877c-15aa44741a0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002352FB500D0>]}
08:50:20.365524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '40984e93-46b1-4a03-877c-15aa44741a0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002352FAFF910>]}
08:50:20.365524 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 0 sources, 0 exposures, 0 metrics
08:50:20.365524 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '40984e93-46b1-4a03-877c-15aa44741a0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002352FAB77C0>]}
08:50:20.365524 [info ] [MainThread]: 
08:50:20.365524 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:50:20.365524 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
08:50:20.365524 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:50:21.220098 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
08:50:21.220098 [debug] [ThreadPool]: Opening a new connection, currently in state init
08:50:21.959834 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt_1"
08:50:21.959834 [debug] [ThreadPool]: Opening a new connection, currently in state closed
08:50:22.676708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '40984e93-46b1-4a03-877c-15aa44741a0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002352FAFECB0>]}
08:50:22.676708 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
08:50:22.676708 [info ] [MainThread]: 
08:50:22.693561 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:50:22.693561 [info ] [Thread-1 (]: 1 of 1 START table model bigquery_example_dbt_1.my_second_dbt_model_1 .......... [RUN]
08:50:22.693561 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:50:22.693561 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:50:22.693561 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:50:22.693561 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:50:22.693561 [debug] [Thread-1 (]: finished collecting timing info
08:50:22.693561 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:50:22.708772 [debug] [Thread-1 (]: Opening a new connection, currently in state init
08:50:23.809798 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
08:50:23.809798 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_second_dbt_model_1: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"} */


  create or replace table `data-analytics-engineer`.`bigquery_example_dbt_1`.`my_second_dbt_model_1`
  
  
  OPTIONS()
  as (
    
-- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_example_dbt`.`vn_provinces`
LIMIT 10
  );
  
08:50:26.445263 [debug] [Thread-1 (]: finished collecting timing info
08:50:26.445263 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '40984e93-46b1-4a03-877c-15aa44741a0d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002352FAFD960>]}
08:50:26.445263 [info ] [Thread-1 (]: 1 of 1 OK created table model bigquery_example_dbt_1.my_second_dbt_model_1 ..... [[32mCREATE TABLE (10.0 rows, 38.0 KB processed)[0m in 3.75s]
08:50:26.445263 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
08:50:26.445263 [debug] [MainThread]: Acquiring new bigquery connection "master"
08:50:26.448809 [info ] [MainThread]: 
08:50:26.448809 [info ] [MainThread]: Finished running 1 table model in 6.08s.
08:50:26.448809 [debug] [MainThread]: Connection 'master' was properly closed.
08:50:26.448809 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
08:50:26.448809 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt_1' was properly closed.
08:50:26.448809 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_second_dbt_model_1' was properly closed.
08:50:26.453855 [info ] [MainThread]: 
08:50:26.453855 [info ] [MainThread]: [32mCompleted successfully[0m
08:50:26.453855 [info ] [MainThread]: 
08:50:26.453855 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
08:50:26.453855 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002352F9AEFB0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002352B5A46D0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002352FAF1A50>]}


============================== 2023-02-18 08:59:59.812673 | f4d16b65-1e13-4b35-83f9-487efc021798 ==============================
08:59:59.812673 [info ] [MainThread]: Running with dbt=1.1.0
08:59:59.813714 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['my_second_dbt_model_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
08:59:59.814232 [debug] [MainThread]: Tracking: tracking
08:59:59.841727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F82586EEC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F82586D690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F82586E290>]}
08:59:59.882970 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
08:59:59.883506 [debug] [MainThread]: Partial parsing: added file: data_warehouse_analytics_engineer://models\sources\bigquery_change_data_capture_example.yml
08:59:59.884051 [debug] [MainThread]: Partial parsing: updated file: data_warehouse_analytics_engineer://models\example_1\my_second_dbt_model_1.sql
08:59:59.887174 [debug] [MainThread]: 1699: static parser successfully parsed example_1\my_second_dbt_model_1.sql
08:59:59.902905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F8259933A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F8259E7C40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001F8259E6FE0>]}


============================== 2023-02-18 09:00:58.021686 | 3fd50bde-fab0-43b6-9424-e8d855cc204a ==============================
09:00:58.021686 [info ] [MainThread]: Running with dbt=1.1.0
09:00:58.021686 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['my_second_dbt_model_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
09:00:58.021686 [debug] [MainThread]: Tracking: tracking
09:00:58.048602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017DE3F9F340>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017DE3F9F9A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017DE3F9CFA0>]}
09:00:58.095978 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 1 files changed.
09:00:58.097211 [debug] [MainThread]: Partial parsing: added file: data_warehouse_analytics_engineer://models\sources\bigquery_change_data_capture_example.yml
09:00:58.097735 [debug] [MainThread]: Partial parsing: updated file: data_warehouse_analytics_engineer://models\example_1\my_second_dbt_model_1.sql
09:00:58.109295 [debug] [MainThread]: 1699: static parser successfully parsed example_1\my_second_dbt_model_1.sql
09:00:58.126338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3fd50bde-fab0-43b6-9424-e8d855cc204a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017DE40D3D60>]}
09:00:58.135856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3fd50bde-fab0-43b6-9424-e8d855cc204a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017DE40B7C70>]}
09:00:58.135856 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
09:00:58.135856 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3fd50bde-fab0-43b6-9424-e8d855cc204a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017DE40B4070>]}
09:00:58.135856 [info ] [MainThread]: 
09:00:58.135856 [debug] [MainThread]: Acquiring new bigquery connection "master"
09:00:58.141865 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
09:00:58.141865 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:00:58.974336 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
09:00:58.989350 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:00:59.711982 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt_1"
09:00:59.711982 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:01:00.480337 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3fd50bde-fab0-43b6-9424-e8d855cc204a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017DE3FB2E90>]}
09:01:00.480337 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:01:00.480337 [info ] [MainThread]: 
09:01:00.480337 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
09:01:00.480337 [info ] [Thread-1 (]: 1 of 1 START table model bigquery_example_dbt_1.my_second_dbt_model_1 .......... [RUN]
09:01:00.480337 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
09:01:00.480337 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
09:01:00.480337 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model_1
09:01:00.480337 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
09:01:00.480337 [debug] [Thread-1 (]: finished collecting timing info
09:01:00.495960 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
09:01:00.504974 [debug] [Thread-1 (]: Opening a new connection, currently in state init
09:01:01.252882 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
09:01:01.252882 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_second_dbt_model_1: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"} */


  create or replace table `data-analytics-engineer`.`bigquery_example_dbt_1`.`my_second_dbt_model_1`
  
  
  OPTIONS()
  as (
    
-- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_change_data_capture_example`.`order_items_delta`
LIMIT 10
  );
  
09:01:04.408135 [debug] [Thread-1 (]: finished collecting timing info
09:01:04.408135 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3fd50bde-fab0-43b6-9424-e8d855cc204a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017DE40B7940>]}
09:01:04.408135 [info ] [Thread-1 (]: 1 of 1 OK created table model bigquery_example_dbt_1.my_second_dbt_model_1 ..... [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 3.93s]
09:01:04.408135 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
09:01:04.408135 [debug] [MainThread]: Acquiring new bigquery connection "master"
09:01:04.408135 [info ] [MainThread]: 
09:01:04.408135 [info ] [MainThread]: Finished running 1 table model in 6.27s.
09:01:04.408135 [debug] [MainThread]: Connection 'master' was properly closed.
09:01:04.408135 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
09:01:04.408135 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt_1' was properly closed.
09:01:04.408135 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_second_dbt_model_1' was properly closed.
09:01:04.455004 [info ] [MainThread]: 
09:01:04.455004 [info ] [MainThread]: [32mCompleted successfully[0m
09:01:04.455004 [info ] [MainThread]: 
09:01:04.455004 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:01:04.455004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017DE35F12A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017DE3EDFD30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000017DE3EDFC40>]}


============================== 2023-02-18 09:03:13.849601 | 88b7be32-0cc4-42d6-9305-c8da613d434b ==============================
09:03:13.849601 [info ] [MainThread]: Running with dbt=1.1.0
09:03:13.850603 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'port': 8080, 'open_browser': True, 'which': 'serve', 'indirect_selection': 'eager'}
09:03:13.850603 [debug] [MainThread]: Tracking: tracking
09:03:13.875111 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BAE12FC7F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BAE12FE0B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001BAE12FD3F0>]}
09:03:13.972194 [info ] [MainThread]: Serving docs at 0.0.0.0:8080
09:03:13.972194 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:8080
09:03:13.972194 [info ] [MainThread]: 
09:03:13.972194 [info ] [MainThread]: 
09:03:13.972194 [info ] [MainThread]: Press Ctrl+C to exit.


============================== 2023-02-18 09:21:58.974074 | 50563d83-b830-4848-a239-899b668ae1cd ==============================
09:21:58.974074 [info ] [MainThread]: Running with dbt=1.1.0
09:21:58.974074 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'compile': True, 'which': 'generate', 'rpc_method': 'docs.generate', 'indirect_selection': 'eager'}
09:21:58.974074 [debug] [MainThread]: Tracking: tracking
09:21:59.004722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7FF81EEC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7FF81E0B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7FF81E290>]}
09:21:59.049200 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
09:21:59.051705 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
09:21:59.052764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '50563d83-b830-4848-a239-899b668ae1cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7FF9540D0>]}
09:21:59.052764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '50563d83-b830-4848-a239-899b668ae1cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7FF892D40>]}
09:21:59.052764 [info ] [MainThread]: Found 4 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
09:21:59.052764 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '50563d83-b830-4848-a239-899b668ae1cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7FF892E00>]}
09:21:59.065840 [info ] [MainThread]: 
09:21:59.065840 [debug] [MainThread]: Acquiring new bigquery connection "master"
09:21:59.067360 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt_1"
09:21:59.067360 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:21:59.887331 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
09:21:59.887331 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:22:00.612882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '50563d83-b830-4848-a239-899b668ae1cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7FF892A10>]}
09:22:00.612882 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:22:00.612882 [info ] [MainThread]: 
09:22:00.612882 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_first_dbt_model
09:22:00.612882 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_first_dbt_model"
09:22:00.612882 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_first_dbt_model
09:22:00.612882 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_first_dbt_model
09:22:00.612882 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
09:22:00.612882 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.612882 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_first_dbt_model
09:22:00.612882 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.612882 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_first_dbt_model
09:22:00.612882 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_first_dbt_model_1
09:22:00.612882 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_first_dbt_model_1"
09:22:00.612882 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_first_dbt_model_1
09:22:00.628517 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_first_dbt_model_1
09:22:00.628517 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model_1"
09:22:00.628517 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.628517 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_first_dbt_model_1
09:22:00.628517 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.628517 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_first_dbt_model_1
09:22:00.628517 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
09:22:00.628517 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
09:22:00.628517 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
09:22:00.628517 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model_1
09:22:00.628517 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model_1"
09:22:00.628517 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.628517 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
09:22:00.628517 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.628517 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model_1
09:22:00.628517 [debug] [Thread-1 (]: Began running node seed.data_warehouse_analytics_engineer.vn_provinces
09:22:00.628517 [debug] [Thread-1 (]: Acquiring new bigquery connection "seed.data_warehouse_analytics_engineer.vn_provinces"
09:22:00.628517 [debug] [Thread-1 (]: Began compiling node seed.data_warehouse_analytics_engineer.vn_provinces
09:22:00.628517 [debug] [Thread-1 (]: Compiling seed.data_warehouse_analytics_engineer.vn_provinces
09:22:00.628517 [debug] [Thread-1 (]: Writing injected SQL for node "seed.data_warehouse_analytics_engineer.vn_provinces"
09:22:00.628517 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.628517 [debug] [Thread-1 (]: Began executing node seed.data_warehouse_analytics_engineer.vn_provinces
09:22:00.628517 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.628517 [debug] [Thread-1 (]: Finished running node seed.data_warehouse_analytics_engineer.vn_provinces
09:22:00.628517 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model
09:22:00.628517 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model"
09:22:00.628517 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model
09:22:00.628517 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model
09:22:00.644145 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
09:22:00.644145 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.644145 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model
09:22:00.644145 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.644145 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model
09:22:00.644145 [debug] [Thread-1 (]: Began running node test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710
09:22:00.644145 [debug] [Thread-1 (]: Acquiring new bigquery connection "test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710"
09:22:00.644145 [debug] [Thread-1 (]: Began compiling node test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710
09:22:00.644145 [debug] [Thread-1 (]: Compiling test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710
09:22:00.644145 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710"
09:22:00.644145 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.644145 [debug] [Thread-1 (]: Began executing node test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710
09:22:00.644145 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.644145 [debug] [Thread-1 (]: Finished running node test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710
09:22:00.644145 [debug] [Thread-1 (]: Began running node test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321
09:22:00.644145 [debug] [Thread-1 (]: Acquiring new bigquery connection "test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321"
09:22:00.644145 [debug] [Thread-1 (]: Began compiling node test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321
09:22:00.644145 [debug] [Thread-1 (]: Compiling test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321
09:22:00.659850 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321"
09:22:00.659850 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.659850 [debug] [Thread-1 (]: Began executing node test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321
09:22:00.659850 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.659850 [debug] [Thread-1 (]: Finished running node test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321
09:22:00.659850 [debug] [Thread-1 (]: Began running node test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778
09:22:00.659850 [debug] [Thread-1 (]: Acquiring new bigquery connection "test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778"
09:22:00.659850 [debug] [Thread-1 (]: Began compiling node test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778
09:22:00.659850 [debug] [Thread-1 (]: Compiling test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778
09:22:00.659850 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778"
09:22:00.659850 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.659850 [debug] [Thread-1 (]: Began executing node test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778
09:22:00.659850 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.659850 [debug] [Thread-1 (]: Finished running node test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778
09:22:00.659850 [debug] [Thread-1 (]: Began running node test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493
09:22:00.659850 [debug] [Thread-1 (]: Acquiring new bigquery connection "test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493"
09:22:00.659850 [debug] [Thread-1 (]: Began compiling node test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493
09:22:00.659850 [debug] [Thread-1 (]: Compiling test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493
09:22:00.659850 [debug] [Thread-1 (]: Writing injected SQL for node "test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493"
09:22:00.659850 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.659850 [debug] [Thread-1 (]: Began executing node test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493
09:22:00.659850 [debug] [Thread-1 (]: finished collecting timing info
09:22:00.659850 [debug] [Thread-1 (]: Finished running node test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493
09:22:00.659850 [debug] [MainThread]: Connection 'master' was properly closed.
09:22:00.673358 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt' was properly closed.
09:22:00.673358 [debug] [MainThread]: Connection 'test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493' was properly closed.
09:22:00.678439 [info ] [MainThread]: Done.
09:22:00.680024 [debug] [MainThread]: Acquiring new bigquery connection "generate_catalog"
09:22:00.680024 [info ] [MainThread]: Building catalog
09:22:00.682353 [debug] [MainThread]: Opening a new connection, currently in state init
09:22:01.435426 [debug] [ThreadPool]: Acquiring new bigquery connection "data-analytics-engineer.information_schema"
09:22:01.447107 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:22:01.447681 [debug] [ThreadPool]: On data-analytics-engineer.information_schema: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "connection_name": "data-analytics-engineer.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `data-analytics-engineer`.`bigquery_example_dbt`.__TABLES__
        where (upper(dataset_id) = upper('bigquery_example_dbt'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `data-analytics-engineer`.`bigquery_example_dbt`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `data-analytics-engineer`.`bigquery_example_dbt`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
09:22:05.390303 [debug] [ThreadPool]: Acquiring new bigquery connection "data-analytics-engineer.information_schema"
09:22:05.439446 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:22:05.439446 [debug] [ThreadPool]: On data-analytics-engineer.information_schema: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "connection_name": "data-analytics-engineer.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `data-analytics-engineer`.`bigquery_example_dbt_1`.__TABLES__
        where (upper(dataset_id) = upper('bigquery_example_dbt_1'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `data-analytics-engineer`.`bigquery_example_dbt_1`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `data-analytics-engineer`.`bigquery_example_dbt_1`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
09:22:09.056817 [debug] [ThreadPool]: Acquiring new bigquery connection "data-analytics-engineer.information_schema"
09:22:09.056817 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:22:09.056817 [debug] [ThreadPool]: On data-analytics-engineer.information_schema: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "connection_name": "data-analytics-engineer.information_schema"} */

    with tables as (
        select
            project_id as table_database,
            dataset_id as table_schema,
            table_id as original_table_name,

            concat(project_id, '.', dataset_id, '.', table_id) as relation_id,

            row_count,
            size_bytes as size_bytes,
            case
                when type = 1 then 'table'
                when type = 2 then 'view'
                else 'external'
            end as table_type,

            REGEXP_CONTAINS(table_id, '^.+[0-9]{8}$') and coalesce(type, 0) = 1 as is_date_shard,
            REGEXP_EXTRACT(table_id, '^(.+)[0-9]{8}$') as shard_base_name,
            REGEXP_EXTRACT(table_id, '^.+([0-9]{8})$') as shard_name

        from `data-analytics-engineer`.`bigquery_change_data_capture_example`.__TABLES__
        where (upper(dataset_id) = upper('bigquery_change_data_capture_example'))
    ),

    extracted as (

        select *,
            case
                when is_date_shard then shard_base_name
                else original_table_name
            end as table_name

        from tables

    ),

    unsharded_tables as (

        select
            table_database,
            table_schema,
            table_name,
            coalesce(table_type, 'external') as table_type,
            is_date_shard,

            struct(
                min(shard_name) as shard_min,
                max(shard_name) as shard_max,
                count(*) as shard_count
            ) as table_shards,

            sum(size_bytes) as size_bytes,
            sum(row_count) as row_count,

            max(relation_id) as relation_id

        from extracted
        group by 1,2,3,4,5

    ),

    info_schema_columns as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            table_catalog as table_database,
            table_schema,
            table_name,

            -- use the "real" column name from the paths query below
            column_name as base_column_name,
            ordinal_position as column_index,

            is_partitioning_column,
            clustering_ordinal_position

        from `data-analytics-engineer`.`bigquery_change_data_capture_example`.INFORMATION_SCHEMA.COLUMNS
        where ordinal_position is not null

    ),

    info_schema_column_paths as (

        select
            concat(table_catalog, '.', table_schema, '.', table_name) as relation_id,
            field_path as column_name,
            data_type as column_type,
            column_name as base_column_name,
            description as column_comment

        from `data-analytics-engineer`.`bigquery_change_data_capture_example`.INFORMATION_SCHEMA.COLUMN_FIELD_PATHS

    ),

    columns as (

        select * except (base_column_name)
        from info_schema_columns
        join info_schema_column_paths using (relation_id, base_column_name)

    ),

    column_stats as (

        select
            table_database,
            table_schema,
            table_name,
            max(relation_id) as relation_id,
            max(case when is_partitioning_column = 'YES' then 1 else 0 end) = 1 as is_partitioned,
            max(case when is_partitioning_column = 'YES' then column_name else null end) as partition_column,
            max(case when clustering_ordinal_position is not null then 1 else 0 end) = 1 as is_clustered,
            array_to_string(
                array_agg(
                    case
                        when clustering_ordinal_position is not null then column_name
                        else null
                    end ignore nulls
                    order by clustering_ordinal_position
                ), ', '
            ) as clustering_columns

        from columns
        group by 1,2,3

    )

    select
        unsharded_tables.table_database,
        unsharded_tables.table_schema,
        case
            when is_date_shard then concat(unsharded_tables.table_name, '*')
            else unsharded_tables.table_name
        end as table_name,
        unsharded_tables.table_type,

        -- coalesce name and type for External tables - these columns are not
        -- present in the COLUMN_FIELD_PATHS resultset
        coalesce(columns.column_name, '<unknown>') as column_name,
        -- invent a row number to account for nested fields -- BQ does
        -- not treat these nested properties as independent fields
        row_number() over (
            partition by relation_id
            order by columns.column_index, columns.column_name
        ) as column_index,
        coalesce(columns.column_type, '<unknown>') as column_type,
        columns.column_comment,

        'Shard count' as `stats__date_shards__label`,
        table_shards.shard_count as `stats__date_shards__value`,
        'The number of date shards in this table' as `stats__date_shards__description`,
        is_date_shard as `stats__date_shards__include`,

        'Shard (min)' as `stats__date_shard_min__label`,
        table_shards.shard_min as `stats__date_shard_min__value`,
        'The first date shard in this table' as `stats__date_shard_min__description`,
        is_date_shard as `stats__date_shard_min__include`,

        'Shard (max)' as `stats__date_shard_max__label`,
        table_shards.shard_max as `stats__date_shard_max__value`,
        'The last date shard in this table' as `stats__date_shard_max__description`,
        is_date_shard as `stats__date_shard_max__include`,

        '# Rows' as `stats__num_rows__label`,
        row_count as `stats__num_rows__value`,
        'Approximate count of rows in this table' as `stats__num_rows__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_rows__include`,

        'Approximate Size' as `stats__num_bytes__label`,
        size_bytes as `stats__num_bytes__value`,
        'Approximate size of table as reported by BigQuery' as `stats__num_bytes__description`,
        (unsharded_tables.table_type = 'table') as `stats__num_bytes__include`,

        'Partitioned By' as `stats__partitioning_type__label`,
        partition_column as `stats__partitioning_type__value`,
        'The partitioning column for this table' as `stats__partitioning_type__description`,
        is_partitioned as `stats__partitioning_type__include`,

        'Clustered By' as `stats__clustering_fields__label`,
        clustering_columns as `stats__clustering_fields__value`,
        'The clustering columns for this table' as `stats__clustering_fields__description`,
        is_clustered as `stats__clustering_fields__include`

    -- join using relation_id (an actual relation, not a shard prefix) to make
    -- sure that column metadata is picked up through the join. This will only
    -- return the column information for the "max" table in a date-sharded table set
    from unsharded_tables
    left join columns using (relation_id)
    left join column_stats using (relation_id)
  
09:22:13.737385 [info ] [MainThread]: Catalog written to C:\Users\HP\Documents\Project\data-analytics-engineer-dbt\data_warehouse_analytics_engineer\target\catalog.json
09:22:13.737385 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7FF7FD720>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7FF7FE470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001D7FF7FDD20>]}
09:22:14.776073 [debug] [MainThread]: Connection 'generate_catalog' was properly closed.
09:22:14.776073 [debug] [MainThread]: Connection 'data-analytics-engineer.information_schema' was properly closed.


============================== 2023-02-18 09:22:36.851314 | 72665292-e1d5-446e-bb05-c1c36d018be8 ==============================
09:22:36.851314 [info ] [MainThread]: Running with dbt=1.1.0
09:22:36.851314 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'port': 8081, 'open_browser': True, 'which': 'serve', 'indirect_selection': 'eager'}
09:22:36.851314 [debug] [MainThread]: Tracking: tracking
09:22:36.877851 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FFADCC10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FFADFCA0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000191FFADE980>]}
09:22:36.877851 [info ] [MainThread]: Serving docs at 0.0.0.0:8081
09:22:36.877851 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:8081
09:22:36.877851 [info ] [MainThread]: 
09:22:36.877851 [info ] [MainThread]: 
09:22:36.877851 [info ] [MainThread]: Press Ctrl+C to exit.


============================== 2023-02-18 09:36:35.034711 | 1d294e98-a550-4569-aedd-129ea4fcae55 ==============================
09:36:35.034711 [info ] [MainThread]: Running with dbt=1.1.0
09:36:35.035713 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
09:36:35.035713 [debug] [MainThread]: Tracking: tracking
09:36:35.059683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002096671CAC0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002096671E2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002096671E290>]}
09:36:35.097210 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 5 files added, 0 files changed.
09:36:35.097210 [debug] [MainThread]: Partial parsing: added file: data_warehouse_analytics_engineer://models\dimension_models\product_dimension.sql
09:36:35.098218 [debug] [MainThread]: Partial parsing: added file: data_warehouse_analytics_engineer://models\dimension_models\product_dimension_type_1.sql
09:36:35.098218 [debug] [MainThread]: Partial parsing: added file: data_warehouse_analytics_engineer://models\dimension_models\sales_report.sql
09:36:35.098218 [debug] [MainThread]: Partial parsing: added file: data_warehouse_analytics_engineer://models\dimension_models\sales_periodic_fact.sql
09:36:35.098218 [debug] [MainThread]: Partial parsing: added file: data_warehouse_analytics_engineer://models\dimension_models\sales_transaction_fact.sql
09:36:35.113528 [debug] [MainThread]: 1603: static parser failed on dimension_models\product_dimension.sql
09:36:35.123625 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models\product_dimension.sql
09:36:35.125509 [debug] [MainThread]: 1603: static parser failed on dimension_models\product_dimension_type_1.sql
09:36:35.132507 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models\product_dimension_type_1.sql
09:36:35.133507 [debug] [MainThread]: 1603: static parser failed on dimension_models\sales_report.sql
09:36:35.137508 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models\sales_report.sql
09:36:35.137508 [debug] [MainThread]: 1603: static parser failed on dimension_models\sales_periodic_fact.sql
09:36:35.141508 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models\sales_periodic_fact.sql
09:36:35.142507 [debug] [MainThread]: 1603: static parser failed on dimension_models\sales_transaction_fact.sql
09:36:35.146509 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models\sales_transaction_fact.sql
09:36:35.154395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1d294e98-a550-4569-aedd-129ea4fcae55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000002096688E800>]}
09:36:35.158395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1d294e98-a550-4569-aedd-129ea4fcae55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020966807BB0>]}
09:36:35.158395 [info ] [MainThread]: Found 9 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
09:36:35.158395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1d294e98-a550-4569-aedd-129ea4fcae55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020966807CD0>]}
09:36:35.159398 [info ] [MainThread]: 
09:36:35.160398 [debug] [MainThread]: Acquiring new bigquery connection "master"
09:36:35.161403 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
09:36:35.161403 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:36:35.974514 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt_1"
09:36:35.974514 [debug] [ThreadPool]: Opening a new connection, currently in state init
09:36:36.712329 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
09:36:36.712329 [debug] [ThreadPool]: Opening a new connection, currently in state closed
09:36:37.463699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1d294e98-a550-4569-aedd-129ea4fcae55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209667C9750>]}
09:36:37.465399 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
09:36:37.465399 [info ] [MainThread]: 
09:36:37.471214 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.product_dimension
09:36:37.472214 [info ] [Thread-1 (]: 1 of 1 START incremental model bigquery_example_dbt.product_dimension .......... [RUN]
09:36:37.472214 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.product_dimension"
09:36:37.472214 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.product_dimension
09:36:37.473216 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.product_dimension
09:36:37.477736 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.product_dimension"
09:36:37.479235 [debug] [Thread-1 (]: finished collecting timing info
09:36:37.479235 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.product_dimension
09:36:37.571547 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.product_dimension"
09:36:37.572530 [debug] [Thread-1 (]: Opening a new connection, currently in state init
09:36:37.572530 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.product_dimension: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.product_dimension"} */


  create or replace table `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension`
  partition by TIMESTAMP_trunc(updated_at, DAY)
  
  OPTIONS()
  as (
    
    






SELECT id, brand, department, category, updated_at
FROM (
    SELECT id, brand, department, category, updated_at,
        ROW_NUMBER() OVER(PARTITION BY id ORDER BY updated_at DESC) AS row_num
    FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`products_delta`
    WHERE DATE(updated_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))
)
WHERE row_num = 1
  );
  
09:36:41.166063 [debug] [Thread-1 (]: finished collecting timing info
09:36:41.166063 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1d294e98-a550-4569-aedd-129ea4fcae55', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000020965D41240>]}
09:36:41.167079 [info ] [Thread-1 (]: 1 of 1 OK created incremental model bigquery_example_dbt.product_dimension ..... [[32mCREATE TABLE (0.0 rows, 44.0 Bytes processed)[0m in 3.69s]
09:36:41.167079 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.product_dimension
09:36:41.168655 [debug] [MainThread]: Acquiring new bigquery connection "master"
09:36:41.168655 [info ] [MainThread]: 
09:36:41.169661 [info ] [MainThread]: Finished running 1 incremental model in 6.01s.
09:36:41.169661 [debug] [MainThread]: Connection 'master' was properly closed.
09:36:41.170715 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
09:36:41.170715 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt' was properly closed.
09:36:41.170715 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.product_dimension' was properly closed.
09:36:41.177670 [info ] [MainThread]: 
09:36:41.178679 [info ] [MainThread]: [32mCompleted successfully[0m
09:36:41.178679 [info ] [MainThread]: 
09:36:41.178679 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
09:36:41.179910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209622F46A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209665FF370>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000209666A3AF0>]}


============================== 2023-02-18 13:52:45.579884 | fca478c6-dceb-4555-b627-e528f639aac4 ==============================
13:52:45.579884 [info ] [MainThread]: Running with dbt=1.1.0
13:52:45.580891 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['dimension_models'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
13:52:45.580891 [debug] [MainThread]: Tracking: tracking
13:52:45.601492 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20C11540>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20C13160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20C115A0>]}
13:52:45.715060 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
13:52:45.715060 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
13:52:45.725150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fca478c6-dceb-4555-b627-e528f639aac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20D93F40>]}
13:52:45.731693 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fca478c6-dceb-4555-b627-e528f639aac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20D5C2B0>]}
13:52:45.733200 [info ] [MainThread]: Found 9 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
13:52:45.733200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fca478c6-dceb-4555-b627-e528f639aac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20D5C490>]}
13:52:45.735212 [info ] [MainThread]: 
13:52:45.736209 [debug] [MainThread]: Acquiring new bigquery connection "master"
13:52:45.737717 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
13:52:45.737717 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:52:47.332340 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
13:52:47.333333 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:52:48.090755 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt_1"
13:52:48.092759 [debug] [ThreadPool]: Opening a new connection, currently in state closed
13:52:48.829476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fca478c6-dceb-4555-b627-e528f639aac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20D429E0>]}
13:52:48.832040 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:52:48.833441 [info ] [MainThread]: 
13:52:48.854960 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.product_dimension
13:52:48.855959 [info ] [Thread-1 (]: 1 of 5 START incremental model bigquery_example_dbt.product_dimension .......... [RUN]
13:52:48.855959 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.product_dimension"
13:52:48.856957 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.product_dimension
13:52:48.856957 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.product_dimension
13:52:48.860042 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.product_dimension"
13:52:48.860959 [debug] [Thread-1 (]: finished collecting timing info
13:52:48.860959 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.product_dimension
13:52:48.889049 [debug] [Thread-1 (]: Opening a new connection, currently in state init
13:52:49.663876 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.product_dimension"
13:52:49.664790 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.product_dimension: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.product_dimension"} */


   

      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension` as DBT_INTERNAL_DEST
        using (
          
    






SELECT id, brand, department, category, updated_at
FROM (
    SELECT id, brand, department, category, updated_at,
        ROW_NUMBER() OVER(PARTITION BY id ORDER BY updated_at DESC) AS row_num
    FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`products_delta`
    WHERE DATE(updated_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))
)
WHERE row_num = 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and TIMESTAMP_trunc(DBT_INTERNAL_DEST.updated_at, DAY) in (
              TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`id`, `brand`, `department`, `category`, `updated_at`)
    values
        (`id`, `brand`, `department`, `category`, `updated_at`)



  


  
13:52:52.834136 [debug] [Thread-1 (]: finished collecting timing info
13:52:52.834136 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fca478c6-dceb-4555-b627-e528f639aac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20C10E50>]}
13:52:52.835244 [info ] [Thread-1 (]: 1 of 5 OK created incremental model bigquery_example_dbt.product_dimension ..... [[32mMERGE (0.0 rows, 44.0 Bytes processed)[0m in 3.98s]
13:52:52.835244 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.product_dimension
13:52:52.836153 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.product_dimension_type_1
13:52:52.836153 [info ] [Thread-1 (]: 2 of 5 START incremental model bigquery_example_dbt.product_dimension_type_1 ... [RUN]
13:52:52.837335 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.product_dimension_type_1"
13:52:52.837335 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.product_dimension_type_1
13:52:52.837335 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.product_dimension_type_1
13:52:52.842341 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.product_dimension_type_1"
13:52:52.843342 [debug] [Thread-1 (]: finished collecting timing info
13:52:52.843342 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.product_dimension_type_1
13:52:52.854342 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.product_dimension_type_1"
13:52:52.855341 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
13:52:52.855341 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.product_dimension_type_1: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.product_dimension_type_1"} */


  create or replace table `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension_type_1`
  partition by TIMESTAMP_trunc(updated_at, DAY)
  
  OPTIONS()
  as (
    

SELECT id, brand, department, category, updated_at
FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`products_main`
WHERE

    DATE(updated_at) >= "2022-01-01"

  );
  
13:52:56.613978 [debug] [Thread-1 (]: finished collecting timing info
13:52:56.614981 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fca478c6-dceb-4555-b627-e528f639aac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20E1AAA0>]}
13:52:56.614981 [info ] [Thread-1 (]: 2 of 5 OK created incremental model bigquery_example_dbt.product_dimension_type_1  [[32mCREATE TABLE (29.1k rows, 1.3 MB processed)[0m in 3.78s]
13:52:56.616022 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.product_dimension_type_1
13:52:56.616022 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.sales_transaction_fact
13:52:56.616022 [info ] [Thread-1 (]: 3 of 5 START incremental model bigquery_example_dbt.sales_transaction_fact ..... [RUN]
13:52:56.617020 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_transaction_fact"
13:52:56.617020 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.sales_transaction_fact
13:52:56.617990 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.sales_transaction_fact
13:52:56.621661 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_transaction_fact"
13:52:56.628700 [debug] [Thread-1 (]: finished collecting timing info
13:52:56.629734 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.sales_transaction_fact
13:52:56.632790 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.sales_transaction_fact"
13:52:56.633715 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
13:52:56.634790 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.sales_transaction_fact: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_transaction_fact"} */


  create or replace table `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact`
  partition by TIMESTAMP_trunc(created_at, DAY)
  
  OPTIONS()
  as (
    
    






SELECT
    id,
    order_id,
    user_id,
    product_id,
    inventory_item_id,
    status,
    created_at,
    shipped_at,
    delivered_at,
    returned_at,
    sale_price
FROM (
    SELECT *, ROW_NUMBER() OVER(PARTITION BY id ORDER BY created_at DESC) AS row_num
    FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`order_items_delta`
    WHERE DATE(created_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))
)
WHERE row_num = 1
  );
  
13:53:00.236409 [debug] [Thread-1 (]: finished collecting timing info
13:53:00.237402 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fca478c6-dceb-4555-b627-e528f639aac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20D43610>]}
13:53:00.237402 [info ] [Thread-1 (]: 3 of 5 OK created incremental model bigquery_example_dbt.sales_transaction_fact  [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 3.62s]
13:53:00.238364 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.sales_transaction_fact
13:53:00.239805 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.sales_periodic_fact
13:53:00.239805 [info ] [Thread-1 (]: 4 of 5 START incremental model bigquery_example_dbt.sales_periodic_fact ........ [RUN]
13:53:00.240526 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_periodic_fact"
13:53:00.240526 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.sales_periodic_fact
13:53:00.240526 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.sales_periodic_fact
13:53:00.245103 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_periodic_fact"
13:53:00.246122 [debug] [Thread-1 (]: finished collecting timing info
13:53:00.246122 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.sales_periodic_fact
13:53:00.252521 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.sales_periodic_fact"
13:53:00.253119 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
13:53:00.254726 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.sales_periodic_fact: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_periodic_fact"} */


  create or replace table `data-analytics-engineer`.`bigquery_example_dbt`.`sales_periodic_fact`
  partition by transaction_date
  
  OPTIONS()
  as (
    
    







SELECT
  DATE(created_at) AS transaction_date,
  SUM(IF(returned_at IS NULL, sale_price, sale_price * -1)) AS total_sale
FROM `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact`
WHERE DATE(created_at) = DATE(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY))
GROUP BY 1
  );
  
13:53:03.593793 [debug] [Thread-1 (]: finished collecting timing info
13:53:03.594802 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fca478c6-dceb-4555-b627-e528f639aac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20EE5150>]}
13:53:03.594802 [info ] [Thread-1 (]: 4 of 5 OK created incremental model bigquery_example_dbt.sales_periodic_fact ... [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 3.35s]
13:53:03.595801 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.sales_periodic_fact
13:53:03.595801 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.sales_report
13:53:03.595801 [info ] [Thread-1 (]: 5 of 5 START incremental model bigquery_example_dbt.sales_report ............... [RUN]
13:53:03.596822 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_report"
13:53:03.596822 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.sales_report
13:53:03.596822 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.sales_report
13:53:03.631311 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_report"
13:53:03.632186 [debug] [Thread-1 (]: finished collecting timing info
13:53:03.632186 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.sales_report
13:53:03.634302 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.sales_report"
13:53:03.635236 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
13:53:03.636196 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.sales_report: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_report"} */


  create or replace table `data-analytics-engineer`.`bigquery_example_dbt`.`sales_report`
  partition by transaction_date
  
  OPTIONS()
  as (
    
    






WITH sales_transaction_data AS (
    SELECT *
    FROM `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact` sales_trans
    WHERE DATE(created_at) = DATE(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY))
)
SELECT DATE(created_at) AS transaction_date, category, brand, department, SUM(sale_price) AS total_sales
FROM (
 SELECT * EXCEPT(row_num)
 FROM (
   SELECT created_at, category, brand, department, sale_price,
   ROW_NUMBER() OVER(PARTITION BY sales_trans.id ORDER BY product_dim.updated_at DESC) AS row_num
   FROM sales_transaction_data sales_trans
     LEFT JOIN `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension` product_dim
       ON sales_trans.product_id = product_dim.id and sales_trans.created_at >= product_dim.updated_at
 )
 WHERE row_num = 1
)
GROUP BY transaction_date, category, brand, department
  );
  
13:53:07.530273 [debug] [Thread-1 (]: finished collecting timing info
13:53:07.531286 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fca478c6-dceb-4555-b627-e528f639aac4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF202D0670>]}
13:53:07.533240 [info ] [Thread-1 (]: 5 of 5 OK created incremental model bigquery_example_dbt.sales_report .......... [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 3.93s]
13:53:07.534189 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.sales_report
13:53:07.536189 [debug] [MainThread]: Acquiring new bigquery connection "master"
13:53:07.537188 [info ] [MainThread]: 
13:53:07.538186 [info ] [MainThread]: Finished running 5 incremental models in 21.80s.
13:53:07.538186 [debug] [MainThread]: Connection 'master' was properly closed.
13:53:07.539183 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
13:53:07.539183 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt_1' was properly closed.
13:53:07.539183 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_report' was properly closed.
13:53:07.544190 [info ] [MainThread]: 
13:53:07.544190 [info ] [MainThread]: [32mCompleted successfully[0m
13:53:07.545519 [info ] [MainThread]: 
13:53:07.545519 [info ] [MainThread]: Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
13:53:07.546526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20C1C2B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20BBDB40>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CF20BBECE0>]}


============================== 2023-02-18 13:53:56.940832 | 146cfb2c-9ee2-459b-b5e1-8f2cde7c75e5 ==============================
13:53:56.940832 [info ] [MainThread]: Running with dbt=1.1.0
13:53:56.940832 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'port': 8081, 'open_browser': True, 'which': 'serve', 'indirect_selection': 'eager'}
13:53:56.940832 [debug] [MainThread]: Tracking: tracking
13:53:56.962832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000198E095D8A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000198E095F9A0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000198E095C850>]}
13:53:56.962832 [info ] [MainThread]: Serving docs at 0.0.0.0:8081
13:53:56.962832 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:8081
13:53:56.962832 [info ] [MainThread]: 
13:53:56.962832 [info ] [MainThread]: 
13:53:56.962832 [info ] [MainThread]: Press Ctrl+C to exit.


============================== 2023-02-18 13:55:20.808821 | 52786fcd-3364-4d5d-aee3-57c15957ce23 ==============================
13:55:20.808821 [info ] [MainThread]: Running with dbt=1.1.0
13:55:20.808821 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
13:55:20.809735 [debug] [MainThread]: Tracking: tracking
13:55:20.835185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A25C790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A25E2F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A25E290>]}
13:55:20.869707 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 0 files added, 0 files changed.
13:55:20.870708 [debug] [MainThread]: Partial parsing: deleted file: data_warehouse_analytics_engineer://models\example_1\my_first_dbt_model_1.sql
13:55:20.870708 [debug] [MainThread]: Partial parsing: deleted file: data_warehouse_analytics_engineer://models\example_1\my_second_dbt_model_1.sql
13:55:20.873708 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

13:55:20.877704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '52786fcd-3364-4d5d-aee3-57c15957ce23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A3C0400>]}
13:55:20.881704 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '52786fcd-3364-4d5d-aee3-57c15957ce23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A34C970>]}
13:55:20.881704 [info ] [MainThread]: Found 7 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
13:55:20.883091 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '52786fcd-3364-4d5d-aee3-57c15957ce23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A34CA00>]}
13:55:20.884098 [info ] [MainThread]: 
13:55:20.884098 [debug] [MainThread]: Acquiring new bigquery connection "master"
13:55:20.886099 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
13:55:20.887098 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:55:21.693794 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
13:55:21.694736 [debug] [ThreadPool]: Opening a new connection, currently in state init
13:55:22.451656 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '52786fcd-3364-4d5d-aee3-57c15957ce23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A366D10>]}
13:55:22.451656 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
13:55:22.452747 [info ] [MainThread]: 
13:55:22.455659 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_first_dbt_model
13:55:22.456657 [info ] [Thread-1 (]: 1 of 7 START table model bigquery_example_dbt.my_first_dbt_model ............... [RUN]
13:55:22.456657 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_first_dbt_model"
13:55:22.457656 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_first_dbt_model
13:55:22.457656 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_first_dbt_model
13:55:22.459664 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
13:55:22.460662 [debug] [Thread-1 (]: finished collecting timing info
13:55:22.460662 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_first_dbt_model
13:55:22.469889 [debug] [Thread-1 (]: Opening a new connection, currently in state init
13:55:23.245904 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
13:55:23.247889 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_first_dbt_model"} */


  create or replace table `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
  
  
  OPTIONS()
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
  
13:55:26.302959 [debug] [Thread-1 (]: finished collecting timing info
13:55:26.302959 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '52786fcd-3364-4d5d-aee3-57c15957ce23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A3C2F80>]}
13:55:26.303976 [info ] [Thread-1 (]: 1 of 7 OK created table model bigquery_example_dbt.my_first_dbt_model .......... [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 3.85s]
13:55:26.304885 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_first_dbt_model
13:55:26.304885 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.product_dimension
13:55:26.305873 [info ] [Thread-1 (]: 2 of 7 START incremental model bigquery_example_dbt.product_dimension .......... [RUN]
13:55:26.305873 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.product_dimension"
13:55:26.306904 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.product_dimension
13:55:26.306904 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.product_dimension
13:55:26.309959 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.product_dimension"
13:55:26.309959 [debug] [Thread-1 (]: finished collecting timing info
13:55:26.310871 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.product_dimension
13:55:26.328962 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
13:55:27.179842 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.product_dimension"
13:55:27.180838 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.product_dimension: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.product_dimension"} */


   

      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension` as DBT_INTERNAL_DEST
        using (
          
    






SELECT id, brand, department, category, updated_at
FROM (
    SELECT id, brand, department, category, updated_at,
        ROW_NUMBER() OVER(PARTITION BY id ORDER BY updated_at DESC) AS row_num
    FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`products_delta`
    WHERE DATE(updated_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))
)
WHERE row_num = 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and TIMESTAMP_trunc(DBT_INTERNAL_DEST.updated_at, DAY) in (
              TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`id`, `brand`, `department`, `category`, `updated_at`)
    values
        (`id`, `brand`, `department`, `category`, `updated_at`)



  


  
13:55:30.367900 [debug] [Thread-1 (]: finished collecting timing info
13:55:30.368408 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '52786fcd-3364-4d5d-aee3-57c15957ce23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A3C3460>]}
13:55:30.369415 [info ] [Thread-1 (]: 2 of 7 OK created incremental model bigquery_example_dbt.product_dimension ..... [[32mMERGE (0.0 rows, 44.0 Bytes processed)[0m in 4.06s]
13:55:30.370415 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.product_dimension
13:55:30.370415 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.product_dimension_type_1
13:55:30.371415 [info ] [Thread-1 (]: 3 of 7 START incremental model bigquery_example_dbt.product_dimension_type_1 ... [RUN]
13:55:30.371415 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.product_dimension_type_1"
13:55:30.372416 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.product_dimension_type_1
13:55:30.372416 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.product_dimension_type_1
13:55:30.382512 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.product_dimension_type_1"
13:55:30.383512 [debug] [Thread-1 (]: finished collecting timing info
13:55:30.384480 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.product_dimension_type_1
13:55:30.386487 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
13:55:31.200509 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.product_dimension_type_1"
13:55:31.201508 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.product_dimension_type_1: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.product_dimension_type_1"} */

        
            
                
                
            
        
    

    

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension_type_1` as DBT_INTERNAL_DEST
        using (
          

SELECT id, brand, department, category, updated_at
FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`products_main`
WHERE

    DATE(updated_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))

        ) as DBT_INTERNAL_SOURCE
        on 
                    DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
                

    
    when matched then update set
        `id` = DBT_INTERNAL_SOURCE.`id`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`department` = DBT_INTERNAL_SOURCE.`department`,`category` = DBT_INTERNAL_SOURCE.`category`,`updated_at` = DBT_INTERNAL_SOURCE.`updated_at`
    

    when not matched then insert
        (`id`, `brand`, `department`, `category`, `updated_at`)
    values
        (`id`, `brand`, `department`, `category`, `updated_at`)


  
13:55:34.401074 [debug] [Thread-1 (]: finished collecting timing info
13:55:34.402075 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '52786fcd-3364-4d5d-aee3-57c15957ce23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A3C2FE0>]}
13:55:34.402075 [info ] [Thread-1 (]: 3 of 7 OK created incremental model bigquery_example_dbt.product_dimension_type_1  [[32mMERGE (0.0 rows, 2.6 MB processed)[0m in 4.03s]
13:55:34.403075 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.product_dimension_type_1
13:55:34.403075 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.sales_transaction_fact
13:55:34.403075 [info ] [Thread-1 (]: 4 of 7 START incremental model bigquery_example_dbt.sales_transaction_fact ..... [RUN]
13:55:34.404074 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_transaction_fact"
13:55:34.404074 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.sales_transaction_fact
13:55:34.404074 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.sales_transaction_fact
13:55:34.412570 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_transaction_fact"
13:55:34.412570 [debug] [Thread-1 (]: finished collecting timing info
13:55:34.413570 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.sales_transaction_fact
13:55:34.450393 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
13:55:35.243531 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.sales_transaction_fact"
13:55:35.245021 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.sales_transaction_fact: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_transaction_fact"} */


   

      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact` as DBT_INTERNAL_DEST
        using (
          
    






SELECT
    id,
    order_id,
    user_id,
    product_id,
    inventory_item_id,
    status,
    created_at,
    shipped_at,
    delivered_at,
    returned_at,
    sale_price
FROM (
    SELECT *, ROW_NUMBER() OVER(PARTITION BY id ORDER BY created_at DESC) AS row_num
    FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`order_items_delta`
    WHERE DATE(created_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))
)
WHERE row_num = 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and TIMESTAMP_trunc(DBT_INTERNAL_DEST.created_at, DAY) in (
              TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`id`, `order_id`, `user_id`, `product_id`, `inventory_item_id`, `status`, `created_at`, `shipped_at`, `delivered_at`, `returned_at`, `sale_price`)
    values
        (`id`, `order_id`, `user_id`, `product_id`, `inventory_item_id`, `status`, `created_at`, `shipped_at`, `delivered_at`, `returned_at`, `sale_price`)



  


  
13:55:38.524215 [debug] [Thread-1 (]: finished collecting timing info
13:55:38.525215 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '52786fcd-3364-4d5d-aee3-57c15957ce23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC598811B0>]}
13:55:38.526218 [info ] [Thread-1 (]: 4 of 7 OK created incremental model bigquery_example_dbt.sales_transaction_fact  [[32mMERGE (0.0 rows, 0 processed)[0m in 4.12s]
13:55:38.527214 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.sales_transaction_fact
13:55:38.527214 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model
13:55:38.528217 [info ] [Thread-1 (]: 5 of 7 START view model bigquery_example_dbt.my_second_dbt_model ............... [RUN]
13:55:38.529215 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model"
13:55:38.529215 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model
13:55:38.529215 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model
13:55:38.531212 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
13:55:38.532211 [debug] [Thread-1 (]: finished collecting timing info
13:55:38.532211 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model
13:55:38.546217 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
13:55:38.546217 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
13:55:38.547217 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
where id = 1;


13:55:40.641912 [debug] [Thread-1 (]: finished collecting timing info
13:55:40.641912 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '52786fcd-3364-4d5d-aee3-57c15957ce23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC598BFE80>]}
13:55:40.642925 [info ] [Thread-1 (]: 5 of 7 OK created view model bigquery_example_dbt.my_second_dbt_model .......... [[32mOK[0m in 2.11s]
13:55:40.643896 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model
13:55:40.643896 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.sales_periodic_fact
13:55:40.643896 [info ] [Thread-1 (]: 6 of 7 START incremental model bigquery_example_dbt.sales_periodic_fact ........ [RUN]
13:55:40.644953 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_periodic_fact"
13:55:40.644953 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.sales_periodic_fact
13:55:40.645919 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.sales_periodic_fact
13:55:40.651905 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_periodic_fact"
13:55:40.651905 [debug] [Thread-1 (]: finished collecting timing info
13:55:40.652905 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.sales_periodic_fact
13:55:40.655905 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
13:55:41.430551 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.sales_periodic_fact"
13:55:41.431594 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.sales_periodic_fact: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_periodic_fact"} */


   

      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_periodic_fact` as DBT_INTERNAL_DEST
        using (
          
    







SELECT
  DATE(created_at) AS transaction_date,
  SUM(IF(returned_at IS NULL, sale_price, sale_price * -1)) AS total_sale
FROM `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact`
WHERE DATE(created_at) = DATE(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY))
GROUP BY 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and DBT_INTERNAL_DEST.transaction_date in (
              DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`transaction_date`, `total_sale`)
    values
        (`transaction_date`, `total_sale`)



  


  
13:55:44.659545 [debug] [Thread-1 (]: finished collecting timing info
13:55:44.660555 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '52786fcd-3364-4d5d-aee3-57c15957ce23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A4EC3A0>]}
13:55:44.661562 [info ] [Thread-1 (]: 6 of 7 OK created incremental model bigquery_example_dbt.sales_periodic_fact ... [[32mMERGE (0.0 rows, 0 processed)[0m in 4.02s]
13:55:44.662564 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.sales_periodic_fact
13:55:44.662564 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.sales_report
13:55:44.662564 [info ] [Thread-1 (]: 7 of 7 START incremental model bigquery_example_dbt.sales_report ............... [RUN]
13:55:44.664159 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_report"
13:55:44.664159 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.sales_report
13:55:44.664159 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.sales_report
13:55:44.669569 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_report"
13:55:44.670569 [debug] [Thread-1 (]: finished collecting timing info
13:55:44.670569 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.sales_report
13:55:44.672588 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
13:55:45.424050 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.sales_report"
13:55:45.426050 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.sales_report: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_report"} */


   

      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_report` as DBT_INTERNAL_DEST
        using (
          
    






WITH sales_transaction_data AS (
    SELECT *
    FROM `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact` sales_trans
    WHERE DATE(created_at) = DATE(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY))
)
SELECT DATE(created_at) AS transaction_date, category, brand, department, SUM(sale_price) AS total_sales
FROM (
 SELECT * EXCEPT(row_num)
 FROM (
   SELECT created_at, category, brand, department, sale_price,
   ROW_NUMBER() OVER(PARTITION BY sales_trans.id ORDER BY product_dim.updated_at DESC) AS row_num
   FROM sales_transaction_data sales_trans
     LEFT JOIN `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension` product_dim
       ON sales_trans.product_id = product_dim.id and sales_trans.created_at >= product_dim.updated_at
 )
 WHERE row_num = 1
)
GROUP BY transaction_date, category, brand, department
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and DBT_INTERNAL_DEST.transaction_date in (
              DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`transaction_date`, `category`, `brand`, `department`, `total_sales`)
    values
        (`transaction_date`, `category`, `brand`, `department`, `total_sales`)



  


  
13:55:49.488316 [debug] [Thread-1 (]: finished collecting timing info
13:55:49.488316 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '52786fcd-3364-4d5d-aee3-57c15957ce23', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A1ED090>]}
13:55:49.489316 [info ] [Thread-1 (]: 7 of 7 OK created incremental model bigquery_example_dbt.sales_report .......... [[32mMERGE (0.0 rows, 0 processed)[0m in 4.82s]
13:55:49.489316 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.sales_report
13:55:49.490317 [debug] [MainThread]: Acquiring new bigquery connection "master"
13:55:49.490317 [info ] [MainThread]: 
13:55:49.491316 [info ] [MainThread]: Finished running 1 table model, 5 incremental models, 1 view model in 28.61s.
13:55:49.491316 [debug] [MainThread]: Connection 'master' was properly closed.
13:55:49.492315 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
13:55:49.492315 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt' was properly closed.
13:55:49.492315 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_report' was properly closed.
13:55:49.498335 [info ] [MainThread]: 
13:55:49.498335 [info ] [MainThread]: [32mCompleted successfully[0m
13:55:49.499316 [info ] [MainThread]: 
13:55:49.499968 [info ] [MainThread]: Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
13:55:49.499968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A367820>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5A3677F0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001FC5B50CA30>]}


============================== 2023-02-18 13:56:20.347616 | 5f834f2f-f942-425d-abb8-5ea35039fca6 ==============================
13:56:20.347616 [info ] [MainThread]: Running with dbt=1.1.0
13:56:20.347616 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'port': 8081, 'open_browser': True, 'which': 'serve', 'indirect_selection': 'eager'}
13:56:20.347616 [debug] [MainThread]: Tracking: tracking
13:56:20.371526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016BD314C940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016BD314E0B0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x0000016BD314D5D0>]}
13:56:20.373526 [info ] [MainThread]: Serving docs at 0.0.0.0:8081
13:56:20.374525 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:8081
13:56:20.374525 [info ] [MainThread]: 
13:56:20.375524 [info ] [MainThread]: 
13:56:20.375524 [info ] [MainThread]: Press Ctrl+C to exit.


============================== 2023-02-18 14:12:22.185166 | aa06be52-e419-434f-9ad0-8d0cdd21e092 ==============================
14:12:22.185166 [info ] [MainThread]: Running with dbt=1.1.0
14:12:22.185929 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
14:12:22.185929 [debug] [MainThread]: Tracking: tracking
14:12:22.208157 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC76E3D030>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC76E3C1C0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC76E3F010>]}
14:12:22.245155 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
14:12:22.245155 [debug] [MainThread]: Partial parsing: added file: data_warehouse_analytics_engineer://models\example\test_source.sql
14:12:22.260808 [debug] [MainThread]: 1699: static parser successfully parsed example\test_source.sql
14:12:22.271567 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

14:12:22.275625 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aa06be52-e419-434f-9ad0-8d0cdd21e092', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC76FBC400>]}
14:12:22.279540 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aa06be52-e419-434f-9ad0-8d0cdd21e092', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC76F6B490>]}
14:12:22.280540 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 191 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
14:12:22.281033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aa06be52-e419-434f-9ad0-8d0cdd21e092', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC7298B700>]}
14:12:22.281033 [info ] [MainThread]: 
14:12:22.282351 [debug] [MainThread]: Acquiring new bigquery connection "master"
14:12:22.282979 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
14:12:22.282979 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:12:23.138192 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
14:12:23.139268 [debug] [ThreadPool]: Opening a new connection, currently in state init
14:12:23.919292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aa06be52-e419-434f-9ad0-8d0cdd21e092', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC76F69C00>]}
14:12:23.920287 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
14:12:23.920287 [info ] [MainThread]: 
14:12:23.924292 [debug] [Thread-1 (]: Began running node model.data_warehouse_analytics_engineer.test_source
14:12:23.924292 [info ] [Thread-1 (]: 1 of 1 START view model bigquery_example_dbt.test_source ....................... [RUN]
14:12:23.924292 [debug] [Thread-1 (]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.test_source"
14:12:23.925287 [debug] [Thread-1 (]: Began compiling node model.data_warehouse_analytics_engineer.test_source
14:12:23.925287 [debug] [Thread-1 (]: Compiling model.data_warehouse_analytics_engineer.test_source
14:12:23.927288 [debug] [Thread-1 (]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.test_source"
14:12:23.928288 [debug] [Thread-1 (]: finished collecting timing info
14:12:23.928288 [debug] [Thread-1 (]: Began executing node model.data_warehouse_analytics_engineer.test_source
14:12:23.951286 [debug] [Thread-1 (]: Writing runtime SQL for node "model.data_warehouse_analytics_engineer.test_source"
14:12:23.952287 [debug] [Thread-1 (]: Opening a new connection, currently in state init
14:12:23.953287 [debug] [Thread-1 (]: On model.data_warehouse_analytics_engineer.test_source: /* {"app": "dbt", "dbt_version": "1.1.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.test_source"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt`.`test_source`
  OPTIONS()
  as SELECT *
FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`order_items_delta`;


14:12:25.560052 [debug] [Thread-1 (]: finished collecting timing info
14:12:25.561050 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'aa06be52-e419-434f-9ad0-8d0cdd21e092', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC76F5EB60>]}
14:12:25.561050 [info ] [Thread-1 (]: 1 of 1 OK created view model bigquery_example_dbt.test_source .................. [[32mOK[0m in 1.64s]
14:12:25.562064 [debug] [Thread-1 (]: Finished running node model.data_warehouse_analytics_engineer.test_source
14:12:25.563053 [debug] [MainThread]: Acquiring new bigquery connection "master"
14:12:25.564052 [info ] [MainThread]: 
14:12:25.564052 [info ] [MainThread]: Finished running 1 view model in 3.28s.
14:12:25.565051 [debug] [MainThread]: Connection 'master' was properly closed.
14:12:25.565051 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
14:12:25.565557 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt' was properly closed.
14:12:25.565557 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.test_source' was properly closed.
14:12:25.573074 [info ] [MainThread]: 
14:12:25.574073 [info ] [MainThread]: [32mCompleted successfully[0m
14:12:25.574580 [info ] [MainThread]: 
14:12:25.574580 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
14:12:25.575589 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC72A18640>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC76F6BCD0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x000001CC76F5CE50>]}


============================== 2023-02-18 14:13:55.371165 | 8f7b11e7-1a75-4845-82bc-e95ee2b81b0c ==============================
14:13:55.371165 [info ] [MainThread]: Running with dbt=1.1.0
14:13:55.371693 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'port': 8081, 'open_browser': True, 'which': 'serve', 'indirect_selection': 'eager'}
14:13:55.371693 [debug] [MainThread]: Tracking: tracking
14:13:55.394004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206F264D900>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206F264F8E0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x00000206F264C3A0>]}
14:13:55.397010 [info ] [MainThread]: Serving docs at 0.0.0.0:8081
14:13:55.397010 [info ] [MainThread]: To access from your browser, navigate to:  http://localhost:8081
14:13:55.398010 [info ] [MainThread]: 
14:13:55.398010 [info ] [MainThread]: 
14:13:55.399005 [info ] [MainThread]: Press Ctrl+C to exit.


============================== 2023-02-18 15:33:32.127245 | f6dd757b-54cb-4ebe-8d14-42651b5e97d8 ==============================
[0m15:33:32.127269 [info ] [MainThread]: Running with dbt=1.3.0
[0m15:33:32.128433 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:33:32.129644 [debug] [MainThread]: Tracking: tracking
[0m15:33:32.131164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08645d12d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08646d0cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08646d0fd0>]}
[0m15:33:32.197936 [debug] [MainThread]: Failed to load parsed file from disk at /opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer/target/partial_parse.msgpack: Field "nodes" of type MutableMapping[str, Union[CompiledAnalysisNode, CompiledSingularTestNode, CompiledModelNode, CompiledHookNode, CompiledRPCNode, CompiledSqlNode, CompiledGenericTestNode, CompiledSeedNode, CompiledSnapshotNode, ParsedAnalysisNode, ParsedSingularTestNode, ParsedHookNode, ParsedModelNode, ParsedRPCNode, ParsedSqlNode, ParsedGenericTestNode, ParsedSeedNode, ParsedSnapshotNode]] in Manifest has invalid value {'model.data_warehouse_analytics_engineer.my_first_dbt_model': {'raw_sql': '/*\n    Welcome to your first dbt model!\n    Did you know that you can also configure models directly within SQL files?\n    This will override configurations stated in dbt_project.yml\n\n    Try changing "table" to "view" below\n*/\n\n{{ config(materialized=\'table\') }}\n\nwith source_data as (\n\n    select 1 as id\n    union all\n    select null as id\n\n)\n\nselect *\nfrom source_data\n\n/*\n    Uncomment the line below to remove records with null `id` values\n*/\n\n-- where id is not null', 'resource_type': 'model', 'depends_on': {'macros': [], 'nodes': []}, 'config': {'enabled': True, 'alias': None, 'schema': None, 'database': None, 'tags': [], 'meta': {}, 'materialized': 'table', 'persist_docs': {}, 'quoting': {}, 'column_types': {}, 'full_refresh': None, 'unique_key': None, 'on_schema_change': 'ignore', 'post-hook': [], 'pre-hook': []}, 'database': 'data-analytics-engineer', 'schema': 'bigquery_example_dbt', 'fqn': ['data_warehouse_analytics_engineer', 'example', 'my_first_dbt_model'], 'unique_id': 'model.data_warehouse_analytics_engineer.my_first_dbt_model', 'package_name': 'data_warehouse_analytics_engineer', 'root_path': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt\\data_warehouse_analytics_engineer', 'path': 'example\\my_first_dbt_model.sql', 'original_file_path': 'models\\example\\my_first_dbt_model.sql', 'name': 'my_first_dbt_model', 'alias': 'my_first_dbt_model', 'checksum': {'name': 'sha256', 'checksum': '842251f5ed1d97920d3748d9686b8c05a3a0071ec7990f948f36796491788aed'}, 'tags': [], 'refs': [], 'sources': [], 'description': 'A starter dbt model', 'columns': {'id': {'name': 'id', 'description': 'The primary key for this table', 'meta': {}, 'data_type': None, 'quote': None, 'tags': []}}, 'meta': {}, 'docs': {'show': True}, 'patch_path': 'data_warehouse_analytics_engineer://models\\example\\schema.yml', 'compiled_path': None, 'build_path': None, 'deferred': False, 'unrendered_config': {'materialized': 'table'}, 'created_at': 1676708730.6722763}, 'model.data_warehouse_analytics_engineer.my_second_dbt_model': {'raw_sql': "-- Use the `ref` function to select from other models\n\nselect *\nfrom {{ ref('my_first_dbt_model') }}\nwhere id = 1", 'resource_type': 'model', 'depends_on': {'macros': [], 'nodes': ['model.data_warehouse_analytics_engineer.my_first_dbt_model']}, 'config': {'enabled': True, 'alias': None, 'schema': None, 'database': None, 'tags': [], 'meta': {}, 'materialized': 'view', 'persist_docs': {}, 'quoting': {}, 'column_types': {}, 'full_refresh': None, 'unique_key': None, 'on_schema_change': 'ignore', 'post-hook': [], 'pre-hook': []}, 'database': 'data-analytics-engineer', 'schema': 'bigquery_example_dbt', 'fqn': ['data_warehouse_analytics_engineer', 'example', 'my_second_dbt_model'], 'unique_id': 'model.data_warehouse_analytics_engineer.my_second_dbt_model', 'package_name': 'data_warehouse_analytics_engineer', 'root_path': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt\\data_warehouse_analytics_engineer', 'path': 'example\\my_second_dbt_model.sql', 'original_file_path': 'models\\example\\my_second_dbt_model.sql', 'name': 'my_second_dbt_model', 'alias': 'my_second_dbt_model', 'checksum': {'name': 'sha256', 'checksum': 'b3aa346f283f3c9c9a75936f3b80d2572ca9ab39aee4c02b30553d3fe2ba5692'}, 'tags': [], 'refs': [['my_first_dbt_model']], 'sources': [], 'description': 'A starter dbt model', 'columns': {'id': {'name': 'id', 'description': 'The primary key for this table', 'meta': {}, 'data_type': None, 'quote': None, 'tags': []}}, 'meta': {}, 'docs': {'show': True}, 'patch_path': 'data_warehouse_analytics_engineer://models\\example\\schema.yml', 'compiled_path': None, 'build_path': None, 'deferred': False, 'unrendered_config': {'materialized': 'view'}, 'created_at': 1676708730.6722763}, 'seed.data_warehouse_analytics_engineer.vn_provinces': {'raw_sql': '', 'resource_type': 'seed', 'depends_on': {'macros': [], 'nodes': []}, 'config': {'enabled': True, 'alias': None, 'schema': None, 'database': None, 'tags': [], 'meta': {}, 'materialized': 'seed', 'persist_docs': {}, 'quoting': {}, 'column_types': {}, 'full_refresh': None, 'unique_key': None, 'on_schema_change': 'ignore', 'quote_columns': None, 'post-hook': [], 'pre-hook': []}, 'database': 'data-analytics-engineer', 'schema': 'bigquery_example_dbt', 'fqn': ['data_warehouse_analytics_engineer', 'vn_provinces'], 'unique_id': 'seed.data_warehouse_analytics_engineer.vn_provinces', 'package_name': 'data_warehouse_analytics_engineer', 'root_path': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt\\data_warehouse_analytics_engineer', 'path': 'vn_provinces.csv', 'original_file_path': 'seeds\\vn_provinces.csv', 'name': 'vn_provinces', 'alias': 'vn_provinces', 'checksum': {'name': 'sha256', 'checksum': '2156beb250b12545678a954677fe18e503420739fb443a10b12f0e785622fb43'}, 'tags': [], 'refs': [], 'sources': [], 'description': '', 'columns': {}, 'meta': {}, 'docs': {'show': True}, 'patch_path': None, 'compiled_path': None, 'build_path': None, 'deferred': False, 'unrendered_config': {}, 'created_at': 1676708730.6722763}, 'test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321': {'raw_sql': '{{ test_unique(**_dbt_generic_test_kwargs) }}', 'test_metadata': {'name': 'unique', 'kwargs': {'column_name': 'id', 'model': "{{ get_where_subquery(ref('my_first_dbt_model')) }}"}, 'namespace': None}, 'resource_type': 'test', 'depends_on': {'macros': ['macro.dbt.test_unique'], 'nodes': ['model.data_warehouse_analytics_engineer.my_first_dbt_model']}, 'config': {'enabled': True, 'alias': None, 'schema': 'dbt_test__audit', 'database': None, 'tags': [], 'meta': {}, 'materialized': 'test', 'severity': 'ERROR', 'store_failures': None, 'where': None, 'limit': None, 'fail_calc': 'count(*)', 'warn_if': '!= 0', 'error_if': '!= 0'}, 'database': 'data-analytics-engineer', 'schema': 'bigquery_example_dbt_dbt_test__audit', 'fqn': ['data_warehouse_analytics_engineer', 'example', 'unique_my_first_dbt_model_id'], 'unique_id': 'test.data_warehouse_analytics_engineer.unique_my_first_dbt_model_id.16e066b321', 'package_name': 'data_warehouse_analytics_engineer', 'root_path': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt\\data_warehouse_analytics_engineer', 'path': 'unique_my_first_dbt_model_id.sql', 'original_file_path': 'models\\example\\schema.yml', 'name': 'unique_my_first_dbt_model_id', 'alias': 'unique_my_first_dbt_model_id', 'checksum': {'name': 'none', 'checksum': ''}, 'tags': [], 'refs': [['my_first_dbt_model']], 'sources': [], 'description': '', 'columns': {}, 'meta': {}, 'docs': {'show': True}, 'patch_path': None, 'compiled_path': None, 'build_path': None, 'deferred': False, 'unrendered_config': {}, 'created_at': 1676708730.688017, 'column_name': 'id', 'file_key_name': 'models.my_first_dbt_model'}, 'test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710': {'raw_sql': '{{ test_not_null(**_dbt_generic_test_kwargs) }}', 'test_metadata': {'name': 'not_null', 'kwargs': {'column_name': 'id', 'model': "{{ get_where_subquery(ref('my_first_dbt_model')) }}"}, 'namespace': None}, 'resource_type': 'test', 'depends_on': {'macros': ['macro.dbt.test_not_null'], 'nodes': ['model.data_warehouse_analytics_engineer.my_first_dbt_model']}, 'config': {'enabled': True, 'alias': None, 'schema': 'dbt_test__audit', 'database': None, 'tags': [], 'meta': {}, 'materialized': 'test', 'severity': 'ERROR', 'store_failures': None, 'where': None, 'limit': None, 'fail_calc': 'count(*)', 'warn_if': '!= 0', 'error_if': '!= 0'}, 'database': 'data-analytics-engineer', 'schema': 'bigquery_example_dbt_dbt_test__audit', 'fqn': ['data_warehouse_analytics_engineer', 'example', 'not_null_my_first_dbt_model_id'], 'unique_id': 'test.data_warehouse_analytics_engineer.not_null_my_first_dbt_model_id.5fb22c2710', 'package_name': 'data_warehouse_analytics_engineer', 'root_path': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt\\data_warehouse_analytics_engineer', 'path': 'not_null_my_first_dbt_model_id.sql', 'original_file_path': 'models\\example\\schema.yml', 'name': 'not_null_my_first_dbt_model_id', 'alias': 'not_null_my_first_dbt_model_id', 'checksum': {'name': 'none', 'checksum': ''}, 'tags': [], 'refs': [['my_first_dbt_model']], 'sources': [], 'description': '', 'columns': {}, 'meta': {}, 'docs': {'show': True}, 'patch_path': None, 'compiled_path': None, 'build_path': None, 'deferred': False, 'unrendered_config': {}, 'created_at': 1676708730.688017, 'column_name': 'id', 'file_key_name': 'models.my_first_dbt_model'}, 'test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493': {'raw_sql': '{{ test_unique(**_dbt_generic_test_kwargs) }}', 'test_metadata': {'name': 'unique', 'kwargs': {'column_name': 'id', 'model': "{{ get_where_subquery(ref('my_second_dbt_model')) }}"}, 'namespace': None}, 'resource_type': 'test', 'depends_on': {'macros': ['macro.dbt.test_unique'], 'nodes': ['model.data_warehouse_analytics_engineer.my_second_dbt_model']}, 'config': {'enabled': True, 'alias': None, 'schema': 'dbt_test__audit', 'database': None, 'tags': [], 'meta': {}, 'materialized': 'test', 'severity': 'ERROR', 'store_failures': None, 'where': None, 'limit': None, 'fail_calc': 'count(*)', 'warn_if': '!= 0', 'error_if': '!= 0'}, 'database': 'data-analytics-engineer', 'schema': 'bigquery_example_dbt_dbt_test__audit', 'fqn': ['data_warehouse_analytics_engineer', 'example', 'unique_my_second_dbt_model_id'], 'unique_id': 'test.data_warehouse_analytics_engineer.unique_my_second_dbt_model_id.57a0f8c493', 'package_name': 'data_warehouse_analytics_engineer', 'root_path': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt\\data_warehouse_analytics_engineer', 'path': 'unique_my_second_dbt_model_id.sql', 'original_file_path': 'models\\example\\schema.yml', 'name': 'unique_my_second_dbt_model_id', 'alias': 'unique_my_second_dbt_model_id', 'checksum': {'name': 'none', 'checksum': ''}, 'tags': [], 'refs': [['my_second_dbt_model']], 'sources': [], 'description': '', 'columns': {}, 'meta': {}, 'docs': {'show': True}, 'patch_path': None, 'compiled_path': None, 'build_path': None, 'deferred': False, 'unrendered_config': {}, 'created_at': 1676708730.688017, 'column_name': 'id', 'file_key_name': 'models.my_second_dbt_model'}, 'test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778': {'raw_sql': '{{ test_not_null(**_dbt_generic_test_kwargs) }}', 'test_metadata': {'name': 'not_null', 'kwargs': {'column_name': 'id', 'model': "{{ get_where_subquery(ref('my_second_dbt_model')) }}"}, 'namespace': None}, 'resource_type': 'test', 'depends_on': {'macros': ['macro.dbt.test_not_null'], 'nodes': ['model.data_warehouse_analytics_engineer.my_second_dbt_model']}, 'config': {'enabled': True, 'alias': None, 'schema': 'dbt_test__audit', 'database': None, 'tags': [], 'meta': {}, 'materialized': 'test', 'severity': 'ERROR', 'store_failures': None, 'where': None, 'limit': None, 'fail_calc': 'count(*)', 'warn_if': '!= 0', 'error_if': '!= 0'}, 'database': 'data-analytics-engineer', 'schema': 'bigquery_example_dbt_dbt_test__audit', 'fqn': ['data_warehouse_analytics_engineer', 'example', 'not_null_my_second_dbt_model_id'], 'unique_id': 'test.data_warehouse_analytics_engineer.not_null_my_second_dbt_model_id.151b76d778', 'package_name': 'data_warehouse_analytics_engineer', 'root_path': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt\\data_warehouse_analytics_engineer', 'path': 'not_null_my_second_dbt_model_id.sql', 'original_file_path': 'models\\example\\schema.yml', 'name': 'not_null_my_second_dbt_model_id', 'alias': 'not_null_my_second_dbt_model_id', 'checksum': {'name': 'none', 'checksum': ''}, 'tags': [], 'refs': [['my_second_dbt_model']], 'sources': [], 'description': '', 'columns': {}, 'meta': {}, 'docs': {'show': True}, 'patch_path': None, 'compiled_path': None, 'build_path': None, 'deferred': False, 'unrendered_config': {}, 'created_at': 1676708730.688017, 'column_name': 'id', 'file_key_name': 'models.my_second_dbt_model'}, 'model.data_warehouse_analytics_engineer.product_dimension': {'raw_sql': '{% if var(\'execution_date\',\'not_set\') != \'not_set\' %}\n    {% set execution_date = \'"\' + var(\'execution_date\') + \'"\' %}\n{% else %}\n    {% set execution_date = "TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)" %}\n{% endif %}\n\n{% set partitions_to_replace = [\n    execution_date\n] %}\n\n{{\n    config(\n        materialized=\'incremental\',\n        incremental_strategy="insert_overwrite",\n        partition_by={\n            \'field\': \'updated_at\',\n            \'data_type\': \'TIMESTAMP\',\n            \'granularity\': \'DAY\'\n        },\n        partitions = partitions_to_replace\n    )\n}}\n\nSELECT id, brand, department, category, updated_at\nFROM (\n    SELECT id, brand, department, category, updated_at,\n        ROW_NUMBER() OVER(PARTITION BY id ORDER BY updated_at DESC) AS row_num\n    FROM {{ source("bigquery_change_data_capture_example", "products_delta") }}\n    WHERE DATE(updated_at) = DATE({{ execution_date }})\n)\nWHERE row_num = 1', 'resource_type': 'model', 'depends_on': {'macros': [], 'nodes': ['source.data_warehouse_analytics_engineer.bigquery_change_data_capture_example.products_delta']}, 'config': {'enabled': True, 'alias': None, 'schema': None, 'database': None, 'tags': [], 'meta': {}, 'materialized': 'incremental', 'persist_docs': {}, 'quoting': {}, 'column_types': {}, 'full_refresh': None, 'unique_key': None, 'on_schema_change': 'ignore', 'partition_by': {'field': 'updated_at', 'data_type': 'TIMESTAMP', 'granularity': 'DAY'}, 'partitions': ['TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)'], 'incremental_strategy': 'insert_overwrite', 'post-hook': [], 'pre-hook': []}, 'database': 'data-analytics-engineer', 'schema': 'bigquery_example_dbt', 'fqn': ['data_warehouse_analytics_engineer', 'dimension_models', 'product_dimension'], 'unique_id': 'model.data_warehouse_analytics_engineer.product_dimension', 'package_name': 'data_warehouse_analytics_engineer', 'root_path': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt\\data_warehouse_analytics_engineer', 'path': 'dimension_models\\product_dimension.sql', 'original_file_path': 'models\\dimension_models\\product_dimension.sql', 'name': 'product_dimension', 'alias': 'product_dimension', 'checksum': {'name': 'sha256', 'checksum': 'b0bb6b0bfffa884be90ad58395cfcb48c48501851790020d7c91f7657ca3946a'}, 'tags': [], 'refs': [], 'sources': [['bigquery_change_data_capture_example', 'products_delta']], 'description': '', 'columns': {}, 'meta': {}, 'docs': {'show': True}, 'patch_path': None, 'compiled_path': None, 'build_path': None, 'deferred': False, 'unrendered_config': {'materialized': 'incremental', 'incremental_strategy': 'insert_overwrite', 'partition_by': {'field': 'updated_at', 'data_type': 'TIMESTAMP', 'granularity': 'DAY'}, 'partitions': ['TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)']}, 'created_at': 1676712995.1042986}, 'model.data_warehouse_analytics_engineer.product_dimension_type_1': {'raw_sql': '{{\n    config(\n        materialized=\'incremental\',\n        unique_key=["id"],\n        incremental_strategy="merge",\n        partition_by={\n            \'field\': \'updated_at\',\n            \'data_type\': \'TIMESTAMP\',\n            \'granularity\': \'DAY\'\n        }\n    )\n}}\n\nSELECT id, brand, department, category, updated_at\nFROM {{ source("bigquery_change_data_capture_example", "products_main") }}\nWHERE\n{% if var(\'execution_date\',\'not_set\') != \'not_set\' %}\n    DATE(updated_at) = \'{{ var(\'execution_date\') }}\'\n{% elif is_incremental() %}\n    DATE(updated_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))\n{% else %}\n    DATE(updated_at) >= "2022-01-01"\n{% endif %}', 'resource_type': 'model', 'depends_on': {'macros': ['macro.dbt.is_incremental'], 'nodes': ['source.data_warehouse_analytics_engineer.bigquery_change_data_capture_example.products_main']}, 'config': {'enabled': True, 'alias': None, 'schema': None, 'database': None, 'tags': [], 'meta': {}, 'materialized': 'incremental', 'persist_docs': {}, 'quoting': {}, 'column_types': {}, 'full_refresh': None, 'unique_key': ['id'], 'on_schema_change': 'ignore', 'partition_by': {'field': 'updated_at', 'data_type': 'TIMESTAMP', 'granularity': 'DAY'}, 'incremental_strategy': 'merge', 'post-hook': [], 'pre-hook': []}, 'database': 'data-analytics-engineer', 'schema': 'bigquery_example_dbt', 'fqn': ['data_warehouse_analytics_engineer', 'dimension_models', 'product_dimension_type_1'], 'unique_id': 'model.data_warehouse_analytics_engineer.product_dimension_type_1', 'package_name': 'data_warehouse_analytics_engineer', 'root_path': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt\\data_warehouse_analytics_engineer', 'path': 'dimension_models\\product_dimension_type_1.sql', 'original_file_path': 'models\\dimension_models\\product_dimension_type_1.sql', 'name': 'product_dimension_type_1', 'alias': 'product_dimension_type_1', 'checksum': {'name': 'sha256', 'checksum': '9b83c602b036ac8496d679e35a2e5ae99be49858b92d2226e330c09004108b8e'}, 'tags': [], 'refs': [], 'sources': [['bigquery_change_data_capture_example', 'products_main']], 'description': '', 'columns': {}, 'meta': {}, 'docs': {'show': True}, 'patch_path': None, 'compiled_path': None, 'build_path': None, 'deferred': False, 'unrendered_config': {'materialized': 'incremental', 'unique_key': ['id'], 'incremental_strategy': 'merge', 'partition_by': {'field': 'updated_at', 'data_type': 'TIMESTAMP', 'granularity': 'DAY'}}, 'created_at': 1676712995.124604}, 'model.data_warehouse_analytics_engineer.sales_report': {'raw_sql': '{% if var(\'execution_date\',\'not_set\') != \'not_set\' %}\n    {% set execution_date = \'"\' + var(\'execution_date\') + \'"\' %}\n{% else %}\n    {% set execution_date = "DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)" %}\n{% endif %}\n\n{% set partitions_to_replace = [\n    execution_date\n] %}\n\n{{\n    config(\n        materialized=\'incremental\',\n        incremental_strategy="insert_overwrite",\n        partition_by={\n            \'field\': \'transaction_date\',\n            \'data_type\': \'DATE\',\n            \'granularity\': \'DAY\'\n        },\n        partitions = partitions_to_replace\n    )\n}}\n\nWITH sales_transaction_data AS (\n    SELECT *\n    FROM {{ ref("sales_transaction_fact") }} sales_trans\n    WHERE DATE(created_at) = DATE({{ execution_date }})\n)\nSELECT DATE(created_at) AS transaction_date, category, brand, department, SUM(sale_price) AS total_sales\nFROM (\n SELECT * EXCEPT(row_num)\n FROM (\n   SELECT created_at, category, brand, department, sale_price,\n   ROW_NUMBER() OVER(PARTITION BY sales_trans.id ORDER BY product_dim.updated_at DESC) AS row_num\n   FROM sales_transaction_data sales_trans\n     LEFT JOIN {{ ref("product_dimension") }} product_dim\n       ON sales_trans.product_id = product_dim.id and sales_trans.created_at >= product_dim.updated_at\n )\n WHERE row_num = 1\n)\nGROUP BY transaction_date, category, brand, department', 'resource_type': 'model', 'depends_on': {'macros': [], 'nodes': ['model.data_warehouse_analytics_engineer.sales_transaction_fact', 'model.data_warehouse_analytics_engineer.product_dimension']}, 'config': {'enabled': True, 'alias': None, 'schema': None, 'database': None, 'tags': [], 'meta': {}, 'materialized': 'incremental', 'persist_docs': {}, 'quoting': {}, 'column_types': {}, 'full_refresh': None, 'unique_key': None, 'on_schema_change': 'ignore', 'partition_by': {'field': 'transaction_date', 'data_type': 'DATE', 'granularity': 'DAY'}, 'partitions': ['DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)'], 'incremental_strategy': 'insert_overwrite', 'post-hook': [], 'pre-hook': []}, 'database': 'data-analytics-engineer', 'schema': 'bigquery_example_dbt', 'fqn': ['data_warehouse_analytics_engineer', 'dimension_models', 'sales_report'], 'unique_id': 'model.data_warehouse_analytics_engineer.sales_report', 'package_name': 'data_warehouse_analytics_engineer', 'root_path': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt\\data_warehouse_analytics_engineer', 'path': 'dimension_models\\sales_report.sql', 'original_file_path': 'models\\dimension_models\\sales_report.sql', 'name': 'sales_report', 'alias': 'sales_report', 'checksum': {'name': 'sha256', 'checksum': 'fd642d44eda73ebf4e343517b234d0e06f0e52ea5052ba0385e3af33d7dffd1e'}, 'tags': [], 'refs': [['sales_transaction_fact'], ['product_dimension']], 'sources': [], 'description': '', 'columns': {}, 'meta': {}, 'docs': {'show': True}, 'patch_path': None, 'compiled_path': None, 'build_path': None, 'deferred': False, 'unrendered_config': {'materialized': 'incremental', 'incremental_strategy': 'insert_overwrite', 'partition_by': {'field': 'transaction_date', 'data_type': 'DATE', 'granularity': 'DAY'}, 'partitions': ['DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)']}, 'created_at': 1676712995.1325078}, 'model.data_warehouse_analytics_engineer.sales_periodic_fact': {'raw_sql': '{% if var(\'execution_date\',\'not_set\') != \'not_set\' %}\n    {% set execution_date = \'"\' + var(\'execution_date\') + \'"\' %}\n{% else %}\n    {% set execution_date = "DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)" %}\n{% endif %}\n\n{% set partitions_to_replace = [\n    execution_date\n] %}\n\n{{\n    config(\n        materialized=\'incremental\',\n        incremental_strategy="insert_overwrite",\n        partition_by={\n            \'field\': \'transaction_date\',\n            \'data_type\': \'DATE\',\n            \'granularity\': \'DAY\'\n        },\n        partitions = partitions_to_replace\n    )\n}}\n\n\nSELECT\n  DATE(created_at) AS transaction_date,\n  SUM(IF(returned_at IS NULL, sale_price, sale_price * -1)) AS total_sale\nFROM {{ ref("sales_transaction_fact") }}\nWHERE DATE(created_at) = DATE({{ execution_date }})\nGROUP BY 1', 'resource_type': 'model', 'depends_on': {'macros': [], 'nodes': ['model.data_warehouse_analytics_engineer.sales_transaction_fact']}, 'config': {'enabled': True, 'alias': None, 'schema': None, 'database': None, 'tags': [], 'meta': {}, 'materialized': 'incremental', 'persist_docs': {}, 'quoting': {}, 'column_types': {}, 'full_refresh': None, 'unique_key': None, 'on_schema_change': 'ignore', 'partition_by': {'field': 'transaction_date', 'data_type': 'DATE', 'granularity': 'DAY'}, 'partitions': ['DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)'], 'incremental_strategy': 'insert_overwrite', 'post-hook': [], 'pre-hook': []}, 'database': 'data-analytics-engineer', 'schema': 'bigquery_example_dbt', 'fqn': ['data_warehouse_analytics_engineer', 'dimension_models', 'sales_periodic_fact'], 'unique_id': 'model.data_warehouse_analytics_engineer.sales_periodic_fact', 'package_name': 'data_warehouse_analytics_engineer', 'root_path': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt\\data_warehouse_analytics_engineer', 'path': 'dimension_models\\sales_periodic_fact.sql', 'original_file_path': 'models\\dimension_models\\sales_periodic_fact.sql', 'name': 'sales_periodic_fact', 'alias': 'sales_periodic_fact', 'checksum': {'name': 'sha256', 'checksum': '25df9c3084af9efdfe91adaaeddf847e75993f9bdb90b929c2a3d569b8131319'}, 'tags': [], 'refs': [['sales_transaction_fact']], 'sources': [], 'description': '', 'columns': {}, 'meta': {}, 'docs': {'show': True}, 'patch_path': None, 'compiled_path': None, 'build_path': None, 'deferred': False, 'unrendered_config': {'materialized': 'incremental', 'incremental_strategy': 'insert_overwrite', 'partition_by': {'field': 'transaction_date', 'data_type': 'DATE', 'granularity': 'DAY'}, 'partitions': ['DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)']}, 'created_at': 1676712995.1375082}, 'model.data_warehouse_analytics_engineer.sales_transaction_fact': {'raw_sql': '{% if var(\'execution_date\',\'not_set\') != \'not_set\' %}\n    {% set execution_date = \'"\' + var(\'execution_date\') + \'"\' %}\n{% else %}\n    {% set execution_date = "TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)" %}\n{% endif %}\n\n{% set partitions_to_replace = [\n    execution_date\n] %}\n\n{{\n    config(\n        materialized=\'incremental\',\n        incremental_strategy="insert_overwrite",\n        partition_by={\n            \'field\': \'created_at\',\n            \'data_type\': \'TIMESTAMP\',\n            \'granularity\': \'DAY\'\n        },\n        partitions = partitions_to_replace\n    )\n}}\n\nSELECT\n    id,\n    order_id,\n    user_id,\n    product_id,\n    inventory_item_id,\n    status,\n    created_at,\n    shipped_at,\n    delivered_at,\n    returned_at,\n    sale_price\nFROM (\n    SELECT *, ROW_NUMBER() OVER(PARTITION BY id ORDER BY created_at DESC) AS row_num\n    FROM {{ source("bigquery_change_data_capture_example", "order_items_delta") }}\n    WHERE DATE(created_at) = DATE({{ execution_date }})\n)\nWHERE row_num = 1', 'resource_type': 'model', 'depends_on': {'macros': [], 'nodes': ['source.data_warehouse_analytics_engineer.bigquery_change_data_capture_example.order_items_delta']}, 'config': {'enabled': True, 'alias': None, 'schema': None, 'database': None, 'tags': [], 'meta': {}, 'materialized': 'incremental', 'persist_docs': {}, 'quoting': {}, 'column_types': {}, 'full_refresh': None, 'unique_key': None, 'on_schema_change': 'ignore', 'partition_by': {'field': 'created_at', 'data_type': 'TIMESTAMP', 'granularity': 'DAY'}, 'partitions': ['TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)'], 'incremental_strategy': 'insert_overwrite', 'post-hook': [], 'pre-hook': []}, 'database': 'data-analytics-engineer', 'schema': 'bigquery_example_dbt', 'fqn': ['data_warehouse_analytics_engineer', 'dimension_models', 'sales_transaction_fact'], 'unique_id': 'model.data_warehouse_analytics_engineer.sales_transaction_fact', 'package_name': 'data_warehouse_analytics_engineer', 'root_path': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt\\data_warehouse_analytics_engineer', 'path': 'dimension_models\\sales_transaction_fact.sql', 'original_file_path': 'models\\dimension_models\\sales_transaction_fact.sql', 'name': 'sales_transaction_fact', 'alias': 'sales_transaction_fact', 'checksum': {'name': 'sha256', 'checksum': 'be028d9abf1989949a1ce8165349bca47d08a15c09dd1ea1a533d11858f924d6'}, 'tags': [], 'refs': [], 'sources': [['bigquery_change_data_capture_example', 'order_items_delta']], 'description': '', 'columns': {}, 'meta': {}, 'docs': {'show': True}, 'patch_path': None, 'compiled_path': None, 'build_path': None, 'deferred': False, 'unrendered_config': {'materialized': 'incremental', 'incremental_strategy': 'insert_overwrite', 'partition_by': {'field': 'created_at', 'data_type': 'TIMESTAMP', 'granularity': 'DAY'}, 'partitions': ['TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)']}, 'created_at': 1676712995.1425078}, 'model.data_warehouse_analytics_engineer.test_source': {'raw_sql': 'SELECT *\r\nFROM {{ source("bigquery_change_data_capture_example", "order_items_delta") }}', 'resource_type': 'model', 'depends_on': {'macros': [], 'nodes': ['source.data_warehouse_analytics_engineer.bigquery_change_data_capture_example.order_items_delta']}, 'config': {'enabled': True, 'alias': None, 'schema': None, 'database': None, 'tags': [], 'meta': {}, 'materialized': 'view', 'persist_docs': {}, 'quoting': {}, 'column_types': {}, 'full_refresh': None, 'unique_key': None, 'on_schema_change': 'ignore', 'post-hook': [], 'pre-hook': []}, 'database': 'data-analytics-engineer', 'schema': 'bigquery_example_dbt', 'fqn': ['data_warehouse_analytics_engineer', 'example', 'test_source'], 'unique_id': 'model.data_warehouse_analytics_engineer.test_source', 'package_name': 'data_warehouse_analytics_engineer', 'root_path': 'C:\\Users\\HP\\Documents\\Project\\data-analytics-engineer-dbt\\data_warehouse_analytics_engineer', 'path': 'example\\test_source.sql', 'original_file_path': 'models\\example\\test_source.sql', 'name': 'test_source', 'alias': 'test_source', 'checksum': {'name': 'sha256', 'checksum': '91b500068308975422bde9e4f7d11fbfbca334343f9a01428276cd885bb74e51'}, 'tags': [], 'refs': [], 'sources': [['bigquery_change_data_capture_example', 'order_items_delta']], 'description': '', 'columns': {}, 'meta': {}, 'docs': {'show': True}, 'patch_path': None, 'compiled_path': None, 'build_path': None, 'deferred': False, 'unrendered_config': {'materialized': 'view'}, 'created_at': 1676729542.252239}}
[0m15:33:32.199188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'f6dd757b-54cb-4ebe-8d14-42651b5e97d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08645fd310>]}
[0m15:33:32.738557 [debug] [MainThread]: Parsing macros/etc.sql
[0m15:33:32.742092 [debug] [MainThread]: Parsing macros/catalog.sql
[0m15:33:32.749080 [debug] [MainThread]: Parsing macros/adapters.sql
[0m15:33:32.770689 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m15:33:32.774032 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m15:33:32.783460 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m15:33:32.787713 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m15:33:32.791657 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m15:33:32.797132 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m15:33:32.799422 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m15:33:32.819074 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m15:33:32.820484 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m15:33:32.821574 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m15:33:32.823155 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m15:33:32.824340 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m15:33:32.825489 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m15:33:32.826340 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m15:33:32.827541 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m15:33:32.828749 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m15:33:32.830116 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m15:33:32.831696 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m15:33:32.832837 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m15:33:32.834293 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m15:33:32.835525 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m15:33:32.836879 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m15:33:32.838133 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m15:33:32.839358 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m15:33:32.841128 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m15:33:32.843643 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m15:33:32.846061 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m15:33:32.848976 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m15:33:32.862188 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m15:33:32.868850 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m15:33:32.873382 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m15:33:32.877340 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m15:33:32.880789 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m15:33:32.893527 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m15:33:32.896306 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m15:33:32.898780 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m15:33:32.907570 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m15:33:32.909527 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m15:33:32.911780 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m15:33:32.913261 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m15:33:32.915214 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m15:33:32.917997 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m15:33:32.922307 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m15:33:32.925173 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m15:33:32.930778 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m15:33:32.934376 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m15:33:32.936137 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m15:33:32.950673 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m15:33:32.953152 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m15:33:32.959736 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m15:33:32.968134 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m15:33:32.981692 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m15:33:32.991968 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m15:33:32.998579 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m15:33:33.002306 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m15:33:33.007047 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m15:33:33.009404 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m15:33:33.011875 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m15:33:33.071993 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m15:33:33.095991 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m15:33:33.099347 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m15:33:33.130174 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m15:33:33.142792 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m15:33:33.158853 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m15:33:33.173276 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m15:33:33.181465 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m15:33:33.188286 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m15:33:33.196575 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m15:33:33.198238 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m15:33:33.199964 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m15:33:33.201691 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m15:33:33.203334 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m15:33:33.205182 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m15:33:33.206534 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m15:33:33.208228 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m15:33:33.209804 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m15:33:33.213489 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m15:33:33.215796 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m15:33:33.218035 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m15:33:33.219724 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m15:33:33.221835 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m15:33:33.224062 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m15:33:33.225845 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m15:33:33.228515 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m15:33:33.232566 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m15:33:33.234668 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m15:33:33.236344 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m15:33:33.238090 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m15:33:33.239783 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m15:33:33.241578 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m15:33:33.245378 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m15:33:33.655038 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension.sql
[0m15:33:33.674951 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension.sql
[0m15:33:33.680143 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension_type_1.sql
[0m15:33:33.692169 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension_type_1.sql
[0m15:33:33.695190 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_periodic_fact.sql
[0m15:33:33.703211 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_periodic_fact.sql
[0m15:33:33.705400 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_report.sql
[0m15:33:33.719872 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_report.sql
[0m15:33:33.728379 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_transaction_fact.sql
[0m15:33:33.737783 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_transaction_fact.sql
[0m15:33:33.743631 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m15:33:33.748337 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m15:33:33.752451 [debug] [MainThread]: 1699: static parser successfully parsed example/test_source.sql
[0m15:33:33.919542 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m15:33:33.930762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f6dd757b-54cb-4ebe-8d14-42651b5e97d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08643ed210>]}
[0m15:33:33.935466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f6dd757b-54cb-4ebe-8d14-42651b5e97d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08643d9dd0>]}
[0m15:33:33.936311 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m15:33:33.937234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f6dd757b-54cb-4ebe-8d14-42651b5e97d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08646eae50>]}
[0m15:33:33.939689 [info ] [MainThread]: 
[0m15:33:33.941373 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:33:33.943396 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m15:33:33.944902 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:33:33.947984 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m15:33:33.952095 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:33:33.953141 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m15:33:33.954219 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m15:33:33.955271 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0864471710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0864471290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0864471c90>]}
[0m15:33:33.956103 [debug] [MainThread]: Flushing usage events


============================== 2023-02-18 15:33:53.633279 | 48a93e96-98da-44a1-a96e-72c7f88987ca ==============================
[0m15:33:53.633303 [info ] [MainThread]: Running with dbt=1.3.0
[0m15:33:53.634556 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:33:53.635240 [debug] [MainThread]: Tracking: tracking
[0m15:33:53.637055 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda43974810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda43974790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda438b6d90>]}
[0m15:33:54.262701 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:33:54.263628 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:33:54.264844 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m15:33:54.275001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '48a93e96-98da-44a1-a96e-72c7f88987ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda43700210>]}
[0m15:33:54.279881 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48a93e96-98da-44a1-a96e-72c7f88987ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda43888610>]}
[0m15:33:54.280692 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m15:33:54.281813 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48a93e96-98da-44a1-a96e-72c7f88987ca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda43888e10>]}
[0m15:33:54.284629 [info ] [MainThread]: 
[0m15:33:54.286365 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:33:54.288181 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m15:33:54.289179 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:33:54.290209 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m15:33:54.292330 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:33:54.293429 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m15:33:54.294119 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m15:33:54.295714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda43836450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda43836c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fda43836650>]}
[0m15:33:54.296459 [debug] [MainThread]: Flushing usage events


============================== 2023-02-18 15:35:23.051477 | 57c9b99e-d84d-4c63-ab39-79cfe0158fee ==============================
[0m15:35:23.051517 [info ] [MainThread]: Running with dbt=1.3.0
[0m15:35:23.057368 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:35:23.058823 [debug] [MainThread]: Tracking: tracking
[0m15:35:23.061564 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b27e63890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b27da4b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b27da4e90>]}


============================== 2023-02-18 15:35:23.063546 | d22fc51f-aadf-401b-816b-d7430c6265f0 ==============================
[0m15:35:23.063621 [info ] [MainThread]: Running with dbt=1.3.0
[0m15:35:23.069948 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:35:23.072252 [debug] [MainThread]: Tracking: tracking
[0m15:35:23.079150 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc4d0fd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc4d0f9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc4d93c90>]}
[0m15:35:23.885122 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:35:23.886187 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:35:23.887980 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m15:35:23.888867 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:35:23.890386 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:35:23.893905 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m15:35:23.906529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '57c9b99e-d84d-4c63-ab39-79cfe0158fee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b2d7ddb50>]}
[0m15:35:23.911654 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd22fc51f-aadf-401b-816b-d7430c6265f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc4b357d0>]}
[0m15:35:23.914878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '57c9b99e-d84d-4c63-ab39-79cfe0158fee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b27d05210>]}
[0m15:35:23.916420 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m15:35:23.918066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '57c9b99e-d84d-4c63-ab39-79cfe0158fee', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b27d87790>]}
[0m15:35:23.919097 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd22fc51f-aadf-401b-816b-d7430c6265f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc4c54290>]}
[0m15:35:23.920295 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m15:35:23.921791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd22fc51f-aadf-401b-816b-d7430c6265f0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc4d0aa50>]}
[0m15:35:23.921784 [info ] [MainThread]: 
[0m15:35:23.924314 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:35:23.925676 [info ] [MainThread]: 
[0m15:35:23.927939 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m15:35:23.928437 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:35:23.929381 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:23.930285 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m15:35:23.931385 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m15:35:23.932489 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:23.933405 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:35:23.933560 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m15:35:23.934366 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m15:35:23.935519 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m15:35:23.937049 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:35:23.937151 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b27d22450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b27d22050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5b27d22b10>]}
[0m15:35:23.938067 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m15:35:23.938402 [debug] [MainThread]: Flushing usage events
[0m15:35:23.939144 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m15:35:23.940861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc4c71a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc4c71410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbcc4c71cd0>]}
[0m15:35:23.942375 [debug] [MainThread]: Flushing usage events


============================== 2023-02-18 15:35:25.053009 | 3b376f3b-3179-4a8e-ad61-19ebf12a1a39 ==============================
[0m15:35:25.053041 [info ] [MainThread]: Running with dbt=1.3.0
[0m15:35:25.054245 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:35:25.054920 [debug] [MainThread]: Tracking: tracking
[0m15:35:25.056559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c5580810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c5580c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c5580790>]}
[0m15:35:25.850415 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:35:25.851571 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:35:25.853534 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m15:35:25.874039 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b376f3b-3179-4a8e-ad61-19ebf12a1a39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c52c2bd0>]}
[0m15:35:25.881087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b376f3b-3179-4a8e-ad61-19ebf12a1a39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c5422bd0>]}
[0m15:35:25.883032 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m15:35:25.885232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b376f3b-3179-4a8e-ad61-19ebf12a1a39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c54dee10>]}
[0m15:35:25.890242 [info ] [MainThread]: 
[0m15:35:25.892668 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:35:25.895452 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m15:35:25.896616 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:25.897582 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m15:35:25.900202 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:35:25.901254 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m15:35:25.902541 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m15:35:25.904868 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c543f790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c543f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe1c543fcd0>]}
[0m15:35:25.906961 [debug] [MainThread]: Flushing usage events


============================== 2023-02-18 15:35:38.145475 | 944d1dd7-6959-4d26-95a8-7f9dc619d672 ==============================
[0m15:35:38.145526 [info ] [MainThread]: Running with dbt=1.3.0
[0m15:35:38.147219 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:35:38.148263 [debug] [MainThread]: Tracking: tracking
[0m15:35:38.150647 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a48e3cbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a48e3cdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a48d98f50>]}


============================== 2023-02-18 15:35:38.165502 | 49d53dc8-3323-4e5d-8f0d-c2206ff0b04c ==============================
[0m15:35:38.165561 [info ] [MainThread]: Running with dbt=1.3.0
[0m15:35:38.167252 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:35:38.168158 [debug] [MainThread]: Tracking: tracking
[0m15:35:38.170291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752aad7c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752aad7d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752aad7e90>]}
[0m15:35:38.938550 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:35:38.939258 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:35:38.939555 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:35:38.940201 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:35:38.941672 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m15:35:38.941443 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m15:35:38.956489 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '944d1dd7-6959-4d26-95a8-7f9dc619d672', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a48be44d0>]}
[0m15:35:38.957770 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '49d53dc8-3323-4e5d-8f0d-c2206ff0b04c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752a8424d0>]}
[0m15:35:38.964058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '944d1dd7-6959-4d26-95a8-7f9dc619d672', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a48cf9150>]}
[0m15:35:38.965789 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m15:35:38.965885 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '49d53dc8-3323-4e5d-8f0d-c2206ff0b04c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752a996cd0>]}
[0m15:35:38.967125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '944d1dd7-6959-4d26-95a8-7f9dc619d672', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a4a7d4610>]}
[0m15:35:38.967092 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m15:35:38.968513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '49d53dc8-3323-4e5d-8f0d-c2206ff0b04c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752aaf3990>]}
[0m15:35:38.969953 [info ] [MainThread]: 
[0m15:35:38.971458 [info ] [MainThread]: 
[0m15:35:38.971772 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:35:38.973974 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:35:38.974400 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m15:35:38.975774 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:38.976885 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m15:35:38.976955 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m15:35:38.977852 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:38.978861 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m15:35:38.980259 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:35:38.981480 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m15:35:38.982549 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m15:35:38.982823 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:35:38.984282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a48d17cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a48d17e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6a48d17f90>]}
[0m15:35:38.984157 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m15:35:38.985404 [debug] [MainThread]: Flushing usage events
[0m15:35:38.985609 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m15:35:38.987607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752a9b41d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752a9b4510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f752a9b4bd0>]}
[0m15:35:38.988805 [debug] [MainThread]: Flushing usage events


============================== 2023-02-18 15:35:46.376094 | c4a8b36e-a32e-4992-a97c-1a6df9fe1f8e ==============================
[0m15:35:46.376126 [info ] [MainThread]: Running with dbt=1.3.0
[0m15:35:46.377497 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:35:46.378194 [debug] [MainThread]: Tracking: tracking
[0m15:35:46.379807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96da26f8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96da26f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96da1b0dd0>]}
[0m15:35:47.097305 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:35:47.098226 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:35:47.099627 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m15:35:47.110742 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c4a8b36e-a32e-4992-a97c-1a6df9fe1f8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96d9ffcfd0>]}
[0m15:35:47.118916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c4a8b36e-a32e-4992-a97c-1a6df9fe1f8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96da113090>]}
[0m15:35:47.120162 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m15:35:47.121566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c4a8b36e-a32e-4992-a97c-1a6df9fe1f8e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96da923ad0>]}
[0m15:35:47.125530 [info ] [MainThread]: 
[0m15:35:47.127546 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:35:47.129919 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m15:35:47.131193 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:47.132266 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m15:35:47.134512 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:35:47.135388 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m15:35:47.136081 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m15:35:47.137100 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96da12f2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96da12f750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96da12fad0>]}
[0m15:35:47.138005 [debug] [MainThread]: Flushing usage events


============================== 2023-02-18 15:35:51.912091 | 7549d208-677f-48bf-a9d8-12506fba2d7f ==============================
[0m15:35:51.912123 [info ] [MainThread]: Running with dbt=1.3.0
[0m15:35:51.913369 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:35:51.914068 [debug] [MainThread]: Tracking: tracking
[0m15:35:51.915891 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b9c1c7850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b9c1c77d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b9c10ae10>]}
[0m15:35:52.613570 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:35:52.614840 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:35:52.617020 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m15:35:52.638391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7549d208-677f-48bf-a9d8-12506fba2d7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b97f30210>]}
[0m15:35:52.644046 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7549d208-677f-48bf-a9d8-12506fba2d7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b9c06a550>]}
[0m15:35:52.645175 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m15:35:52.646357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7549d208-677f-48bf-a9d8-12506fba2d7f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b9c0e6790>]}
[0m15:35:52.650302 [info ] [MainThread]: 
[0m15:35:52.654417 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:35:52.657360 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m15:35:52.658307 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:52.659265 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m15:35:52.661843 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:35:52.662883 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m15:35:52.664132 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m15:35:52.665528 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b9c087790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b9c087b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7b9c087290>]}
[0m15:35:52.668322 [debug] [MainThread]: Flushing usage events


============================== 2023-02-18 15:35:53.432764 | 4422cab9-f0eb-469d-b09a-0bede8af83fe ==============================
[0m15:35:53.432792 [info ] [MainThread]: Running with dbt=1.3.0
[0m15:35:53.433904 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:35:53.434865 [debug] [MainThread]: Tracking: tracking
[0m15:35:53.436757 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadb5387910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadb5387890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadb52cae50>]}
[0m15:35:54.100545 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:35:54.103071 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:35:54.104680 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m15:35:54.115935 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4422cab9-f0eb-469d-b09a-0bede8af83fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadb50cc390>]}
[0m15:35:54.122379 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4422cab9-f0eb-469d-b09a-0bede8af83fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadb522a990>]}
[0m15:35:54.123612 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m15:35:54.124634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4422cab9-f0eb-469d-b09a-0bede8af83fe', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadb52e2c50>]}
[0m15:35:54.127675 [info ] [MainThread]: 
[0m15:35:54.129684 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:35:54.131776 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m15:35:54.132672 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:54.133435 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m15:35:54.136074 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:35:54.137046 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m15:35:54.137796 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m15:35:54.138953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadb52472d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadb52477d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fadb5247e90>]}
[0m15:35:54.140023 [debug] [MainThread]: Flushing usage events


============================== 2023-02-18 15:35:58.962106 | 2a2d55f8-3657-454c-bf9e-13ce3c0dc5d6 ==============================
[0m15:35:58.962148 [info ] [MainThread]: Running with dbt=1.3.0
[0m15:35:58.964387 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:35:58.966075 [debug] [MainThread]: Tracking: tracking
[0m15:35:58.968395 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f692f27ccd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f692f31db10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f692f31d690>]}
[0m15:35:59.676951 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:35:59.678104 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:35:59.680488 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m15:35:59.690966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2a2d55f8-3657-454c-bf9e-13ce3c0dc5d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f692f0a2750>]}
[0m15:35:59.696807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2a2d55f8-3657-454c-bf9e-13ce3c0dc5d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f692f1c1050>]}
[0m15:35:59.698087 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m15:35:59.699771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2a2d55f8-3657-454c-bf9e-13ce3c0dc5d6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f692f2ab3d0>]}
[0m15:35:59.702527 [info ] [MainThread]: 
[0m15:35:59.704036 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:35:59.706319 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m15:35:59.707389 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:35:59.708164 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m15:35:59.710505 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:35:59.711458 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m15:35:59.712910 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m15:35:59.714368 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f692f1de510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f692f1ded50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f692f1de710>]}
[0m15:35:59.715705 [debug] [MainThread]: Flushing usage events


============================== 2023-02-18 15:36:04.307967 | 16b80356-11d3-4de7-bd1c-9d7b62fa1232 ==============================
[0m15:36:04.307996 [info ] [MainThread]: Running with dbt=1.3.0
[0m15:36:04.309276 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m15:36:04.310010 [debug] [MainThread]: Tracking: tracking
[0m15:36:04.311908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27cd42bcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27cd42be10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27cd42bc50>]}
[0m15:36:04.991488 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m15:36:04.992312 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m15:36:04.993684 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m15:36:05.003996 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '16b80356-11d3-4de7-bd1c-9d7b62fa1232', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27cd1cca10>]}
[0m15:36:05.008727 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '16b80356-11d3-4de7-bd1c-9d7b62fa1232', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27cd2ea310>]}
[0m15:36:05.009725 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m15:36:05.011051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '16b80356-11d3-4de7-bd1c-9d7b62fa1232', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27cd447890>]}
[0m15:36:05.013036 [info ] [MainThread]: 
[0m15:36:05.014416 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m15:36:05.016199 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m15:36:05.017008 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m15:36:05.018058 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m15:36:05.020249 [debug] [MainThread]: Connection 'master' was properly closed.
[0m15:36:05.021246 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m15:36:05.022210 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m15:36:05.023383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27cd3080d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27cd308590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f27cd308d10>]}
[0m15:36:05.024383 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 00:51:30.263198 | 92664721-79ef-4e2b-a1c2-6b29dfb1fd62 ==============================
[0m00:51:30.263225 [info ] [MainThread]: Running with dbt=1.3.0
[0m00:51:30.273902 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m00:51:30.274552 [debug] [MainThread]: Tracking: tracking
[0m00:51:30.276013 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ddaaf3d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ddaaf36d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ddab79c90>]}
[0m00:51:31.031942 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:51:31.033120 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:51:31.034223 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m00:51:31.045065 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '92664721-79ef-4e2b-a1c2-6b29dfb1fd62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0dda924210>]}
[0m00:51:31.050329 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '92664721-79ef-4e2b-a1c2-6b29dfb1fd62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ddaa38290>]}
[0m00:51:31.051177 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m00:51:31.052161 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '92664721-79ef-4e2b-a1c2-6b29dfb1fd62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ddaadf410>]}
[0m00:51:31.055745 [info ] [MainThread]: 
[0m00:51:31.057649 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m00:51:31.059441 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m00:51:31.060240 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:51:31.060962 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m00:51:31.062808 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:51:31.063391 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m00:51:31.064103 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m00:51:31.064919 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ddaa56390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ddaa56850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0ddaa56a10>]}
[0m00:51:31.065662 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 00:51:52.973672 | 91c771f0-8336-4903-9371-6a1f25ba1521 ==============================
[0m00:51:52.973714 [info ] [MainThread]: Running with dbt=1.3.0
[0m00:51:52.975436 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m00:51:52.976315 [debug] [MainThread]: Tracking: tracking
[0m00:51:52.978691 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd34eabe10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd34eabc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd34eabdd0>]}
[0m00:51:53.762906 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:51:53.763960 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:51:53.765745 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m00:51:53.782772 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '91c771f0-8336-4903-9371-6a1f25ba1521', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd34c14310>]}
[0m00:51:53.790369 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '91c771f0-8336-4903-9371-6a1f25ba1521', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd34d68050>]}
[0m00:51:53.791753 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m00:51:53.793207 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '91c771f0-8336-4903-9371-6a1f25ba1521', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd34e62b10>]}
[0m00:51:53.796439 [info ] [MainThread]: 
[0m00:51:53.798940 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m00:51:53.801282 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m00:51:53.802339 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:51:53.803417 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m00:51:53.806374 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:51:53.807340 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m00:51:53.808337 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m00:51:53.809673 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd34d86650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd34d86a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd34d86c50>]}
[0m00:51:53.810798 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 00:59:30.266531 | f1c48859-9505-4634-a6a5-21c1c445813f ==============================
[0m00:59:30.266562 [info ] [MainThread]: Running with dbt=1.3.0
[0m00:59:30.268489 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m00:59:30.269152 [debug] [MainThread]: Tracking: tracking
[0m00:59:30.270836 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9c3f7e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9c498c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9c498790>]}


============================== 2023-02-19 00:59:30.319639 | 0d900f95-ac09-4818-be2e-de3ac87bb9dd ==============================
[0m00:59:30.319683 [info ] [MainThread]: Running with dbt=1.3.0
[0m00:59:30.321387 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m00:59:30.322307 [debug] [MainThread]: Tracking: tracking
[0m00:59:30.324686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55c0718910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55c0718d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55c0659e50>]}
[0m00:59:30.892541 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:59:30.893408 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:59:30.894725 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m00:59:30.906201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f1c48859-9505-4634-a6a5-21c1c445813f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9c224290>]}
[0m00:59:30.911566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f1c48859-9505-4634-a6a5-21c1c445813f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9c33c690>]}
[0m00:59:30.912524 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m00:59:30.913555 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f1c48859-9505-4634-a6a5-21c1c445813f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9c3ccd10>]}
[0m00:59:30.917622 [info ] [MainThread]: 
[0m00:59:30.919404 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m00:59:30.921528 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m00:59:30.922345 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:59:30.923225 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m00:59:30.925475 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:59:30.926217 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m00:59:30.927102 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m00:59:30.928275 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9c358210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9c358690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdb9c3589d0>]}
[0m00:59:30.929483 [debug] [MainThread]: Flushing usage events
[0m00:59:30.966258 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:59:30.967676 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:59:30.968876 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m00:59:30.981193 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0d900f95-ac09-4818-be2e-de3ac87bb9dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55c0465250>]}
[0m00:59:30.986700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0d900f95-ac09-4818-be2e-de3ac87bb9dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55c05bba10>]}
[0m00:59:30.987764 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m00:59:30.988816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0d900f95-ac09-4818-be2e-de3ac87bb9dd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55c06fadd0>]}
[0m00:59:30.990992 [info ] [MainThread]: 
[0m00:59:30.992703 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m00:59:30.994650 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m00:59:30.995552 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:59:30.996269 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m00:59:30.997996 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:59:30.998596 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m00:59:30.999234 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m00:59:31.000700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55c05d85d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55c05d8a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f55c05d8bd0>]}
[0m00:59:31.001535 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 00:59:31.223088 | 0677c020-18b3-4b26-8757-0d303fba827d ==============================
[0m00:59:31.223113 [info ] [MainThread]: Running with dbt=1.3.0
[0m00:59:31.224579 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m00:59:31.225285 [debug] [MainThread]: Tracking: tracking
[0m00:59:31.226818 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0d727c990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0e10f4b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0d731d6d0>]}
[0m00:59:31.817631 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:59:31.818456 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:59:31.819611 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m00:59:31.827432 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0677c020-18b3-4b26-8757-0d303fba827d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0d70a9190>]}
[0m00:59:31.832552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0677c020-18b3-4b26-8757-0d303fba827d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0d71c12d0>]}
[0m00:59:31.833827 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m00:59:31.834798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0677c020-18b3-4b26-8757-0d303fba827d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0dd4b8690>]}
[0m00:59:31.836594 [info ] [MainThread]: 
[0m00:59:31.837846 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m00:59:31.839431 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m00:59:31.840187 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:59:31.840918 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m00:59:31.842804 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:59:31.843443 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m00:59:31.844334 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m00:59:31.845402 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0d71df650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0d71dfa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff0d71df910>]}
[0m00:59:31.846182 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 00:59:42.084786 | 5253242f-6bc0-42e7-9ff2-17754b3ef1b7 ==============================
[0m00:59:42.084816 [info ] [MainThread]: Running with dbt=1.3.0


============================== 2023-02-19 00:59:42.084860 | 86781a8c-de1b-4e24-a891-19ef0e00def8 ==============================
[0m00:59:42.084896 [info ] [MainThread]: Running with dbt=1.3.0
[0m00:59:42.086278 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m00:59:42.086281 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m00:59:42.087155 [debug] [MainThread]: Tracking: tracking
[0m00:59:42.087124 [debug] [MainThread]: Tracking: tracking
[0m00:59:42.088923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91196e6650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91196e6c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f911976cc10>]}
[0m00:59:42.089168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe52b8b3810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe52b8b3790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe52b7f5dd0>]}
[0m00:59:42.635196 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:59:42.636091 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:59:42.637426 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m00:59:42.644393 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:59:42.645262 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:59:42.646579 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m00:59:42.648685 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5253242f-6bc0-42e7-9ff2-17754b3ef1b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe52b80ded0>]}
[0m00:59:42.654225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5253242f-6bc0-42e7-9ff2-17754b3ef1b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe52b755350>]}
[0m00:59:42.655156 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m00:59:42.656105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5253242f-6bc0-42e7-9ff2-17754b3ef1b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe54d1a6650>]}
[0m00:59:42.657679 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '86781a8c-de1b-4e24-a891-19ef0e00def8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f911950c990>]}
[0m00:59:42.658462 [info ] [MainThread]: 
[0m00:59:42.660061 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m00:59:42.662150 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m00:59:42.662651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '86781a8c-de1b-4e24-a891-19ef0e00def8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f911962b4d0>]}
[0m00:59:42.662912 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:59:42.663530 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m00:59:42.663777 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m00:59:42.664529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '86781a8c-de1b-4e24-a891-19ef0e00def8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f91196a68d0>]}
[0m00:59:42.666412 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:59:42.667081 [info ] [MainThread]: 
[0m00:59:42.667186 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m00:59:42.668035 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m00:59:42.668781 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m00:59:42.669238 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe52b7725d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe52b772a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe52b772bd0>]}
[0m00:59:42.670236 [debug] [MainThread]: Flushing usage events
[0m00:59:42.670874 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m00:59:42.671647 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:59:42.672412 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m00:59:42.674736 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:59:42.675394 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m00:59:42.676058 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m00:59:42.677015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f911964a390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f911964a850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f911964aa10>]}
[0m00:59:42.677995 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 00:59:52.862026 | 46907fc2-69ad-4b27-9d66-66e25c3d3fff ==============================
[0m00:59:52.862073 [info ] [MainThread]: Running with dbt=1.3.0
[0m00:59:52.865559 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m00:59:52.868218 [debug] [MainThread]: Tracking: tracking
[0m00:59:52.871340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5875205890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5875121750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5875205810>]}
[0m00:59:53.926061 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:59:53.927158 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:59:53.928877 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m00:59:53.967484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '46907fc2-69ad-4b27-9d66-66e25c3d3fff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5874f90210>]}
[0m00:59:53.973176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '46907fc2-69ad-4b27-9d66-66e25c3d3fff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58750a7290>]}
[0m00:59:53.974244 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m00:59:53.975455 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '46907fc2-69ad-4b27-9d66-66e25c3d3fff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f587519f8d0>]}
[0m00:59:53.978686 [info ] [MainThread]: 
[0m00:59:53.981120 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m00:59:53.987414 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m00:59:53.989289 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:59:53.990273 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m00:59:53.992381 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:59:53.993075 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m00:59:53.993968 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m00:59:53.995377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58750c3490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58750c3c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58750c3690>]}
[0m00:59:53.996517 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 00:59:54.983470 | 18f6606b-e7a4-471a-8e6e-5d19a42f7357 ==============================
[0m00:59:54.983515 [info ] [MainThread]: Running with dbt=1.3.0
[0m00:59:54.996878 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m00:59:55.007461 [debug] [MainThread]: Tracking: tracking
[0m00:59:55.015596 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d6098810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d6098c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d6098790>]}


============================== 2023-02-19 00:59:55.020961 | d813271f-985c-4277-84d7-ed0ad8d690de ==============================
[0m00:59:55.021023 [info ] [MainThread]: Running with dbt=1.3.0
[0m00:59:55.023942 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m00:59:55.027705 [debug] [MainThread]: Tracking: tracking
[0m00:59:55.030936 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feef1d8ea90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feef83a6b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feef1e30790>]}
[0m00:59:56.311627 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:59:56.312809 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:59:56.314920 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m00:59:56.331725 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '18f6606b-e7a4-471a-8e6e-5d19a42f7357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d5e25290>]}
[0m00:59:56.338643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '18f6606b-e7a4-471a-8e6e-5d19a42f7357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d5f3b3d0>]}
[0m00:59:56.340258 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m00:59:56.341763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '18f6606b-e7a4-471a-8e6e-5d19a42f7357', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d5ff7710>]}
[0m00:59:56.346526 [info ] [MainThread]: 
[0m00:59:56.348892 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m00:59:56.351688 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m00:59:56.352638 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:59:56.353726 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m00:59:56.356282 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:59:56.357064 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m00:59:56.357929 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m00:59:56.359547 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d5f584d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d5f58110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f70d5f58bd0>]}
[0m00:59:56.360697 [debug] [MainThread]: Flushing usage events
[0m00:59:56.379433 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m00:59:56.380777 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m00:59:56.382842 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m00:59:56.398049 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd813271f-985c-4277-84d7-ed0ad8d690de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feef1bbc190>]}
[0m00:59:56.403591 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd813271f-985c-4277-84d7-ed0ad8d690de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feef1cd3250>]}
[0m00:59:56.405021 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m00:59:56.406707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd813271f-985c-4277-84d7-ed0ad8d690de', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fef0f5a2510>]}
[0m00:59:56.409831 [info ] [MainThread]: 
[0m00:59:56.412216 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m00:59:56.415232 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m00:59:56.416381 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m00:59:56.417309 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m00:59:56.420039 [debug] [MainThread]: Connection 'master' was properly closed.
[0m00:59:56.421025 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m00:59:56.422144 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m00:59:56.423804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feef1cf2990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feef1cf2e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7feef1cf2350>]}
[0m00:59:56.424960 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 01:00:04.738726 | 578b59cf-43a0-44c7-a543-c0d6ce6c6a39 ==============================
[0m01:00:04.738752 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:00:04.740005 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:00:04.740631 [debug] [MainThread]: Tracking: tracking
[0m01:00:04.742058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aae7afd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aafe13d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aae7af910>]}
[0m01:00:05.435449 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:00:05.436433 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:00:05.437681 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m01:00:05.446216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '578b59cf-43a0-44c7-a543-c0d6ce6c6a39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aae53a450>]}
[0m01:00:05.452284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '578b59cf-43a0-44c7-a543-c0d6ce6c6a39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aae653150>]}
[0m01:00:05.453299 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:00:05.454903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '578b59cf-43a0-44c7-a543-c0d6ce6c6a39', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aae70ec10>]}
[0m01:00:05.457050 [info ] [MainThread]: 
[0m01:00:05.458469 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:00:05.460142 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:00:05.460919 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:00:05.461796 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m01:00:05.463588 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:00:05.464455 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m01:00:05.465537 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m01:00:05.466717 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aae66e690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aae66ee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1aae66e0d0>]}
[0m01:00:05.467659 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 01:00:06.444446 | 5cfd9878-840a-4178-a48f-4f0fdb5a3188 ==============================
[0m01:00:06.444471 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:00:06.445671 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:00:06.446280 [debug] [MainThread]: Tracking: tracking
[0m01:00:06.447565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b94519810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b9445bad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b9445bdd0>]}
[0m01:00:07.141545 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:00:07.142729 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:00:07.144058 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m01:00:07.155092 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5cfd9878-840a-4178-a48f-4f0fdb5a3188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b94264450>]}
[0m01:00:07.160943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5cfd9878-840a-4178-a48f-4f0fdb5a3188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b943bb190>]}
[0m01:00:07.162133 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:00:07.163563 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5cfd9878-840a-4178-a48f-4f0fdb5a3188', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b9443aa50>]}
[0m01:00:07.166477 [info ] [MainThread]: 
[0m01:00:07.168200 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:00:07.170659 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:00:07.171791 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:00:07.172661 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m01:00:07.174974 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:00:07.175850 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m01:00:07.176668 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m01:00:07.177861 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b943d86d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b943d8e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9b943d8110>]}
[0m01:00:07.178778 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:24:17.478022 | ac964868-8130-4571-9f2d-b7012b1dbadb ==============================
[0m05:24:17.478098 [info ] [MainThread]: Running with dbt=1.3.0


============================== 2023-02-19 05:24:17.478385 | 8e4fc9ff-3b1d-4cb8-aa2c-2eb31b15bdca ==============================
[0m05:24:17.478416 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:24:17.479546 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:24:17.479698 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:24:17.480307 [debug] [MainThread]: Tracking: tracking
[0m05:24:17.480412 [debug] [MainThread]: Tracking: tracking
[0m05:24:17.482203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74957de7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74957debd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74957de750>]}
[0m05:24:17.482203 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6e9bce650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6e9bba490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6e9c6fb10>]}
[0m05:24:17.971307 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:24:17.971306 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:24:17.972297 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:24:17.972298 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:24:17.973732 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:24:17.973748 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:24:17.983195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '8e4fc9ff-3b1d-4cb8-aa2c-2eb31b15bdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6eb59cf10>]}
[0m05:24:17.983857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ac964868-8130-4571-9f2d-b7012b1dbadb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7496958750>]}
[0m05:24:17.987590 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '8e4fc9ff-3b1d-4cb8-aa2c-2eb31b15bdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6e9b13550>]}
[0m05:24:17.988019 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ac964868-8130-4571-9f2d-b7012b1dbadb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f74956812d0>]}
[0m05:24:17.988565 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:24:17.988833 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:24:17.989634 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '8e4fc9ff-3b1d-4cb8-aa2c-2eb31b15bdca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6e9c53ad0>]}
[0m05:24:17.989715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac964868-8130-4571-9f2d-b7012b1dbadb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f749573ddd0>]}
[0m05:24:17.992857 [info ] [MainThread]: 
[0m05:24:17.993300 [info ] [MainThread]: 
[0m05:24:17.994606 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:24:17.995082 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:24:17.996389 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:24:17.996617 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:24:17.997166 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:24:17.997462 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:24:17.998276 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:24:17.998279 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:24:18.000190 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:24:18.000147 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:24:18.000896 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:24:18.000947 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:24:18.001554 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:24:18.001642 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:24:18.002406 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6e9b314d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6e9bca9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd6e9b31150>]}
[0m05:24:18.002677 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f749569e2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f749569e7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f749569ee90>]}
[0m05:24:18.003233 [debug] [MainThread]: Flushing usage events
[0m05:24:18.003605 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:24:18.520532 | a689e630-7819-40e6-8592-2132ff594848 ==============================
[0m05:24:18.520558 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:24:18.521796 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:24:18.522423 [debug] [MainThread]: Tracking: tracking
[0m05:24:18.523817 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cb05af850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cb05af7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cb2715410>]}
[0m05:24:19.128397 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:24:19.129687 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:24:19.131205 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:24:19.139080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a689e630-7819-40e6-8592-2132ff594848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cb033c410>]}
[0m05:24:19.146439 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a689e630-7819-40e6-8592-2132ff594848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cb0453350>]}
[0m05:24:19.147362 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:24:19.148301 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a689e630-7819-40e6-8592-2132ff594848', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cb2715410>]}
[0m05:24:19.150174 [info ] [MainThread]: 
[0m05:24:19.151539 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:24:19.153168 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:24:19.153993 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:24:19.154814 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:24:19.156746 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:24:19.157382 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:24:19.158505 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:24:19.159643 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cb04702d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cb0470750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0cb0470ad0>]}
[0m05:24:19.160606 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:24:28.848272 | da194b12-efa4-468d-9c3c-e84a2538546f ==============================
[0m05:24:28.848314 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:24:28.853054 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:24:28.854237 [debug] [MainThread]: Tracking: tracking
[0m05:24:28.857387 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f509458edd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f509458e750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5094613d10>]}
[0m05:24:29.915238 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:24:29.918603 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:24:29.920570 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:24:29.987214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'da194b12-efa4-468d-9c3c-e84a2538546f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f509443eed0>]}
[0m05:24:29.993910 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'da194b12-efa4-468d-9c3c-e84a2538546f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50944d3b10>]}
[0m05:24:29.994979 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:24:29.998144 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'da194b12-efa4-468d-9c3c-e84a2538546f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5094551a10>]}
[0m05:24:30.003750 [info ] [MainThread]: 
[0m05:24:30.010194 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:24:30.018792 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:24:30.023762 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:24:30.025617 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:24:30.030869 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:24:30.032480 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:24:30.034211 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:24:30.035838 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50944f06d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50944f0ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f50944f0990>]}
[0m05:24:30.037053 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:24:31.011336 | 5ab28153-243c-4969-9509-50fb3dbcaa48 ==============================
[0m05:24:31.011372 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:24:31.012948 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:24:31.013768 [debug] [MainThread]: Tracking: tracking
[0m05:24:31.016120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba5c247850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba5c247c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba5c2477d0>]}


============================== 2023-02-19 05:24:31.046278 | bedf85d2-0e64-4d77-9fd2-041ee70b4a6a ==============================
[0m05:24:31.046335 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:24:31.049184 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:24:31.050577 [debug] [MainThread]: Tracking: tracking
[0m05:24:31.052715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0198446f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0198446bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01984c9e90>]}
[0m05:24:31.887420 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:24:31.888302 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:24:31.889704 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:24:31.902282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5ab28153-243c-4969-9509-50fb3dbcaa48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba57f6f210>]}
[0m05:24:31.906769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5ab28153-243c-4969-9509-50fb3dbcaa48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba5c0e9b50>]}
[0m05:24:31.907658 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:24:31.908788 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5ab28153-243c-4969-9509-50fb3dbcaa48', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba5c1a5e50>]}
[0m05:24:31.910929 [info ] [MainThread]: 
[0m05:24:31.912984 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:24:31.915435 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:24:31.916428 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:24:31.917179 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:24:31.919017 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:24:31.919720 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:24:31.920400 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:24:31.921344 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba5c107890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba5c107b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba5c107290>]}
[0m05:24:31.922264 [debug] [MainThread]: Flushing usage events
[0m05:24:31.925167 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:24:31.926261 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:24:31.928260 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:24:31.943118 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'bedf85d2-0e64-4d77-9fd2-041ee70b4a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01982742d0>]}
[0m05:24:31.948629 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'bedf85d2-0e64-4d77-9fd2-041ee70b4a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f019838b150>]}
[0m05:24:31.949789 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:24:31.950814 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'bedf85d2-0e64-4d77-9fd2-041ee70b4a6a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0198442750>]}
[0m05:24:31.953139 [info ] [MainThread]: 
[0m05:24:31.954771 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:24:31.956475 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:24:31.957297 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:24:31.957987 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:24:31.959936 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:24:31.960714 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:24:31.961355 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:24:31.962414 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01983a96d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01983a99d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f01983a90d0>]}
[0m05:24:31.963255 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:24:43.210828 | 32a33d3f-2d78-4a08-bd51-f89b062969ed ==============================
[0m05:24:43.210871 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:24:43.213994 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:24:43.218016 [debug] [MainThread]: Tracking: tracking
[0m05:24:43.223661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0caaa1790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0caaa1710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ca9e2d90>]}
[0m05:24:44.078682 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:24:44.080038 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:24:44.081652 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:24:44.099526 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '32a33d3f-2d78-4a08-bd51-f89b062969ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ca7ec4d0>]}
[0m05:24:44.108598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '32a33d3f-2d78-4a08-bd51-f89b062969ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ca943350>]}
[0m05:24:44.110592 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:24:44.115577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '32a33d3f-2d78-4a08-bd51-f89b062969ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ca9d5bd0>]}
[0m05:24:44.120228 [info ] [MainThread]: 
[0m05:24:44.125701 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:24:44.129210 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:24:44.130602 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:24:44.131673 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:24:44.134016 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:24:44.134828 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:24:44.135628 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:24:44.137417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ca960250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ca960750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0ca960e10>]}
[0m05:24:44.139879 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:24:45.169547 | 32c16cbd-aab4-4445-872c-f471f51bfe37 ==============================
[0m05:24:45.169576 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:24:45.170776 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:24:45.171897 [debug] [MainThread]: Tracking: tracking
[0m05:24:45.173907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4321098810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4321098c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4321098790>]}


============================== 2023-02-19 05:24:45.276224 | 1726c10b-0347-46c5-9d7b-cdc8a0c43062 ==============================
[0m05:24:45.276274 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:24:45.277774 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:24:45.278756 [debug] [MainThread]: Tracking: tracking
[0m05:24:45.281252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f01b5ba50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f01bfcc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f01bfc790>]}
[0m05:24:45.880626 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:24:45.881840 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:24:45.883662 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:24:45.900812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '32c16cbd-aab4-4445-872c-f471f51bfe37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4320e25410>]}
[0m05:24:45.908803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '32c16cbd-aab4-4445-872c-f471f51bfe37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4320f3b250>]}
[0m05:24:45.910297 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:24:45.911966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '32c16cbd-aab4-4445-872c-f471f51bfe37', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4320ff7d10>]}
[0m05:24:45.915677 [info ] [MainThread]: 
[0m05:24:45.918043 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:24:45.920797 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:24:45.922623 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:24:45.923630 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:24:45.926551 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:24:45.927566 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:24:45.928660 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:24:45.930448 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4320f58250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4320f58750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4320f58e10>]}
[0m05:24:45.931552 [debug] [MainThread]: Flushing usage events
[0m05:24:45.998392 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:24:45.999483 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:24:46.001380 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:24:46.016425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1726c10b-0347-46c5-9d7b-cdc8a0c43062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f019817d0>]}
[0m05:24:46.024350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1726c10b-0347-46c5-9d7b-cdc8a0c43062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f01aa0850>]}
[0m05:24:46.025635 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:24:46.027015 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1726c10b-0347-46c5-9d7b-cdc8a0c43062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f01b26b90>]}
[0m05:24:46.030288 [info ] [MainThread]: 
[0m05:24:46.032466 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:24:46.034807 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:24:46.035777 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:24:46.036811 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:24:46.040547 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:24:46.041645 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:24:46.042688 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:24:46.044031 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f01abc690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f01abca90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2f01abc950>]}
[0m05:24:46.045076 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:24:55.862909 | 983bb900-54c4-4e7b-9f1d-1c3e955ce246 ==============================
[0m05:24:55.862952 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:24:55.865546 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:24:55.866554 [debug] [MainThread]: Tracking: tracking
[0m05:24:55.868220 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9279ff8d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9279ff8c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9279ff8f10>]}
[0m05:24:56.677973 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:24:56.678862 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:24:56.681643 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:24:56.697400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '983bb900-54c4-4e7b-9f1d-1c3e955ce246', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9279da1290>]}
[0m05:24:56.702791 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '983bb900-54c4-4e7b-9f1d-1c3e955ce246', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9279eb6cd0>]}
[0m05:24:56.703756 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:24:56.704929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '983bb900-54c4-4e7b-9f1d-1c3e955ce246', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f927a012990>]}
[0m05:24:56.707840 [info ] [MainThread]: 
[0m05:24:56.710042 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:24:56.713365 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:24:56.714798 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:24:56.715862 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:24:56.718884 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:24:56.719906 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:24:56.720903 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:24:56.722569 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9279ed5490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9279ed5890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9279ed5a10>]}
[0m05:24:56.723839 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:24:57.471057 | 4e3be1f2-3e11-487a-ac7d-4b30333e49db ==============================
[0m05:24:57.471135 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:24:57.473457 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:24:57.474580 [debug] [MainThread]: Tracking: tracking
[0m05:24:57.477030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f657cfb7990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f657d058b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f657d058710>]}


============================== 2023-02-19 05:24:57.692128 | a07a0d71-5102-4c12-a6bb-f402ca04e7db ==============================
[0m05:24:57.692170 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:24:57.696827 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:24:57.697891 [debug] [MainThread]: Tracking: tracking
[0m05:24:57.700246 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fe8d54990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fe8d54e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fe8c9be10>]}
[0m05:24:58.842710 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:24:58.845148 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:24:58.847995 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:24:58.883945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4e3be1f2-3e11-487a-ac7d-4b30333e49db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f657cde5090>]}
[0m05:24:58.893930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4e3be1f2-3e11-487a-ac7d-4b30333e49db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f657cefc110>]}
[0m05:24:58.896145 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:24:58.898802 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4e3be1f2-3e11-487a-ac7d-4b30333e49db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6582adb350>]}
[0m05:24:58.905593 [info ] [MainThread]: 
[0m05:24:58.909807 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:24:58.914746 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:24:58.916017 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:24:58.917441 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:24:58.920817 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:24:58.922133 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:24:58.923966 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:24:58.926549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f657cf1a510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f657cf1a8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f657cf1a7d0>]}
[0m05:24:58.930070 [debug] [MainThread]: Flushing usage events
[0m05:24:59.101871 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:24:59.103632 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:24:59.105578 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:24:59.127857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a07a0d71-5102-4c12-a6bb-f402ca04e7db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fe8ae43d0>]}
[0m05:24:59.134695 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a07a0d71-5102-4c12-a6bb-f402ca04e7db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fe8bfb150>]}
[0m05:24:59.135920 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:24:59.137642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a07a0d71-5102-4c12-a6bb-f402ca04e7db', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa00663ae10>]}
[0m05:24:59.141609 [info ] [MainThread]: 
[0m05:24:59.144702 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:24:59.147753 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:24:59.148921 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:24:59.150532 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:24:59.154629 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:24:59.155887 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:24:59.156888 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:24:59.158389 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fe8c17490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fe8c17950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fe8c17b10>]}
[0m05:24:59.161803 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:25:10.630570 | 56ee3cfd-d9bc-4227-99fe-af58f1fe9338 ==============================
[0m05:25:10.630619 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:25:10.632198 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:25:10.632944 [debug] [MainThread]: Tracking: tracking
[0m05:25:10.635107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fcf332750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fcf3326d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fcf274d50>]}
[0m05:25:11.368493 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:25:11.369545 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:25:11.371007 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:25:11.386376 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '56ee3cfd-d9bc-4227-99fe-af58f1fe9338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fcf316c10>]}
[0m05:25:11.392467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '56ee3cfd-d9bc-4227-99fe-af58f1fe9338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fcf1d6ad0>]}
[0m05:25:11.393767 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:25:11.395214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '56ee3cfd-d9bc-4227-99fe-af58f1fe9338', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fcf253990>]}
[0m05:25:11.398385 [info ] [MainThread]: 
[0m05:25:11.401427 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:25:11.404336 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:25:11.405210 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:25:11.406060 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:25:11.408082 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:25:11.408808 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:25:11.409512 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:25:11.410546 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fcf1f2690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fcf1f2a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9fcf1f2950>]}
[0m05:25:11.411553 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:25:11.525613 | 7aa34271-af5c-497a-9932-22e436c4131a ==============================
[0m05:25:11.525645 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:25:11.527122 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:25:11.528171 [debug] [MainThread]: Tracking: tracking
[0m05:25:11.530350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0834266d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0834307c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0834307790>]}


============================== 2023-02-19 05:25:11.554427 | 5c060201-b19f-4dc4-bbcd-8fd4d3155a63 ==============================
[0m05:25:11.554461 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:25:11.555726 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:25:11.556574 [debug] [MainThread]: Tracking: tracking
[0m05:25:11.558705 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6500a6d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6500a6c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb6500a6c50>]}
[0m05:25:12.227937 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:25:12.228998 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:25:12.230967 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:25:12.247476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7aa34271-af5c-497a-9932-22e436c4131a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f083408b6d0>]}
[0m05:25:12.250110 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:25:12.251926 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:25:12.253514 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:25:12.254445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7aa34271-af5c-497a-9932-22e436c4131a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08341aa710>]}
[0m05:25:12.255648 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:25:12.257073 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7aa34271-af5c-497a-9932-22e436c4131a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f083afc98d0>]}
[0m05:25:12.260345 [info ] [MainThread]: 
[0m05:25:12.262811 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:25:12.265490 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:25:12.266234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5c060201-b19f-4dc4-bbcd-8fd4d3155a63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb64bea99d0>]}
[0m05:25:12.266632 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:25:12.268275 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:25:12.271311 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:25:12.272180 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:25:12.272580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5c060201-b19f-4dc4-bbcd-8fd4d3155a63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb64bfc7750>]}
[0m05:25:12.272907 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:25:12.273532 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:25:12.274199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08341c8690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08341c8a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08341c8950>]}
[0m05:25:12.274740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c060201-b19f-4dc4-bbcd-8fd4d3155a63', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb65005b610>]}
[0m05:25:12.275116 [debug] [MainThread]: Flushing usage events
[0m05:25:12.278045 [info ] [MainThread]: 
[0m05:25:12.280192 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:25:12.282444 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:25:12.283553 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:25:12.284995 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:25:12.287737 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:25:12.288584 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:25:12.289499 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:25:12.290811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb64bfe5a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb64bfe5d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb64bfe5d10>]}
[0m05:25:12.292057 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:25:24.203191 | ee3eb7bf-46fa-4753-b87b-429166d5c76d ==============================
[0m05:25:24.203219 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:25:24.204637 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:25:24.205420 [debug] [MainThread]: Tracking: tracking
[0m05:25:24.207173 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca2330550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca2330950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca23304d0>]}


============================== 2023-02-19 05:25:24.635545 | 2898468e-c7ab-48cd-a5f1-2689fde795f8 ==============================
[0m05:25:24.635592 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:25:24.637355 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:25:24.638224 [debug] [MainThread]: Tracking: tracking
[0m05:25:24.640357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ef72c37d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ef72c3bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ef72c3750>]}


============================== 2023-02-19 05:25:24.656012 | 6a84ca3d-22ec-4f2f-80b3-99c295c3c244 ==============================
[0m05:25:24.656062 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:25:24.658603 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:25:24.659882 [debug] [MainThread]: Tracking: tracking
[0m05:25:24.662277 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fad01b27e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fad01b27dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fad01b27e90>]}
[0m05:25:25.019490 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:25:25.020741 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:25:25.022938 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:25:25.047622 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ee3eb7bf-46fa-4753-b87b-429166d5c76d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca20b5210>]}
[0m05:25:25.067469 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ee3eb7bf-46fa-4753-b87b-429166d5c76d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca21d42d0>]}
[0m05:25:25.070447 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:25:25.075140 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ee3eb7bf-46fa-4753-b87b-429166d5c76d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca228fb10>]}
[0m05:25:25.085639 [info ] [MainThread]: 
[0m05:25:25.088988 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:25:25.098449 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:25:25.099946 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:25:25.103085 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:25:25.111913 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:25:25.115124 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:25:25.118679 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:25:25.126811 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca21f24d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca21f2890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4ca21f2790>]}
[0m05:25:25.130199 [debug] [MainThread]: Flushing usage events
[0m05:25:25.493795 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:25:25.494817 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:25:25.496545 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:25:25.504180 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:25:25.505477 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:25:25.509173 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:25:25.515832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2898468e-c7ab-48cd-a5f1-2689fde795f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ef7050290>]}
[0m05:25:25.521714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2898468e-c7ab-48cd-a5f1-2689fde795f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ef7167a90>]}
[0m05:25:25.522871 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:25:25.524882 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2898468e-c7ab-48cd-a5f1-2689fde795f8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ef7222d90>]}
[0m05:25:25.526565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6a84ca3d-22ec-4f2f-80b3-99c295c3c244', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fad018d3490>]}
[0m05:25:25.528781 [info ] [MainThread]: 
[0m05:25:25.530625 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:25:25.532428 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6a84ca3d-22ec-4f2f-80b3-99c295c3c244', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fad019e8950>]}
[0m05:25:25.532722 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:25:25.533663 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:25:25.533640 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:25:25.534545 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:25:25.534896 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6a84ca3d-22ec-4f2f-80b3-99c295c3c244', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fad01b43b50>]}
[0m05:25:25.537184 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:25:25.537983 [info ] [MainThread]: 
[0m05:25:25.538107 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:25:25.538997 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:25:25.541129 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:25:25.541006 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ef71847d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ef7184ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3ef71841d0>]}
[0m05:25:25.544718 [debug] [MainThread]: Flushing usage events
[0m05:25:25.545289 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:25:25.546456 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:25:25.547606 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:25:25.550314 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:25:25.551310 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:25:25.552258 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:25:25.553649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fad01a06a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fad01a06f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fad01a061d0>]}
[0m05:25:25.554814 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:25:47.339974 | 88acd598-6a72-41e8-8b2f-4ce500e03109 ==============================
[0m05:25:47.340019 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:25:47.341902 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:25:47.342873 [debug] [MainThread]: Tracking: tracking
[0m05:25:47.344916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1eda5e6dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1eda5e6b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1eda5e6e90>]}


============================== 2023-02-19 05:25:47.376082 | ac97775c-33d3-445c-9322-93fd4fc4b4f3 ==============================
[0m05:25:47.376126 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:25:47.378289 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:25:47.379136 [debug] [MainThread]: Tracking: tracking
[0m05:25:47.381442 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f890eef9d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f891426fc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f890eef9c90>]}
[0m05:25:48.046432 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:25:48.048083 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:25:48.049830 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:25:48.063722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '88acd598-6a72-41e8-8b2f-4ce500e03109', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1eda5e3e10>]}
[0m05:25:48.070214 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '88acd598-6a72-41e8-8b2f-4ce500e03109', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1eda52b510>]}
[0m05:25:48.071420 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:25:48.072714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '88acd598-6a72-41e8-8b2f-4ce500e03109', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1ef7faf710>]}
[0m05:25:48.075652 [info ] [MainThread]: 
[0m05:25:48.077550 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:25:48.079716 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:25:48.080704 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:25:48.081567 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:25:48.084053 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:25:48.085075 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:25:48.085892 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:25:48.087285 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1eda5495d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1eda549990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1eda549890>]}
[0m05:25:48.088393 [debug] [MainThread]: Flushing usage events
[0m05:25:48.105973 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:25:48.106968 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:25:48.108275 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:25:48.119404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ac97775c-33d3-445c-9322-93fd4fc4b4f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f890ef9b790>]}
[0m05:25:48.124680 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ac97775c-33d3-445c-9322-93fd4fc4b4f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f890ee3d310>]}
[0m05:25:48.125587 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:25:48.126697 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac97775c-33d3-445c-9322-93fd4fc4b4f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f891426fc50>]}
[0m05:25:48.129731 [info ] [MainThread]: 
[0m05:25:48.131850 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:25:48.133926 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:25:48.134957 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:25:48.135825 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:25:48.138830 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:25:48.139651 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:25:48.140431 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:25:48.142330 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f890ee5a690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f890ee5aa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f890ee5a950>]}
[0m05:25:48.143703 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:30:48.296349 | ea6f196a-70b4-4f7b-bce0-35ded2a75a19 ==============================
[0m05:30:48.296392 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:30:48.297844 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:30:48.298566 [debug] [MainThread]: Tracking: tracking
[0m05:30:48.300269 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc129404810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc129fd4510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc129404790>]}
[0m05:30:48.815086 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:30:48.816047 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:30:48.817127 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:30:48.824720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ea6f196a-70b4-4f7b-bce0-35ded2a75a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1291902d0>]}
[0m05:30:48.830849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ea6f196a-70b4-4f7b-bce0-35ded2a75a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1292a7810>]}
[0m05:30:48.831756 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:30:48.832859 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ea6f196a-70b4-4f7b-bce0-35ded2a75a19', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc129fd4510>]}
[0m05:30:48.835206 [info ] [MainThread]: 
[0m05:30:48.836779 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:30:48.838548 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:30:48.839443 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:30:48.840569 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:30:48.842930 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:30:48.843569 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:30:48.844121 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:30:48.844943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1292c3390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1292c3810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc1292c3590>]}
[0m05:30:48.845645 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:35:43.467293 | 063e26ef-ddd8-4160-a4ae-c5f7f6e964ad ==============================
[0m05:35:43.467330 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:35:43.468873 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:35:43.469789 [debug] [MainThread]: Tracking: tracking
[0m05:35:43.471587 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb27126f7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb271191850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb2711b1dd0>]}


============================== 2023-02-19 05:35:43.659506 | e5cc5a94-f783-4f1e-b741-8977aa5668a4 ==============================
[0m05:35:43.659533 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:35:43.661177 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:35:43.662112 [debug] [MainThread]: Tracking: tracking
[0m05:35:43.665833 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc618892cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc618892d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc618892bd0>]}
[0m05:35:43.997223 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 0 files added, 0 files changed.
[0m05:35:43.998184 [debug] [MainThread]: Partial parsing: deleted file: data_warehouse_analytics_engineer://models/example/test_source.sql
[0m05:35:43.999079 [debug] [MainThread]: Partial parsing: deleted file: data_warehouse_analytics_engineer://models/dimension_models/product_dimension_type_1.sql
[0m05:35:44.024912 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:35:44.038272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '063e26ef-ddd8-4160-a4ae-c5f7f6e964ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb270fff250>]}
[0m05:35:44.042987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '063e26ef-ddd8-4160-a4ae-c5f7f6e964ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb270fccb50>]}
[0m05:35:44.043813 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:35:44.044708 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '063e26ef-ddd8-4160-a4ae-c5f7f6e964ad', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb28eb962d0>]}
[0m05:35:44.046699 [warn ] [MainThread]: The selection criterion 'test_source' does not match any nodes
[0m05:35:44.048737 [info ] [MainThread]: 
[0m05:35:44.049559 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:35:44.050580 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb271085290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb271085310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb270fccb50>]}
[0m05:35:44.051412 [debug] [MainThread]: Flushing usage events
[0m05:35:44.169149 [debug] [MainThread]: Partial parsing enabled: 2 files deleted, 0 files added, 0 files changed.
[0m05:35:44.169935 [debug] [MainThread]: Partial parsing: deleted file: data_warehouse_analytics_engineer://models/dimension_models/product_dimension_type_1.sql
[0m05:35:44.170555 [debug] [MainThread]: Partial parsing: deleted file: data_warehouse_analytics_engineer://models/example/test_source.sql
[0m05:35:44.193507 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:35:44.203216 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e5cc5a94-f783-4f1e-b741-8977aa5668a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6185f22d0>]}
[0m05:35:44.208525 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e5cc5a94-f783-4f1e-b741-8977aa5668a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc618650cd0>]}
[0m05:35:44.209409 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:35:44.210225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e5cc5a94-f783-4f1e-b741-8977aa5668a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc61e1c2a10>]}
[0m05:35:44.211216 [warn ] [MainThread]: The selection criterion 'product_dimension_type_1' does not match any nodes
[0m05:35:44.213574 [info ] [MainThread]: 
[0m05:35:44.214374 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:35:44.215260 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc6187a2710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc618650c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc618650d10>]}
[0m05:35:44.215878 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:35:44.633581 | 96a0798f-1ee8-4fb8-9de7-d40482c80f03 ==============================
[0m05:35:44.633612 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:35:44.634904 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:35:44.635515 [debug] [MainThread]: Tracking: tracking
[0m05:35:44.637401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee5fba3690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee5fba3a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee5fba3610>]}
[0m05:35:45.415185 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:35:45.416635 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:35:45.420281 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:35:45.443630 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '96a0798f-1ee8-4fb8-9de7-d40482c80f03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee5f920a90>]}
[0m05:35:45.451568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '96a0798f-1ee8-4fb8-9de7-d40482c80f03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee5fabb350>]}
[0m05:35:45.452735 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:35:45.454048 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96a0798f-1ee8-4fb8-9de7-d40482c80f03', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee5fb025d0>]}
[0m05:35:45.457019 [info ] [MainThread]: 
[0m05:35:45.459464 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:35:45.463778 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:35:45.464931 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:35:45.466045 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:35:45.468481 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:35:45.469259 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:35:45.469995 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:35:45.470993 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee5fabbfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee5fa6c490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee5fa6c1d0>]}
[0m05:35:45.471859 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:35:55.843077 | a93cabbf-3744-490d-a1dd-9fab905ab140 ==============================
[0m05:35:55.843107 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:35:55.844356 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}


============================== 2023-02-19 05:35:55.844453 | 3f649aff-a449-4d6e-a053-113750770903 ==============================
[0m05:35:55.844484 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:35:55.844969 [debug] [MainThread]: Tracking: tracking
[0m05:35:55.846148 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:35:55.847851 [debug] [MainThread]: Tracking: tracking
[0m05:35:55.848131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f626ab44c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f626ab44d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f626ab44b90>]}
[0m05:35:55.849347 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff519530950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff519530d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5195308d0>]}
[0m05:35:56.273181 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:35:56.274108 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:35:56.275447 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:35:56.280227 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:35:56.281076 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:35:56.282401 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:35:56.285268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3f649aff-a449-4d6e-a053-113750770903', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5192b5450>]}
[0m05:35:56.291057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3f649aff-a449-4d6e-a053-113750770903', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff519448f90>]}
[0m05:35:56.292470 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:35:56.294195 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3f649aff-a449-4d6e-a053-113750770903', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff51948f850>]}
[0m05:35:56.295294 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a93cabbf-3744-490d-a1dd-9fab905ab140', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f626a8e5550>]}
[0m05:35:56.296407 [info ] [MainThread]: 
[0m05:35:56.297960 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:35:56.299905 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:35:56.300588 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a93cabbf-3744-490d-a1dd-9fab905ab140', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f626aa76d50>]}
[0m05:35:56.300722 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:35:56.301521 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:35:56.301556 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:35:56.302740 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a93cabbf-3744-490d-a1dd-9fab905ab140', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f626ab60850>]}
[0m05:35:56.304033 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:35:56.305067 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:35:56.305372 [info ] [MainThread]: 
[0m05:35:56.306131 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:35:56.306946 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:35:56.307334 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5193f7790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5193f7050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff5193f75d0>]}
[0m05:35:56.308208 [debug] [MainThread]: Flushing usage events
[0m05:35:56.309116 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:35:56.310029 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:35:56.310915 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:35:56.312865 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:35:56.313661 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:35:56.314499 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:35:56.315484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f626aa25250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f626aa25890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f626aa25490>]}
[0m05:35:56.316341 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:36:09.634748 | e5933e70-f464-418d-b618-5d79b196e0b7 ==============================
[0m05:36:09.634789 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:36:09.636638 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:36:09.637631 [debug] [MainThread]: Tracking: tracking
[0m05:36:09.639816 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6982487850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69823a8990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69823c9d90>]}
[0m05:36:10.763012 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:36:10.764135 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:36:10.765883 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:36:10.786595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e5933e70-f464-418d-b618-5d79b196e0b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69823e2b10>]}
[0m05:36:10.794651 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e5933e70-f464-418d-b618-5d79b196e0b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f698239f4d0>]}
[0m05:36:10.796019 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:36:10.797391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e5933e70-f464-418d-b618-5d79b196e0b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f69823acbd0>]}
[0m05:36:10.799214 [warn ] [MainThread]: The selection criterion 'test_source' does not match any nodes
[0m05:36:10.802078 [info ] [MainThread]: 
[0m05:36:10.803487 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:36:10.805421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f698239fa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f698239f210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f698239fcd0>]}
[0m05:36:10.806578 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:36:12.813103 | aea76c15-d89b-48a8-9d08-dd7a46f38d68 ==============================
[0m05:36:12.813130 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:36:12.814346 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:36:12.814977 [debug] [MainThread]: Tracking: tracking
[0m05:36:12.816550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc52a8d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc5852810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc52a8f10>]}


============================== 2023-02-19 05:36:12.871215 | ea4c6d52-ac33-47bc-8b3e-449b03a60931 ==============================
[0m05:36:12.871240 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:36:12.872386 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:36:12.873728 [debug] [MainThread]: Tracking: tracking
[0m05:36:12.875415 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24ff87cc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24ff91dad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24ff91d650>]}
[0m05:36:13.448398 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:36:13.449415 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:36:13.450859 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:36:13.462666 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'aea76c15-d89b-48a8-9d08-dd7a46f38d68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc504c550>]}
[0m05:36:13.469270 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'aea76c15-d89b-48a8-9d08-dd7a46f38d68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc51dcad0>]}
[0m05:36:13.470837 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:36:13.472765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'aea76c15-d89b-48a8-9d08-dd7a46f38d68', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc5852810>]}
[0m05:36:13.476218 [info ] [MainThread]: 
[0m05:36:13.478795 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:36:13.481219 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:36:13.482287 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:36:13.483140 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:36:13.485549 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:36:13.486458 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:36:13.487427 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:36:13.489939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc518c310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc518c9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7effc518c610>]}
[0m05:36:13.491480 [debug] [MainThread]: Flushing usage events
[0m05:36:13.516978 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:36:13.517988 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:36:13.519624 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:36:13.532319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ea4c6d52-ac33-47bc-8b3e-449b03a60931', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24ff6a2250>]}
[0m05:36:13.537933 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ea4c6d52-ac33-47bc-8b3e-449b03a60931', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24ff836fd0>]}
[0m05:36:13.540401 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:36:13.541912 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ea4c6d52-ac33-47bc-8b3e-449b03a60931', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2521266950>]}
[0m05:36:13.543716 [warn ] [MainThread]: The selection criterion 'product_dimension_type_1' does not match any nodes
[0m05:36:13.546311 [info ] [MainThread]: 
[0m05:36:13.547585 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:36:13.549185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24ff836d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24ff836ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24ff836fd0>]}
[0m05:36:13.550098 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:36:22.765813 | 82d950d3-eeb4-453a-a9d8-8894c7cb86c2 ==============================
[0m05:36:22.765844 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:36:22.767124 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:36:22.767871 [debug] [MainThread]: Tracking: tracking
[0m05:36:22.770133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08688afbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0869a03910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08687f2dd0>]}
[0m05:36:23.410426 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:36:23.411251 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:36:23.412405 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:36:23.423066 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '82d950d3-eeb4-453a-a9d8-8894c7cb86c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f086862c450>]}
[0m05:36:23.427880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '82d950d3-eeb4-453a-a9d8-8894c7cb86c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08687c7f10>]}
[0m05:36:23.428697 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:36:23.429636 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '82d950d3-eeb4-453a-a9d8-8894c7cb86c2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08687e38d0>]}
[0m05:36:23.433154 [info ] [MainThread]: 
[0m05:36:23.435476 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:36:23.437474 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:36:23.438254 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:36:23.438990 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:36:23.440756 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:36:23.441489 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:36:23.442125 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:36:23.443076 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f08687766d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0868776090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0868776510>]}
[0m05:36:23.443908 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:36:24.507981 | a55e4658-a7ff-490d-847e-f9215cd4d749 ==============================
[0m05:36:24.508004 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:36:24.509222 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:36:24.509939 [debug] [MainThread]: Tracking: tracking
[0m05:36:24.511353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f75310c7890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7531006b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7531006e90>]}
[0m05:36:25.154434 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:36:25.155537 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:36:25.156796 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example_1

[0m05:36:25.166037 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a55e4658-a7ff-490d-847e-f9215cd4d749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7530e4c0d0>]}
[0m05:36:25.171864 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a55e4658-a7ff-490d-847e-f9215cd4d749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7530fddcd0>]}
[0m05:36:25.172898 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:36:25.174034 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a55e4658-a7ff-490d-847e-f9215cd4d749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f754e9d4d10>]}
[0m05:36:25.176070 [info ] [MainThread]: 
[0m05:36:25.177472 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:36:25.179358 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:36:25.180696 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:36:25.181686 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:36:25.183741 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:36:25.184419 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:36:25.185199 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:36:25.186283 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7530f39190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7530f39450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7530f39a90>]}
[0m05:36:25.187208 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:42:51.851835 | ad40e91c-0859-41c3-8cd4-6bb4c65c22d9 ==============================
[0m05:42:51.851860 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:42:51.853271 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:42:51.853951 [debug] [MainThread]: Tracking: tracking
[0m05:42:51.855281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcabf812790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcabf812b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcabf84b990>]}
[0m05:42:51.942893 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m05:42:51.944281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ad40e91c-0859-41c3-8cd4-6bb4c65c22d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcabf6ea5d0>]}


============================== 2023-02-19 05:42:52.025980 | 47132c99-f6f1-4fdd-8551-e29b78604d6d ==============================
[0m05:42:52.026015 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:42:52.027892 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:42:52.029323 [debug] [MainThread]: Tracking: tracking
[0m05:42:52.034720 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f296f58dd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2951c7e650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2951c7e6d0>]}
[0m05:42:52.268138 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m05:42:52.270916 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '47132c99-f6f1-4fdd-8551-e29b78604d6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2951a8b650>]}
[0m05:42:52.692817 [debug] [MainThread]: Parsing macros/etc.sql
[0m05:42:52.698495 [debug] [MainThread]: Parsing macros/catalog.sql
[0m05:42:52.707279 [debug] [MainThread]: Parsing macros/adapters.sql
[0m05:42:52.773423 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m05:42:52.780045 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m05:42:52.798923 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m05:42:52.811588 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m05:42:52.837355 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m05:42:52.847247 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m05:42:52.850900 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m05:42:52.873452 [debug] [MainThread]: Parsing macros/etc.sql
[0m05:42:52.876503 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m05:42:52.877971 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m05:42:52.878347 [debug] [MainThread]: Parsing macros/catalog.sql
[0m05:42:52.879191 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m05:42:52.881968 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m05:42:52.883289 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m05:42:52.884581 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m05:42:52.885396 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m05:42:52.886047 [debug] [MainThread]: Parsing macros/adapters.sql
[0m05:42:52.886492 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m05:42:52.887407 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m05:42:52.888730 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m05:42:52.890759 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m05:42:52.891897 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m05:42:52.893277 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m05:42:52.894549 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m05:42:52.895529 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m05:42:52.897069 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m05:42:52.898219 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m05:42:52.899962 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m05:42:52.903173 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m05:42:52.905353 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m05:42:52.909783 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m05:42:52.911733 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m05:42:52.916105 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m05:42:52.924158 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m05:42:52.927385 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m05:42:52.929097 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m05:42:52.934816 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m05:42:52.937951 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m05:42:52.938750 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m05:42:52.940103 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m05:42:52.944742 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m05:42:52.950335 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m05:42:52.954182 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m05:42:52.969239 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m05:42:52.970558 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m05:42:52.971591 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m05:42:52.973137 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m05:42:52.974150 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m05:42:52.974208 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m05:42:52.975263 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m05:42:52.976037 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m05:42:52.976774 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m05:42:52.977100 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m05:42:52.978260 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m05:42:52.980427 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m05:42:52.980424 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m05:42:52.982240 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m05:42:52.983229 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m05:42:52.984474 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m05:42:52.985474 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m05:42:52.986228 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m05:42:52.987144 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m05:42:52.988084 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m05:42:52.989730 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m05:42:52.990389 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m05:42:52.991794 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m05:42:52.991891 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m05:42:52.993013 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m05:42:52.993881 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m05:42:52.994313 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m05:42:52.996491 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m05:42:52.997377 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m05:42:53.001302 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m05:42:53.009946 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m05:42:53.014115 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m05:42:53.018616 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m05:42:53.022116 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m05:42:53.027925 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m05:42:53.028831 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m05:42:53.031019 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m05:42:53.034638 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m05:42:53.038520 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m05:42:53.043178 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m05:42:53.048915 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m05:42:53.051146 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m05:42:53.058207 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m05:42:53.063134 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m05:42:53.067184 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m05:42:53.069972 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m05:42:53.082512 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m05:42:53.085090 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m05:42:53.086907 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m05:42:53.088324 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m05:42:53.090251 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m05:42:53.094262 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m05:42:53.101067 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m05:42:53.104960 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m05:42:53.111275 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m05:42:53.116763 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m05:42:53.118763 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m05:42:53.127709 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m05:42:53.139657 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m05:42:53.141837 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m05:42:53.149403 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m05:42:53.152928 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m05:42:53.165460 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m05:42:53.175003 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m05:42:53.181122 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m05:42:53.187604 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m05:42:53.190341 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m05:42:53.193856 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m05:42:53.203437 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m05:42:53.226273 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m05:42:53.228544 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m05:42:53.232738 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m05:42:53.252077 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m05:42:53.254297 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m05:42:53.269742 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m05:42:53.270976 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m05:42:53.281652 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m05:42:53.286042 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m05:42:53.287854 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m05:42:53.292520 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m05:42:53.294908 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m05:42:53.298681 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m05:42:53.299697 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m05:42:53.308650 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m05:42:53.309395 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m05:42:53.322958 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m05:42:53.334774 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m05:42:53.337188 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m05:42:53.339753 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m05:42:53.340870 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m05:42:53.342492 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m05:42:53.344028 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m05:42:53.345225 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m05:42:53.349356 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m05:42:53.351646 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m05:42:53.354160 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m05:42:53.356344 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m05:42:53.359825 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m05:42:53.362119 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m05:42:53.366822 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m05:42:53.369210 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m05:42:53.371651 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m05:42:53.374582 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m05:42:53.375509 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m05:42:53.377525 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m05:42:53.380544 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m05:42:53.384934 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m05:42:53.387532 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m05:42:53.389828 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m05:42:53.392520 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m05:42:53.394743 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m05:42:53.395286 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m05:42:53.398530 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m05:42:53.403048 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m05:42:53.414625 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m05:42:53.431964 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m05:42:53.439612 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m05:42:53.456206 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m05:42:53.470207 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m05:42:53.473021 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m05:42:53.480705 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m05:42:53.484450 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m05:42:53.487855 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m05:42:53.492636 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m05:42:53.497162 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m05:42:53.500400 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m05:42:53.503473 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m05:42:53.514771 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m05:42:53.520677 [debug] [MainThread]: Parsing macros/utils/datediff.sql


============================== 2023-02-19 05:42:53.521476 | 4b3f40d1-02eb-4b61-b0b5-b98ddd76482b ==============================
[0m05:42:53.521517 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:42:53.523480 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:42:53.526002 [debug] [MainThread]: Tracking: tracking
[0m05:42:53.526250 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m05:42:53.532184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa584c3c550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa584c3cdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa584c3c750>]}
[0m05:42:53.533636 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m05:42:53.537773 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m05:42:53.544445 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m05:42:53.550894 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m05:42:53.557425 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m05:42:53.568719 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m05:42:53.572102 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m05:42:53.575363 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m05:42:53.578862 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m05:42:53.586558 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m05:42:53.589687 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m05:42:53.594881 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m05:42:53.656101 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m05:42:53.657222 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '4b3f40d1-02eb-4b61-b0b5-b98ddd76482b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa584b14710>]}
[0m05:42:54.290125 [debug] [MainThread]: Parsing macros/etc.sql
[0m05:42:54.297123 [debug] [MainThread]: Parsing macros/catalog.sql
[0m05:42:54.307479 [debug] [MainThread]: Parsing macros/adapters.sql
[0m05:42:54.319294 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension.sql
[0m05:42:54.338392 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m05:42:54.339631 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension.sql
[0m05:42:54.343784 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m05:42:54.351321 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension.sql
[0m05:42:54.354730 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m05:42:54.354934 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_periodic_fact.sql
[0m05:42:54.361316 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m05:42:54.367514 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m05:42:54.369476 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension.sql
[0m05:42:54.371543 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_periodic_fact.sql
[0m05:42:54.371999 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_periodic_fact.sql
[0m05:42:54.374070 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m05:42:54.376255 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_report.sql
[0m05:42:54.378000 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m05:42:54.386151 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_periodic_fact.sql
[0m05:42:54.388980 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_report.sql
[0m05:42:54.392576 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_report.sql
[0m05:42:54.397300 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_transaction_fact.sql
[0m05:42:54.400886 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_report.sql
[0m05:42:54.403440 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_transaction_fact.sql
[0m05:42:54.413602 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m05:42:54.415393 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m05:42:54.416411 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_transaction_fact.sql
[0m05:42:54.417127 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m05:42:54.417558 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_transaction_fact.sql
[0m05:42:54.419844 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m05:42:54.421482 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m05:42:54.421573 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m05:42:54.422510 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m05:42:54.430642 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m05:42:54.430679 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m05:42:54.432659 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m05:42:54.433822 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m05:42:54.435213 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m05:42:54.436486 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m05:42:54.438722 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m05:42:54.441426 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m05:42:54.443040 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m05:42:54.445065 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m05:42:54.447298 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m05:42:54.448364 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m05:42:54.449526 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m05:42:54.450847 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m05:42:54.453193 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m05:42:54.455803 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m05:42:54.458091 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m05:42:54.461810 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m05:42:54.490578 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m05:42:54.506897 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m05:42:54.517160 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m05:42:54.524796 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m05:42:54.529473 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m05:42:54.557360 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m05:42:54.562336 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m05:42:54.567574 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m05:42:54.587781 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m05:42:54.592245 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m05:42:54.596344 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m05:42:54.598861 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m05:42:54.601569 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m05:42:54.608534 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m05:42:54.618575 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m05:42:54.626240 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m05:42:54.638954 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m05:42:54.648217 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m05:42:54.652147 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m05:42:54.678808 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '47132c99-f6f1-4fdd-8551-e29b78604d6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2951b39d10>]}
[0m05:42:54.683943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ad40e91c-0859-41c3-8cd4-6bb4c65c22d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcabf6ab550>]}
[0m05:42:54.686188 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '47132c99-f6f1-4fdd-8551-e29b78604d6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2951b39ed0>]}
[0m05:42:54.687534 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:42:54.690185 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m05:42:54.689897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47132c99-f6f1-4fdd-8551-e29b78604d6d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f296f58dd50>]}
[0m05:42:54.690600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ad40e91c-0859-41c3-8cd4-6bb4c65c22d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcabf6ab150>]}
[0m05:42:54.692189 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:42:54.692405 [warn ] [MainThread]: The selection criterion 'test_source' does not match any nodes
[0m05:42:54.693762 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ad40e91c-0859-41c3-8cd4-6bb4c65c22d9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcac5a71a10>]}
[0m05:42:54.696379 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m05:42:54.696906 [warn ] [MainThread]: The selection criterion 'product_dimension_type_1' does not match any nodes
[0m05:42:54.697360 [info ] [MainThread]: 
[0m05:42:54.698873 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:42:54.700425 [info ] [MainThread]: 
[0m05:42:54.701463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2970f80f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2950efea90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2951b39410>]}
[0m05:42:54.702509 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:42:54.703516 [debug] [MainThread]: Flushing usage events
[0m05:42:54.704268 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcabf6ab910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcabf6ab2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcabf6ab9d0>]}
[0m05:42:54.705379 [debug] [MainThread]: Flushing usage events
[0m05:42:54.712390 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m05:42:54.810768 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m05:42:54.839373 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m05:42:54.860757 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m05:42:54.873638 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m05:42:54.881291 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m05:42:54.892728 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m05:42:54.897313 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m05:42:54.905457 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m05:42:54.920132 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m05:42:54.953839 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m05:42:54.963063 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m05:42:55.002039 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m05:42:55.037546 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m05:42:55.072973 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m05:42:55.093846 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m05:42:55.105746 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m05:42:55.122895 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m05:42:55.146024 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m05:42:55.159786 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m05:42:55.169982 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m05:42:55.173325 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m05:42:55.187481 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m05:42:55.192368 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m05:42:55.195108 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m05:42:55.198578 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m05:42:55.205968 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m05:42:55.212323 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m05:42:55.215369 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m05:42:55.219243 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m05:42:55.225499 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m05:42:55.233595 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m05:42:55.239029 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m05:42:55.242300 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m05:42:55.246283 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m05:42:55.255700 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m05:42:55.260316 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m05:42:55.264309 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m05:42:55.266761 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m05:42:55.270478 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m05:42:55.273890 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m05:42:55.279776 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m05:42:55.855834 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension.sql
[0m05:42:55.896426 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension.sql
[0m05:42:55.899284 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_periodic_fact.sql
[0m05:42:55.915500 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_periodic_fact.sql
[0m05:42:55.919989 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_report.sql
[0m05:42:55.942728 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_report.sql
[0m05:42:55.947789 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_transaction_fact.sql
[0m05:42:55.960104 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_transaction_fact.sql
[0m05:42:55.964896 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m05:42:55.971673 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m05:42:56.248182 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '4b3f40d1-02eb-4b61-b0b5-b98ddd76482b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa584ad5c90>]}
[0m05:42:56.253934 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '4b3f40d1-02eb-4b61-b0b5-b98ddd76482b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa584ad58d0>]}
[0m05:42:56.255159 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:42:56.256501 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '4b3f40d1-02eb-4b61-b0b5-b98ddd76482b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa584c63350>]}
[0m05:42:56.259807 [info ] [MainThread]: 
[0m05:42:56.263109 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:42:56.265565 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:42:56.266643 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:42:56.267592 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:42:56.270169 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:42:56.270977 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:42:56.272065 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:42:56.273383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa584b96490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa584b96a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa584b96e10>]}
[0m05:42:56.274573 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:43:11.911914 | d5d4ed41-5123-469d-b15f-4834deb60c8c ==============================
[0m05:43:11.911987 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:43:11.913674 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:43:11.914487 [debug] [MainThread]: Tracking: tracking
[0m05:43:11.917018 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48dff17e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48dff05810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4901942c10>]}


============================== 2023-02-19 05:43:12.088027 | 0d035ffa-012a-4276-8392-f331e662a062 ==============================
[0m05:43:12.088070 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:43:12.094794 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:43:12.096295 [debug] [MainThread]: Tracking: tracking
[0m05:43:12.098706 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f780da25e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f780da25310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f780da25750>]}
[0m05:43:12.581059 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:43:12.582237 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:43:12.596652 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd5d4ed41-5123-469d-b15f-4834deb60c8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48dfd61a10>]}
[0m05:43:12.605244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd5d4ed41-5123-469d-b15f-4834deb60c8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48dfef9290>]}
[0m05:43:12.606614 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:43:12.608850 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd5d4ed41-5123-469d-b15f-4834deb60c8c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4901942c10>]}
[0m05:43:12.612779 [info ] [MainThread]: 
[0m05:43:12.616038 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:43:12.628993 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:43:12.630277 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:43:12.631805 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:43:12.643055 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:43:12.644012 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:43:12.645146 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:43:12.649550 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48dfea9290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48dfea9150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f48dfea90d0>]}
[0m05:43:12.652787 [debug] [MainThread]: Flushing usage events
[0m05:43:12.811205 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:43:12.812104 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:43:12.824819 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0d035ffa-012a-4276-8392-f331e662a062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f780d877290>]}
[0m05:43:12.830911 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0d035ffa-012a-4276-8392-f331e662a062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f780da07d90>]}
[0m05:43:12.831922 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:43:12.833284 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0d035ffa-012a-4276-8392-f331e662a062', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f780da07590>]}
[0m05:43:12.835650 [info ] [MainThread]: 
[0m05:43:12.837828 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:43:12.839733 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:43:12.840611 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:43:12.841649 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:43:12.843562 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:43:12.844269 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:43:12.845071 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:43:12.846291 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f780d9b7110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f780d9b7410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f780d9b7910>]}
[0m05:43:12.847247 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:43:18.434762 | 528c7e4d-05e6-4673-995b-52228db0fefa ==============================
[0m05:43:18.434795 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:43:18.436346 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:43:18.437202 [debug] [MainThread]: Tracking: tracking
[0m05:43:18.439122 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c22a5550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c22a5f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c22a5390>]}
[0m05:43:19.231865 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:43:19.233205 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:43:19.247123 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '528c7e4d-05e6-4673-995b-52228db0fefa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c451d710>]}
[0m05:43:19.252000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '528c7e4d-05e6-4673-995b-52228db0fefa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c2287610>]}
[0m05:43:19.252930 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:43:19.253870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '528c7e4d-05e6-4673-995b-52228db0fefa', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c2b6b490>]}
[0m05:43:19.255425 [warn ] [MainThread]: The selection criterion 'test_source' does not match any nodes
[0m05:43:19.257750 [info ] [MainThread]: 
[0m05:43:19.258982 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:43:19.260793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c2287ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c22871d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff6c22cfc90>]}
[0m05:43:19.261800 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:43:28.072838 | 96e4a798-b137-418c-948c-65ab3a70f0a4 ==============================
[0m05:43:28.072873 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:43:28.074311 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:43:28.075070 [debug] [MainThread]: Tracking: tracking
[0m05:43:28.077299 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a7093450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a70937d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a715da90>]}
[0m05:43:28.262242 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m05:43:28.264058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '96e4a798-b137-418c-948c-65ab3a70f0a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a6f64f90>]}


============================== 2023-02-19 05:43:28.417053 | 415ed942-0780-4059-b431-1922f506e7ce ==============================
[0m05:43:28.417108 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:43:28.424226 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:43:28.425154 [debug] [MainThread]: Tracking: tracking
[0m05:43:28.427700 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a7b173550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a7b173c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a7b173cd0>]}
[0m05:43:28.621050 [info ] [MainThread]: Unable to do partial parsing because a project config has changed
[0m05:43:28.622969 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '415ed942-0780-4059-b431-1922f506e7ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a5d63c690>]}
[0m05:43:29.089178 [debug] [MainThread]: Parsing macros/etc.sql
[0m05:43:29.095956 [debug] [MainThread]: Parsing macros/catalog.sql
[0m05:43:29.110466 [debug] [MainThread]: Parsing macros/adapters.sql
[0m05:43:29.159062 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m05:43:29.166045 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m05:43:29.179592 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m05:43:29.187717 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m05:43:29.196031 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m05:43:29.204190 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m05:43:29.207878 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m05:43:29.253521 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m05:43:29.255818 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m05:43:29.258032 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m05:43:29.263016 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m05:43:29.265865 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m05:43:29.268053 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m05:43:29.270370 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m05:43:29.272504 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m05:43:29.275574 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m05:43:29.279932 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m05:43:29.287464 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m05:43:29.292389 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m05:43:29.298470 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m05:43:29.302409 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m05:43:29.304285 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m05:43:29.306096 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m05:43:29.307822 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m05:43:29.310885 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m05:43:29.314549 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m05:43:29.320484 [debug] [MainThread]: Parsing macros/etc.sql
[0m05:43:29.321332 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m05:43:29.327708 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m05:43:29.328410 [debug] [MainThread]: Parsing macros/catalog.sql
[0m05:43:29.340488 [debug] [MainThread]: Parsing macros/adapters.sql
[0m05:43:29.360955 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m05:43:29.383321 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m05:43:29.396474 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m05:43:29.398925 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m05:43:29.402782 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m05:43:29.404873 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m05:43:29.407502 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m05:43:29.420847 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m05:43:29.433055 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m05:43:29.440540 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m05:43:29.441591 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m05:43:29.446750 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m05:43:29.448587 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m05:43:29.453312 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m05:43:29.453874 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m05:43:29.470351 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m05:43:29.472236 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m05:43:29.474540 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m05:43:29.477174 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m05:43:29.480761 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m05:43:29.484364 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m05:43:29.486698 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m05:43:29.487342 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m05:43:29.493309 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m05:43:29.496915 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m05:43:29.496443 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m05:43:29.499596 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m05:43:29.502001 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m05:43:29.503706 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m05:43:29.505922 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m05:43:29.506622 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m05:43:29.508503 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m05:43:29.512718 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m05:43:29.516289 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m05:43:29.518482 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m05:43:29.520226 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m05:43:29.521547 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m05:43:29.523646 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m05:43:29.525842 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m05:43:29.529164 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m05:43:29.533601 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m05:43:29.539244 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m05:43:29.539360 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m05:43:29.543118 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m05:43:29.547505 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m05:43:29.551427 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m05:43:29.558906 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m05:43:29.578532 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m05:43:29.582264 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m05:43:29.596062 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m05:43:29.599867 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m05:43:29.613886 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m05:43:29.626548 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m05:43:29.643659 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m05:43:29.660245 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m05:43:29.720208 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m05:43:29.728156 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m05:43:29.732921 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m05:43:29.752148 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m05:43:29.764930 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m05:43:29.767468 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m05:43:29.770958 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m05:43:29.774262 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m05:43:29.779316 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m05:43:29.785307 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m05:43:29.790487 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m05:43:29.798028 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m05:43:29.803566 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m05:43:29.816304 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m05:43:29.819399 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m05:43:29.824617 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m05:43:29.828375 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m05:43:29.834011 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m05:43:29.842247 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m05:43:29.854798 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m05:43:29.860268 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m05:43:29.865342 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m05:43:29.866078 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m05:43:29.872079 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m05:43:29.885681 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m05:43:29.891730 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m05:43:29.921528 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m05:43:29.926624 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m05:43:29.968687 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m05:43:30.000655 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m05:43:30.012724 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m05:43:30.031058 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m05:43:30.054428 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m05:43:30.055212 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m05:43:30.067753 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m05:43:30.082766 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m05:43:30.087093 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m05:43:30.096796 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m05:43:30.105183 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m05:43:30.106596 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m05:43:30.107930 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m05:43:30.110113 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m05:43:30.112386 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m05:43:30.115347 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m05:43:30.116537 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m05:43:30.119335 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m05:43:30.121312 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m05:43:30.122459 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m05:43:30.124659 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m05:43:30.126411 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m05:43:30.129207 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m05:43:30.133014 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m05:43:30.135788 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m05:43:30.139019 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m05:43:30.140022 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m05:43:30.141601 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m05:43:30.144572 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m05:43:30.146601 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m05:43:30.148380 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m05:43:30.150821 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m05:43:30.156266 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m05:43:30.159134 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m05:43:30.162097 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m05:43:30.164199 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m05:43:30.166244 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m05:43:30.170461 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m05:43:30.175507 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m05:43:30.175583 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m05:43:30.180458 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m05:43:30.214680 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m05:43:30.245294 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m05:43:30.279126 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m05:43:30.310584 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m05:43:30.334650 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m05:43:30.367118 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m05:43:30.395283 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m05:43:30.397629 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m05:43:30.399722 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m05:43:30.402567 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m05:43:30.404758 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m05:43:30.407122 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m05:43:30.408961 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m05:43:30.411205 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m05:43:30.413500 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m05:43:30.417138 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m05:43:30.420370 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m05:43:30.423145 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m05:43:30.426006 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m05:43:30.428911 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m05:43:30.430992 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m05:43:30.432753 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m05:43:30.435610 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m05:43:30.438892 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m05:43:30.441522 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m05:43:30.443579 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m05:43:30.445607 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m05:43:30.447529 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m05:43:30.449579 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m05:43:30.453730 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m05:43:30.790049 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension.sql
[0m05:43:30.818550 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension.sql
[0m05:43:30.821375 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_periodic_fact.sql
[0m05:43:30.831309 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_periodic_fact.sql
[0m05:43:30.834880 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_report.sql
[0m05:43:30.849694 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_report.sql
[0m05:43:30.853830 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_transaction_fact.sql
[0m05:43:30.866832 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_transaction_fact.sql
[0m05:43:30.871052 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m05:43:30.876125 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m05:43:30.979770 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension.sql
[0m05:43:31.043287 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension.sql
[0m05:43:31.046435 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_periodic_fact.sql
[0m05:43:31.058869 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_periodic_fact.sql
[0m05:43:31.061820 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_report.sql
[0m05:43:31.074396 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_report.sql
[0m05:43:31.077110 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_transaction_fact.sql
[0m05:43:31.089205 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_transaction_fact.sql
[0m05:43:31.103458 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m05:43:31.109740 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m05:43:31.119084 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '96e4a798-b137-418c-948c-65ab3a70f0a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a7024190>]}
[0m05:43:31.123607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '96e4a798-b137-418c-948c-65ab3a70f0a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a6fc1790>]}
[0m05:43:31.124888 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:43:31.126281 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '96e4a798-b137-418c-948c-65ab3a70f0a4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07c8a80cd0>]}
[0m05:43:31.129904 [info ] [MainThread]: 
[0m05:43:31.132254 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:43:31.135916 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:43:31.137019 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:43:31.137978 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:43:31.141345 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:43:31.142515 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:43:31.143636 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:43:31.145171 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a6fc11d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a6fc23d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f07a6fc2a90>]}
[0m05:43:31.146379 [debug] [MainThread]: Flushing usage events
[0m05:43:31.297202 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '415ed942-0780-4059-b431-1922f506e7ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a5d6aeb50>]}
[0m05:43:31.303650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '415ed942-0780-4059-b431-1922f506e7ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a5d6aefd0>]}
[0m05:43:31.304726 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:43:31.306004 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '415ed942-0780-4059-b431-1922f506e7ce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a5d78a350>]}
[0m05:43:31.307236 [warn ] [MainThread]: The selection criterion 'product_dimension_type_1' does not match any nodes
[0m05:43:31.309196 [info ] [MainThread]: 
[0m05:43:31.310405 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:43:31.311683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a5d714810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a5d6aed10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4a5d6ae9d0>]}
[0m05:43:31.312550 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:43:36.709196 | d378cfb5-4f67-4eea-b670-b039be1b078c ==============================
[0m05:43:36.709241 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:43:36.711330 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:43:36.713525 [debug] [MainThread]: Tracking: tracking
[0m05:43:36.716830 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4c2960890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4c2960d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4e437dd10>]}
[0m05:43:37.475571 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:43:37.477034 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:43:37.492987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd378cfb5-4f67-4eea-b670-b039be1b078c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4c27b44d0>]}
[0m05:43:37.500463 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd378cfb5-4f67-4eea-b670-b039be1b078c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4c2943690>]}
[0m05:43:37.501608 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:43:37.502839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd378cfb5-4f67-4eea-b670-b039be1b078c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4e437dd10>]}
[0m05:43:37.505631 [info ] [MainThread]: 
[0m05:43:37.507298 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:43:37.509489 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:43:37.510345 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:43:37.511179 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:43:37.514738 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:43:37.515836 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:43:37.517009 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:43:37.518530 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4c28f3a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4c28f3110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4c28f37d0>]}
[0m05:43:37.519811 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:43:44.038584 | 463cb6cc-96eb-4b20-b45b-615ec6223834 ==============================
[0m05:43:44.038612 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:43:44.039964 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:43:44.041119 [debug] [MainThread]: Tracking: tracking
[0m05:43:44.042535 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e1184a9d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e11883810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e11883910>]}
[0m05:43:44.763190 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:43:44.764014 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:43:44.774248 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '463cb6cc-96eb-4b20-b45b-615ec6223834', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e11694310>]}
[0m05:43:44.778667 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '463cb6cc-96eb-4b20-b45b-615ec6223834', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e1182ef10>]}
[0m05:43:44.779625 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:43:44.780606 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '463cb6cc-96eb-4b20-b45b-615ec6223834', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e1183abd0>]}
[0m05:43:44.782666 [info ] [MainThread]: 
[0m05:43:44.783926 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:43:44.785566 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:43:44.786306 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:43:44.786930 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:43:44.788412 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:43:44.789065 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:43:44.789952 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:43:44.791288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e1182ee50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e117de450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0e117de190>]}
[0m05:43:44.792577 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:47:17.530651 | 40127edf-cde5-4d04-8ba4-04ac6866fdce ==============================
[0m05:47:17.530685 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:47:17.532188 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:47:17.533248 [debug] [MainThread]: Tracking: tracking
[0m05:47:17.535467 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc358fc710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc371721d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc532cdc10>]}


============================== 2023-02-19 05:47:17.552826 | a8612eda-2376-46f4-bd52-c8da87f6afb7 ==============================
[0m05:47:17.552870 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:47:17.556525 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:47:17.557457 [debug] [MainThread]: Tracking: tracking
[0m05:47:17.560612 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfe8aca590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfe8aca750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfe8b96ad0>]}
[0m05:47:18.230879 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 0 files added, 0 files changed.
[0m05:47:18.232312 [debug] [MainThread]: Partial parsing: deleted file: data_warehouse_analytics_engineer://models/example/my_first_dbt_model.sql
[0m05:47:18.233545 [debug] [MainThread]: Partial parsing: deleted file: data_warehouse_analytics_engineer://models/example/my_second_dbt_model.sql
[0m05:47:18.240731 [debug] [MainThread]: Partial parsing enabled: 3 files deleted, 0 files added, 0 files changed.
[0m05:47:18.242761 [debug] [MainThread]: Partial parsing: deleted file: data_warehouse_analytics_engineer://models/example/my_first_dbt_model.sql
[0m05:47:18.243888 [debug] [MainThread]: Partial parsing: deleted file: data_warehouse_analytics_engineer://models/example/my_second_dbt_model.sql
[0m05:47:18.271780 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example

[0m05:47:18.280760 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example

[0m05:47:18.289129 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '40127edf-cde5-4d04-8ba4-04ac6866fdce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc35752410>]}
[0m05:47:18.296040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a8612eda-2376-46f4-bd52-c8da87f6afb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfe891c310>]}
[0m05:47:18.298865 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '40127edf-cde5-4d04-8ba4-04ac6866fdce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc3579cd50>]}
[0m05:47:18.300297 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:47:18.301832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '40127edf-cde5-4d04-8ba4-04ac6866fdce', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc532cd6d0>]}
[0m05:47:18.302663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a8612eda-2376-46f4-bd52-c8da87f6afb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfe896add0>]}
[0m05:47:18.303444 [warn ] [MainThread]: The selection criterion 'test_source' does not match any nodes
[0m05:47:18.303853 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:47:18.305396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a8612eda-2376-46f4-bd52-c8da87f6afb7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe0064dfcd0>]}
[0m05:47:18.306770 [info ] [MainThread]: 
[0m05:47:18.307072 [warn ] [MainThread]: The selection criterion 'product_dimension_type_1' does not match any nodes
[0m05:47:18.308271 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:47:18.311276 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc3579ce50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc3579cdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc3579cd10>]}
[0m05:47:18.311627 [info ] [MainThread]: 
[0m05:47:18.312722 [debug] [MainThread]: Flushing usage events
[0m05:47:18.313055 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:47:18.314450 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfe896add0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfe896ad10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdfe896ad50>]}
[0m05:47:18.315528 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:47:19.067374 | f714cf6f-233d-4944-945b-5b33e1a43d4f ==============================
[0m05:47:19.067403 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:47:19.068625 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:47:19.069268 [debug] [MainThread]: Tracking: tracking
[0m05:47:19.070942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84c5949790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84c5949710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84c5949e50>]}
[0m05:47:19.657201 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:47:19.658857 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:47:19.660523 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example

[0m05:47:19.681057 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f714cf6f-233d-4944-945b-5b33e1a43d4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84c577d710>]}
[0m05:47:19.687264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f714cf6f-233d-4944-945b-5b33e1a43d4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84c59559d0>]}
[0m05:47:19.688601 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:47:19.690887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f714cf6f-233d-4944-945b-5b33e1a43d4f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84c7090c90>]}
[0m05:47:19.695949 [info ] [MainThread]: 
[0m05:47:19.698544 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:47:19.702080 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:47:19.703679 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:47:19.704780 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:47:19.707717 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:47:19.708928 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:47:19.709913 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:47:19.711617 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84c58d3350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84c58d3ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84c58d3690>]}
[0m05:47:19.714432 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:47:30.618205 | f0ed25e5-94cc-420c-8a09-39cc37815bfc ==============================
[0m05:47:30.618233 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:47:30.619492 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:47:30.620094 [debug] [MainThread]: Tracking: tracking
[0m05:47:30.621511 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b7572f850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b75754c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b75754410>]}


============================== 2023-02-19 05:47:30.739061 | 46ad454c-16fd-4486-9f03-4fbd31dc4030 ==============================
[0m05:47:30.739160 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:47:30.741125 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:47:30.742209 [debug] [MainThread]: Tracking: tracking
[0m05:47:30.745058 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d102cc890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d102ccc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d2dca2c90>]}
[0m05:47:31.251686 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:47:31.253173 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:47:31.254707 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example

[0m05:47:31.272101 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f0ed25e5-94cc-420c-8a09-39cc37815bfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b53b8a3d0>]}
[0m05:47:31.279143 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f0ed25e5-94cc-420c-8a09-39cc37815bfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b53d2bc90>]}
[0m05:47:31.280401 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:47:31.282185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f0ed25e5-94cc-420c-8a09-39cc37815bfc', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b53bf9fd0>]}
[0m05:47:31.285599 [info ] [MainThread]: 
[0m05:47:31.288334 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:47:31.291431 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:47:31.292579 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:47:31.294088 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:47:31.298141 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:47:31.299972 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:47:31.300986 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:47:31.302499 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b53ce30d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b53ce3690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f6b53ce3850>]}
[0m05:47:31.303570 [debug] [MainThread]: Flushing usage events
[0m05:47:31.415595 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:47:31.417011 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:47:31.419095 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example

[0m05:47:31.434427 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '46ad454c-16fd-4486-9f03-4fbd31dc4030', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d100bf510>]}
[0m05:47:31.440464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '46ad454c-16fd-4486-9f03-4fbd31dc4030', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d10236290>]}
[0m05:47:31.441753 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:47:31.443077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '46ad454c-16fd-4486-9f03-4fbd31dc4030', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d2dc7db10>]}
[0m05:47:31.444694 [warn ] [MainThread]: The selection criterion 'my_first_dbt_model' does not match any nodes
[0m05:47:31.447099 [info ] [MainThread]: 
[0m05:47:31.448463 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:47:31.450133 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d102ccc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d1029ee90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9d102bd890>]}
[0m05:47:31.451164 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:47:44.255067 | 2769dd39-802a-4e22-9c50-a2fb1ee374a7 ==============================
[0m05:47:44.255129 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:47:44.257249 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:47:44.258195 [debug] [MainThread]: Tracking: tracking
[0m05:47:44.260259 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58181b3250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f58181b36d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57f6856b90>]}
[0m05:47:44.864916 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:47:44.865937 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:47:44.867114 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example

[0m05:47:44.887215 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2769dd39-802a-4e22-9c50-a2fb1ee374a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57f65bd190>]}
[0m05:47:44.894167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2769dd39-802a-4e22-9c50-a2fb1ee374a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57f67b1290>]}
[0m05:47:44.895322 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:47:44.896611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2769dd39-802a-4e22-9c50-a2fb1ee374a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57f6839c90>]}
[0m05:47:44.898168 [warn ] [MainThread]: The selection criterion 'product_dimension_type_1' does not match any nodes
[0m05:47:44.902141 [info ] [MainThread]: 
[0m05:47:44.905556 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:47:44.907404 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57f6778750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57f6778810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f57f67b15d0>]}
[0m05:47:44.908561 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:47:47.462722 | e9db7c11-caec-4d58-b94c-eaabbd3d129d ==============================
[0m05:47:47.462764 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:47:47.464444 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:47:47.465423 [debug] [MainThread]: Tracking: tracking
[0m05:47:47.467478 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96f32277d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96f3227710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9714c1bd10>]}


============================== 2023-02-19 05:47:47.628356 | ca45c454-6026-4524-8d36-223ed74537e6 ==============================
[0m05:47:47.628406 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:47:47.630868 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:47:47.633111 [debug] [MainThread]: Tracking: tracking
[0m05:47:47.636978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38598e4810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38599af7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38599af850>]}
[0m05:47:48.182340 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:47:48.183582 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:47:48.187825 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example

[0m05:47:48.206915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e9db7c11-caec-4d58-b94c-eaabbd3d129d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96f3059590>]}
[0m05:47:48.214648 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e9db7c11-caec-4d58-b94c-eaabbd3d129d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96f322dcd0>]}
[0m05:47:48.216110 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:47:48.217722 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e9db7c11-caec-4d58-b94c-eaabbd3d129d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96f949ed10>]}
[0m05:47:48.220487 [warn ] [MainThread]: The selection criterion 'test_source' does not match any nodes
[0m05:47:48.223394 [info ] [MainThread]: 
[0m05:47:48.225282 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:47:48.227614 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96f322d790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96f322d7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f96f322de90>]}
[0m05:47:48.229011 [debug] [MainThread]: Flushing usage events
[0m05:47:48.390678 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:47:48.391998 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:47:48.393771 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example

[0m05:47:48.417714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca45c454-6026-4524-8d36-223ed74537e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3859716fd0>]}
[0m05:47:48.424759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca45c454-6026-4524-8d36-223ed74537e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f385984c050>]}
[0m05:47:48.426363 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:47:48.427616 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ca45c454-6026-4524-8d36-223ed74537e6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f385f743590>]}
[0m05:47:48.430070 [info ] [MainThread]: 
[0m05:47:48.431696 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:47:48.433835 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:47:48.434962 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:47:48.436379 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:47:48.439105 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:47:48.440078 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:47:48.441334 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:47:48.443156 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f385986e310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f385986e950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f385986ec10>]}
[0m05:47:48.444363 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:47:58.602211 | deecd676-a504-4bf6-bd06-977f95df7599 ==============================
[0m05:47:58.602244 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:47:58.603577 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:47:58.604288 [debug] [MainThread]: Tracking: tracking
[0m05:47:58.605903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4388c3b550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4388c3b510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4388d08950>]}
[0m05:47:59.195978 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:47:59.196978 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:47:59.198291 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example

[0m05:47:59.213713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'deecd676-a504-4bf6-bd06-977f95df7599', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f438ae6f0d0>]}
[0m05:47:59.219206 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'deecd676-a504-4bf6-bd06-977f95df7599', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4388c66ad0>]}
[0m05:47:59.220136 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:47:59.221152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'deecd676-a504-4bf6-bd06-977f95df7599', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43a663ecd0>]}
[0m05:47:59.222593 [warn ] [MainThread]: The selection criterion 'my_first_dbt_model' does not match any nodes
[0m05:47:59.224714 [info ] [MainThread]: 
[0m05:47:59.225699 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m05:47:59.227089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4388c42510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4388c426d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4388c42250>]}
[0m05:47:59.228279 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 05:48:00.934660 | e744ed4b-f86a-4639-b96c-bb6a993f8069 ==============================
[0m05:48:00.934690 [info ] [MainThread]: Running with dbt=1.3.0
[0m05:48:00.937527 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m05:48:00.940086 [debug] [MainThread]: Tracking: tracking
[0m05:48:00.941599 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f024991f4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f024991fbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0227fe3d90>]}
[0m05:48:01.466661 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m05:48:01.467665 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m05:48:01.468805 [warn ] [MainThread]: [[33mWARNING[0m]: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.data_warehouse_analytics_engineer.example

[0m05:48:01.479504 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e744ed4b-f86a-4639-b96c-bb6a993f8069', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0227d4a690>]}
[0m05:48:01.486542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e744ed4b-f86a-4639-b96c-bb6a993f8069', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0227f08950>]}
[0m05:48:01.487722 [info ] [MainThread]: Found 4 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m05:48:01.489077 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e744ed4b-f86a-4639-b96c-bb6a993f8069', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0227f02610>]}
[0m05:48:01.491027 [info ] [MainThread]: 
[0m05:48:01.493033 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m05:48:01.494738 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m05:48:01.495663 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m05:48:01.496622 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m05:48:01.499245 [debug] [MainThread]: Connection 'master' was properly closed.
[0m05:48:01.500064 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m05:48:01.500902 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m05:48:01.501971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0227ea0050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0227ea0490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0227ea0a50>]}
[0m05:48:01.502852 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:20:20.105446 | 0191d9c8-61a7-4d23-8409-a3bc5d87135c ==============================
[0m07:20:20.105471 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:20:20.107463 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:20:20.108564 [debug] [MainThread]: Tracking: tracking
[0m07:20:20.110105 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8c186a3750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8c186a3950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8c18707c90>]}
[0m07:20:20.185302 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m07:20:20.186500 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '0191d9c8-61a7-4d23-8409-a3bc5d87135c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8c18509250>]}
[0m07:20:20.662508 [debug] [MainThread]: Parsing macros/etc.sql
[0m07:20:20.665772 [debug] [MainThread]: Parsing macros/catalog.sql
[0m07:20:20.671285 [debug] [MainThread]: Parsing macros/adapters.sql
[0m07:20:20.691843 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:20:20.695156 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m07:20:20.702950 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m07:20:20.706871 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m07:20:20.710793 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m07:20:20.714127 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m07:20:20.716696 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m07:20:20.740390 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:20:20.741818 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:20:20.743448 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m07:20:20.745062 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:20:20.746498 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:20:20.747716 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:20:20.748767 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:20:20.749979 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:20:20.751244 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:20:20.752835 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:20:20.754494 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:20:20.755791 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:20:20.757672 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:20:20.759019 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:20:20.759980 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:20:20.761226 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:20:20.762677 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:20:20.764958 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m07:20:20.767674 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m07:20:20.770371 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m07:20:20.774267 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:20:20.787036 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m07:20:20.794679 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m07:20:20.799844 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m07:20:20.803841 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m07:20:20.807606 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m07:20:20.821428 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m07:20:20.825143 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m07:20:20.828119 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m07:20:20.836805 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m07:20:20.838365 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m07:20:20.840160 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m07:20:20.841736 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m07:20:20.843631 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m07:20:20.846642 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m07:20:20.850793 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m07:20:20.853562 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m07:20:20.859804 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m07:20:20.863722 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m07:20:20.865696 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m07:20:20.880344 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m07:20:20.882518 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m07:20:20.894374 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m07:20:20.902852 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m07:20:20.915833 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m07:20:20.971618 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m07:20:20.978146 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m07:20:20.982300 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m07:20:20.987365 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m07:20:20.991016 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m07:20:20.993348 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m07:20:21.001255 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m07:20:21.018484 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m07:20:21.020911 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m07:20:21.035995 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m07:20:21.047394 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m07:20:21.060284 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m07:20:21.068848 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m07:20:21.075379 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m07:20:21.081573 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m07:20:21.088059 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:20:21.090495 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:20:21.092197 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:20:21.093926 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m07:20:21.095556 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:20:21.097477 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:20:21.099049 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:20:21.100728 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:20:21.102461 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:20:21.105617 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m07:20:21.107748 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:20:21.109706 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:20:21.111673 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:20:21.114026 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:20:21.115905 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:20:21.117680 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:20:21.119626 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m07:20:21.122359 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m07:20:21.124621 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m07:20:21.126414 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:20:21.128071 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m07:20:21.129725 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m07:20:21.131506 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:20:21.134085 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m07:20:21.470782 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension.sql
[0m07:20:21.496506 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension.sql
[0m07:20:21.498703 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_periodic_fact.sql
[0m07:20:21.508228 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_periodic_fact.sql
[0m07:20:21.511061 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_report.sql
[0m07:20:21.520179 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_report.sql
[0m07:20:21.522993 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_transaction_fact.sql
[0m07:20:21.531918 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_transaction_fact.sql
[0m07:20:21.536508 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m07:20:21.541787 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m07:20:21.659373 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0191d9c8-61a7-4d23-8409-a3bc5d87135c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8c185a8b90>]}
[0m07:20:21.665167 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0191d9c8-61a7-4d23-8409-a3bc5d87135c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8c18461990>]}
[0m07:20:21.666249 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:20:21.667394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0191d9c8-61a7-4d23-8409-a3bc5d87135c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8c3601ed10>]}
[0m07:20:21.669468 [info ] [MainThread]: 
[0m07:20:21.671060 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:20:21.673822 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:20:21.674867 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:20:21.675892 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-enginee-airflow/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m07:20:21.678199 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:20:21.679134 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:20:21.680430 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-enginee-airflow/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m07:20:21.681523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8c184a8110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8c184a8ed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8c184a8910>]}
[0m07:20:21.682376 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:23:52.185537 | 927b2ef7-5ae0-45b3-b71c-a0d57843ad98 ==============================
[0m07:23:52.185602 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:23:52.188326 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:23:52.189437 [debug] [MainThread]: Tracking: tracking
[0m07:23:52.196396 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f220a223ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f220a223550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2227c20bd0>]}
[0m07:23:52.294817 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m07:23:52.296089 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '927b2ef7-5ae0-45b3-b71c-a0d57843ad98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f220a0f4650>]}
[0m07:23:52.904866 [debug] [MainThread]: Parsing macros/etc.sql
[0m07:23:52.910805 [debug] [MainThread]: Parsing macros/catalog.sql
[0m07:23:52.920472 [debug] [MainThread]: Parsing macros/adapters.sql
[0m07:23:52.950424 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:23:52.954388 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m07:23:52.966168 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m07:23:52.971048 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m07:23:52.976082 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m07:23:52.980676 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m07:23:52.983485 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m07:23:53.008913 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:23:53.010785 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:23:53.012142 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m07:23:53.014128 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:23:53.015386 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:23:53.017616 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:23:53.018821 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:23:53.020194 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:23:53.021417 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:23:53.023246 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:23:53.025786 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:23:53.027487 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:23:53.029520 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:23:53.031400 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:23:53.032663 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:23:53.034283 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:23:53.035905 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:23:53.038468 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m07:23:53.041685 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m07:23:53.045080 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m07:23:53.051034 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:23:53.070215 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m07:23:53.081105 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m07:23:53.087482 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m07:23:53.092831 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m07:23:53.098571 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m07:23:53.121201 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m07:23:53.124414 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m07:23:53.129629 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m07:23:53.149449 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m07:23:53.151404 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m07:23:53.152939 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m07:23:53.154574 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m07:23:53.157482 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m07:23:53.163164 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m07:23:53.169581 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m07:23:53.178937 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m07:23:53.191608 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m07:23:53.199472 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m07:23:53.204074 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m07:23:53.237977 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m07:23:53.242097 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m07:23:53.253476 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql


============================== 2023-02-19 07:23:53.266972 | 6ee6e012-3f71-4eca-8581-8dd988d2d267 ==============================
[0m07:23:53.267034 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:23:53.268669 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:23:53.269565 [debug] [MainThread]: Tracking: tracking
[0m07:23:53.271928 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m07:23:53.272554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8770bdb3d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87765ad7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f878e58d2d0>]}


============================== 2023-02-19 07:23:53.285173 | 83538dca-3ce3-43ae-89fc-38ad3eec0346 ==============================
[0m07:23:53.285211 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:23:53.286855 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:23:53.287829 [debug] [MainThread]: Tracking: tracking
[0m07:23:53.289768 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3e42cd690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3e42cd7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa401ca8bd0>]}
[0m07:23:53.309629 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m07:23:53.426581 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m07:23:53.427556 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m07:23:53.428242 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '83538dca-3ce3-43ae-89fc-38ad3eec0346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3e419d6d0>]}
[0m07:23:53.428801 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6ee6e012-3f71-4eca-8581-8dd988d2d267', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8770aac710>]}
[0m07:23:53.445720 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m07:23:53.460398 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m07:23:53.472937 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m07:23:53.491961 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m07:23:53.508168 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m07:23:53.524127 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m07:23:53.560792 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m07:23:53.635011 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m07:23:53.640320 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m07:23:53.690322 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m07:23:53.734336 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m07:23:53.781043 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m07:23:53.800201 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m07:23:53.814365 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m07:23:53.832642 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m07:23:53.850039 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:23:53.853248 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:23:53.856366 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:23:53.860250 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m07:23:53.863367 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:23:53.866649 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:23:53.868597 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:23:53.871016 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:23:53.873365 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:23:53.881401 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m07:23:53.891370 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:23:53.901643 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:23:53.908215 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:23:53.916925 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:23:53.927078 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:23:53.932351 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:23:53.935699 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m07:23:53.945253 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m07:23:53.956201 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m07:23:53.959982 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:23:53.963083 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m07:23:53.965435 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m07:23:53.968192 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:23:53.972418 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m07:23:54.171338 [debug] [MainThread]: Parsing macros/etc.sql
[0m07:23:54.172979 [debug] [MainThread]: Parsing macros/etc.sql
[0m07:23:54.176104 [debug] [MainThread]: Parsing macros/catalog.sql
[0m07:23:54.178596 [debug] [MainThread]: Parsing macros/catalog.sql
[0m07:23:54.183497 [debug] [MainThread]: Parsing macros/adapters.sql
[0m07:23:54.185885 [debug] [MainThread]: Parsing macros/adapters.sql
[0m07:23:54.234758 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:23:54.240910 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m07:23:54.248208 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:23:54.254788 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m07:23:54.255022 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m07:23:54.260588 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m07:23:54.265683 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m07:23:54.268477 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m07:23:54.270993 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m07:23:54.272783 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m07:23:54.274088 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m07:23:54.279561 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m07:23:54.284132 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m07:23:54.287131 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m07:23:54.302085 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:23:54.303495 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:23:54.304791 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m07:23:54.306846 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:23:54.308485 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:23:54.310001 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:23:54.311136 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:23:54.312543 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:23:54.313939 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:23:54.315942 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:23:54.317420 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:23:54.318585 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:23:54.319293 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:23:54.320019 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:23:54.320605 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m07:23:54.321741 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:23:54.322870 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:23:54.323022 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:23:54.324152 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:23:54.324691 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:23:54.325650 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:23:54.326682 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:23:54.327004 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:23:54.328034 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:23:54.329358 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:23:54.329385 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m07:23:54.330919 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:23:54.332192 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m07:23:54.332874 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:23:54.334576 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m07:23:54.335096 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:23:54.336770 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:23:54.338267 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:23:54.338664 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:23:54.340037 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:23:54.341250 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:23:54.342979 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:23:54.344260 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:23:54.346522 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m07:23:54.349128 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m07:23:54.351571 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m07:23:54.355110 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:23:54.358755 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m07:23:54.368488 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m07:23:54.375729 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m07:23:54.380543 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m07:23:54.381521 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m07:23:54.388475 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m07:23:54.392220 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m07:23:54.398563 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m07:23:54.404618 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m07:23:54.409473 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m07:23:54.413090 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m07:23:54.417255 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m07:23:54.420967 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m07:23:54.431138 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m07:23:54.434416 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m07:23:54.434559 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m07:23:54.436506 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m07:23:54.438345 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m07:23:54.438290 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m07:23:54.440265 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m07:23:54.443117 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m07:23:54.447149 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m07:23:54.452895 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m07:23:54.457151 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m07:23:54.458727 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m07:23:54.460512 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m07:23:54.462391 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m07:23:54.464011 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m07:23:54.465055 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m07:23:54.467343 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m07:23:54.470905 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m07:23:54.471101 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m07:23:54.473223 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m07:23:54.477526 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m07:23:54.481038 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m07:23:54.489355 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m07:23:54.494970 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m07:23:54.495096 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m07:23:54.497432 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m07:23:54.497742 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m07:23:54.506810 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m07:23:54.521157 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m07:23:54.522525 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m07:23:54.525954 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m07:23:54.535614 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m07:23:54.543032 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension.sql
[0m07:23:54.545697 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m07:23:54.548039 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m07:23:54.565872 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension.sql
[0m07:23:54.566881 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m07:23:54.568513 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_periodic_fact.sql
[0m07:23:54.579735 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_periodic_fact.sql
[0m07:23:54.582537 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_report.sql
[0m07:23:54.595801 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_report.sql
[0m07:23:54.599437 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_transaction_fact.sql
[0m07:23:54.617536 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_transaction_fact.sql
[0m07:23:54.628548 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m07:23:54.636558 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m07:23:54.642473 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m07:23:54.647261 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m07:23:54.648941 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m07:23:54.651701 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m07:23:54.654553 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m07:23:54.655198 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m07:23:54.661102 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m07:23:54.664697 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m07:23:54.668976 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m07:23:54.670505 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m07:23:54.675748 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m07:23:54.677453 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m07:23:54.681001 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m07:23:54.696581 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m07:23:54.697707 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m07:23:54.700273 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m07:23:54.736564 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m07:23:54.738311 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m07:23:54.739344 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m07:23:54.756363 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m07:23:54.772982 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m07:23:54.777169 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m07:23:54.792103 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m07:23:54.791882 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m07:23:54.803590 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m07:23:54.817833 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m07:23:54.820446 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m07:23:54.831092 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:23:54.832976 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:23:54.834878 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m07:23:54.835314 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:23:54.837852 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m07:23:54.842908 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:23:54.850461 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:23:54.853015 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:23:54.855771 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:23:54.859055 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:23:54.860139 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m07:23:54.862184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '927b2ef7-5ae0-45b3-b71c-a0d57843ad98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f220a092110>]}
[0m07:23:54.864398 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m07:23:54.867100 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:23:54.867315 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '927b2ef7-5ae0-45b3-b71c-a0d57843ad98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f220a09e750>]}
[0m07:23:54.868455 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:23:54.870128 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:23:54.869759 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '927b2ef7-5ae0-45b3-b71c-a0d57843ad98', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f2209515dd0>]}
[0m07:23:54.871874 [warn ] [MainThread]: The selection criterion 'product_dimension_type_1' does not match any nodes
[0m07:23:54.873118 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:23:54.874205 [info ] [MainThread]: 
[0m07:23:54.875618 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:23:54.875767 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m07:23:54.876901 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f220a1d2610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f220a25e7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f220a25e890>]}
[0m07:23:54.877332 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:23:54.877728 [debug] [MainThread]: Flushing usage events
[0m07:23:54.880308 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:23:54.882237 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:23:54.884778 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m07:23:54.889348 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m07:23:54.889832 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:23:54.892135 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:23:54.892275 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m07:23:54.894188 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:23:54.894287 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:23:54.896177 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m07:23:54.896219 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m07:23:54.898093 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m07:23:54.898260 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:23:54.900365 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:23:54.900392 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:23:54.902092 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:23:54.903976 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:23:54.903704 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m07:23:54.905984 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:23:54.910221 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m07:23:54.911999 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:23:54.914751 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:23:54.916844 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:23:54.919358 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:23:54.921207 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:23:54.922738 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:23:54.924948 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m07:23:54.930501 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m07:23:54.933680 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m07:23:54.938566 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:23:54.942559 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m07:23:54.945698 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m07:23:54.949247 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:23:54.955416 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m07:23:55.381414 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension.sql
[0m07:23:55.401928 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension.sql
[0m07:23:55.404635 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_periodic_fact.sql
[0m07:23:55.414482 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_periodic_fact.sql
[0m07:23:55.417104 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_report.sql
[0m07:23:55.422075 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension.sql
[0m07:23:55.426798 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_report.sql
[0m07:23:55.429217 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_transaction_fact.sql
[0m07:23:55.439839 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_transaction_fact.sql
[0m07:23:55.443405 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension.sql
[0m07:23:55.444211 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m07:23:55.446208 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_periodic_fact.sql
[0m07:23:55.449141 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m07:23:55.455204 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_periodic_fact.sql
[0m07:23:55.458150 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_report.sql
[0m07:23:55.467516 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_report.sql
[0m07:23:55.469767 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_transaction_fact.sql
[0m07:23:55.481840 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_transaction_fact.sql
[0m07:23:55.486073 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m07:23:55.491001 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m07:23:55.572009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6ee6e012-3f71-4eca-8581-8dd988d2d267', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8770a26190>]}
[0m07:23:55.578081 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6ee6e012-3f71-4eca-8581-8dd988d2d267', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8770a17dd0>]}
[0m07:23:55.579375 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:23:55.580553 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6ee6e012-3f71-4eca-8581-8dd988d2d267', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f877123a4d0>]}
[0m07:23:55.582285 [info ] [MainThread]: 
[0m07:23:55.583798 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:23:55.585610 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:23:55.586509 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:23:55.587371 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m07:23:55.589408 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:23:55.590711 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:23:55.591959 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m07:23:55.593121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8770b8c690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87700c36d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f87700c35d0>]}
[0m07:23:55.593973 [debug] [MainThread]: Flushing usage events
[0m07:23:55.609602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '83538dca-3ce3-43ae-89fc-38ad3eec0346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3e4169310>]}
[0m07:23:55.614232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '83538dca-3ce3-43ae-89fc-38ad3eec0346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3e41697d0>]}
[0m07:23:55.615265 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:23:55.616200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '83538dca-3ce3-43ae-89fc-38ad3eec0346', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3e4a4c9d0>]}
[0m07:23:55.618580 [info ] [MainThread]: 
[0m07:23:55.620893 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:23:55.622528 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:23:55.623533 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:23:55.624854 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m07:23:55.626802 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:23:55.627684 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:23:55.628459 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m07:23:55.629575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3e4173d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3e414a5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa3e414a850>]}
[0m07:23:55.630494 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:24:09.288299 | 3630f8da-6472-4c80-a916-a1cc30cd48f4 ==============================
[0m07:24:09.288332 [info ] [MainThread]: Running with dbt=1.3.0


============================== 2023-02-19 07:24:09.288308 | 2e4852fa-d1c7-40e1-ada3-fbbfc3da396b ==============================
[0m07:24:09.288333 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:24:09.289780 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:24:09.290156 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:24:09.290597 [debug] [MainThread]: Tracking: tracking
[0m07:24:09.291206 [debug] [MainThread]: Tracking: tracking
[0m07:24:09.293053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8f4d69dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8f4d69850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8d3404b90>]}
[0m07:24:09.293913 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d2a9d4850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d2b8618d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d4c3f3cd0>]}


============================== 2023-02-19 07:24:09.293999 | fbcd8040-2c01-45f2-b28e-c5d89ecf9718 ==============================
[0m07:24:09.294022 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:24:09.295364 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:24:09.296459 [debug] [MainThread]: Tracking: tracking
[0m07:24:09.299313 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca6dd7bbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca6dd7b710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca6de47bd0>]}
[0m07:24:09.975101 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:24:09.975941 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:24:09.978084 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:24:09.980449 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:24:09.991200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fbcd8040-2c01-45f2-b28e-c5d89ecf9718', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca6dbb8b50>]}
[0m07:24:09.999131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fbcd8040-2c01-45f2-b28e-c5d89ecf9718', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca6dce5650>]}
[0m07:24:09.998905 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3630f8da-6472-4c80-a916-a1cc30cd48f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8d31742d0>]}
[0m07:24:10.000483 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:24:10.002462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fbcd8040-2c01-45f2-b28e-c5d89ecf9718', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca6dd69550>]}
[0m07:24:10.007365 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3630f8da-6472-4c80-a916-a1cc30cd48f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8d32a1650>]}
[0m07:24:10.007970 [info ] [MainThread]: 
[0m07:24:10.008756 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:24:10.010234 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3630f8da-6472-4c80-a916-a1cc30cd48f4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8d33e7ad0>]}
[0m07:24:10.011162 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:24:10.014078 [info ] [MainThread]: 
[0m07:24:10.015897 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:24:10.018439 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:24:10.018564 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:24:10.019639 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:24:10.019917 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:24:10.020851 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m07:24:10.021102 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m07:24:10.023949 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:24:10.024213 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:24:10.025174 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:24:10.024966 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:24:10.026933 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m07:24:10.027887 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m07:24:10.029421 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8d32c0550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8d32c09d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff8d32c0950>]}
[0m07:24:10.031030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca6dd04550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca6dd049d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fca6dd04950>]}
[0m07:24:10.031691 [debug] [MainThread]: Flushing usage events
[0m07:24:10.034145 [debug] [MainThread]: Flushing usage events
[0m07:24:10.161379 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:24:10.162494 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:24:10.175064 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2e4852fa-d1c7-40e1-ada3-fbbfc3da396b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d2a814150>]}
[0m07:24:10.180519 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2e4852fa-d1c7-40e1-ada3-fbbfc3da396b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d2a9ffdd0>]}
[0m07:24:10.181713 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:24:10.183116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2e4852fa-d1c7-40e1-ada3-fbbfc3da396b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d2b8618d0>]}
[0m07:24:10.186144 [info ] [MainThread]: 
[0m07:24:10.188400 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:24:10.191981 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:24:10.193447 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:24:10.194574 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m07:24:10.197708 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:24:10.198695 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:24:10.199511 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m07:24:10.201319 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d2a95f1d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d2a95f810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5d2a95f410>]}
[0m07:24:10.202478 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:24:23.233525 | ac4aa7b2-ddde-4338-99c2-92856802e22d ==============================
[0m07:24:23.233568 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:24:23.236656 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:24:23.237640 [debug] [MainThread]: Tracking: tracking
[0m07:24:23.241197 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c67786d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8e8155bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8e81554d0>]}


============================== 2023-02-19 07:24:23.291654 | 67a02804-690f-4d58-bbe4-a7482d1f3900 ==============================
[0m07:24:23.291687 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:24:23.293527 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:24:23.294479 [debug] [MainThread]: Tracking: tracking
[0m07:24:23.296952 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a7a5abd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a7a5ab90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a7b23b90>]}
[0m07:24:23.963540 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:24:23.964415 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:24:23.977371 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ac4aa7b2-ddde-4338-99c2-92856802e22d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c65b5210>]}
[0m07:24:23.988274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ac4aa7b2-ddde-4338-99c2-92856802e22d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c66e2310>]}
[0m07:24:23.989690 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:24:23.990998 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ac4aa7b2-ddde-4338-99c2-92856802e22d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c6844810>]}
[0m07:24:23.994259 [info ] [MainThread]: 
[0m07:24:23.996533 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:24:24.003712 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:24:24.006518 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:24:24.007548 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m07:24:24.014556 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:24:24.016192 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:24:24.017020 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m07:24:24.022030 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c67014d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c6701110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe8c6701d50>]}
[0m07:24:24.024216 [debug] [MainThread]: Flushing usage events
[0m07:24:24.060505 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:24:24.061547 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:24:24.071945 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '67a02804-690f-4d58-bbe4-a7482d1f3900', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a78965d0>]}
[0m07:24:24.076822 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '67a02804-690f-4d58-bbe4-a7482d1f3900', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a7a66ad0>]}
[0m07:24:24.077804 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:24:24.078971 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '67a02804-690f-4d58-bbe4-a7482d1f3900', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c944dd10>]}
[0m07:24:24.081123 [info ] [MainThread]: 
[0m07:24:24.082621 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:24:24.084606 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:24:24.086047 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:24:24.086894 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m07:24:24.088908 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:24:24.089590 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:24:24.090273 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m07:24:24.091252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a79df350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a79df890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7a79df590>]}
[0m07:24:24.092031 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:24:24.638930 | 6614686b-d15f-4a66-ab57-a10cf94dcb97 ==============================
[0m07:24:24.638957 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:24:24.640271 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:24:24.640969 [debug] [MainThread]: Tracking: tracking
[0m07:24:24.642354 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68b9eccb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68bb104190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68b9eccdd0>]}
[0m07:24:25.250926 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:24:25.252293 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:24:25.263401 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6614686b-d15f-4a66-ab57-a10cf94dcb97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68b9d02d90>]}
[0m07:24:25.270001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6614686b-d15f-4a66-ab57-a10cf94dcb97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68b9e36610>]}
[0m07:24:25.271084 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:24:25.272085 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6614686b-d15f-4a66-ab57-a10cf94dcb97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68b9ef7d10>]}
[0m07:24:25.274129 [info ] [MainThread]: 
[0m07:24:25.275616 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:24:25.277303 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:24:25.277998 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:24:25.278717 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m07:24:25.280460 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:24:25.281080 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:24:25.281720 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m07:24:25.283121 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68b9e55650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68b9e551d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f68b9e55c90>]}
[0m07:24:25.285769 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:24:37.998220 | fe501f91-0b78-4358-9b00-46daa8509322 ==============================
[0m07:24:37.998253 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:24:37.999596 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:24:38.000339 [debug] [MainThread]: Tracking: tracking
[0m07:24:38.001984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38057e37d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38058af750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38058af7d0>]}


============================== 2023-02-19 07:24:38.012870 | b87a7daf-f98a-427f-9187-13a7221eebb2 ==============================
[0m07:24:38.012911 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:24:38.014553 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:24:38.015476 [debug] [MainThread]: Tracking: tracking
[0m07:24:38.017777 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe67596950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe67596850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe88fb1c50>]}


============================== 2023-02-19 07:24:38.157974 | 029b1c05-bc5a-428a-a78f-d493146364d5 ==============================
[0m07:24:38.158146 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:24:38.162792 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:24:38.164661 [debug] [MainThread]: Tracking: tracking
[0m07:24:38.168159 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee63ed8550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee63ed8450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee63fa49d0>]}
[0m07:24:38.838775 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:24:38.840547 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:24:38.841157 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:24:38.842384 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:24:38.855425 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b87a7daf-f98a-427f-9187-13a7221eebb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe673d3290>]}
[0m07:24:38.857744 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fe501f91-0b78-4358-9b00-46daa8509322', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f380580b9d0>]}
[0m07:24:38.862942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b87a7daf-f98a-427f-9187-13a7221eebb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe6757e510>]}
[0m07:24:38.863336 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fe501f91-0b78-4358-9b00-46daa8509322', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38057fa610>]}
[0m07:24:38.864636 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:24:38.864656 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:24:38.866141 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b87a7daf-f98a-427f-9187-13a7221eebb2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe88fb1c50>]}
[0m07:24:38.866179 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fe501f91-0b78-4358-9b00-46daa8509322', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f38231c6410>]}
[0m07:24:38.869720 [info ] [MainThread]: 
[0m07:24:38.869781 [info ] [MainThread]: 
[0m07:24:38.871987 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:24:38.872030 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:24:38.875857 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:24:38.876304 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:24:38.877029 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:24:38.877433 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:24:38.878127 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m07:24:38.878608 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m07:24:38.881069 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:24:38.881682 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:24:38.881993 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:24:38.882510 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:24:38.882996 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m07:24:38.883462 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m07:24:38.884660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f380576d310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f380576db10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f380576d610>]}
[0m07:24:38.885016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe6751e590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe6751ea10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbe6751e890>]}
[0m07:24:38.886222 [debug] [MainThread]: Flushing usage events
[0m07:24:38.886288 [debug] [MainThread]: Flushing usage events
[0m07:24:39.022077 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:24:39.023465 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:24:39.033488 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '029b1c05-bc5a-428a-a78f-d493146364d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee63d14190>]}
[0m07:24:39.038880 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '029b1c05-bc5a-428a-a78f-d493146364d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee63f02b90>]}
[0m07:24:39.040720 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:24:39.041970 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '029b1c05-bc5a-428a-a78f-d493146364d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee858c1c50>]}
[0m07:24:39.044075 [info ] [MainThread]: 
[0m07:24:39.045538 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:24:39.048077 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:24:39.049007 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:24:39.049752 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m07:24:39.053496 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:24:39.054301 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:24:39.055219 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m07:24:39.056930 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee63e622d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee63e629d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fee63e625d0>]}
[0m07:24:39.058139 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:24:50.255700 | b8560ac8-b09e-49ca-9860-da54e55c1876 ==============================
[0m07:24:50.255728 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:24:50.256877 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:24:50.257584 [debug] [MainThread]: Tracking: tracking
[0m07:24:50.259447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba0be978d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba0be97790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba0be97bd0>]}


============================== 2023-02-19 07:24:50.342327 | d9b25b0a-a23e-4546-b38b-7321b09fd879 ==============================
[0m07:24:50.342400 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:24:50.343867 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:24:50.344717 [debug] [MainThread]: Tracking: tracking
[0m07:24:50.347040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a71f7810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a71f7610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a72c3c50>]}
[0m07:24:50.853726 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:24:50.854562 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:24:50.865987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b8560ac8-b09e-49ca-9860-da54e55c1876', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba0bcd7650>]}
[0m07:24:50.871754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b8560ac8-b09e-49ca-9860-da54e55c1876', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba0be012d0>]}
[0m07:24:50.872862 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:24:50.874176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b8560ac8-b09e-49ca-9860-da54e55c1876', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba0bea04d0>]}
[0m07:24:50.875871 [warn ] [MainThread]: The selection criterion 'test_source' does not match any nodes
[0m07:24:50.878577 [info ] [MainThread]: 
[0m07:24:50.879616 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:24:50.881698 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba110c2690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba110c2a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fba0be89d50>]}
[0m07:24:50.882739 [debug] [MainThread]: Flushing usage events
[0m07:24:50.962302 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:24:50.963351 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:24:50.975962 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'd9b25b0a-a23e-4546-b38b-7321b09fd879', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a71e8bd0>]}
[0m07:24:50.981042 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'd9b25b0a-a23e-4546-b38b-7321b09fd879', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a7160350>]}
[0m07:24:50.982374 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:24:50.983605 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'd9b25b0a-a23e-4546-b38b-7321b09fd879', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84c8c23bd0>]}
[0m07:24:50.985728 [info ] [MainThread]: 
[0m07:24:50.987063 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:24:50.988713 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:24:50.989394 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:24:50.989997 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json''
[0m07:24:50.991562 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:24:50.992178 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:24:50.992756 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '/Users/HP/Documents/Project/data-analytics-engineer-dbt/credentials/data-analytics-engineer-d7e247899ebd.json'
[0m07:24:50.993567 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a71803d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a7180050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a7180a90>]}
[0m07:24:50.994300 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:24:51.426826 | 105bfb50-a21a-4395-ab2f-a06fe72d6b70 ==============================
[0m07:24:51.426849 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:24:51.428271 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:24:51.429238 [debug] [MainThread]: Tracking: tracking
[0m07:24:51.431537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbe640d610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbe640d5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcc03e29c10>]}
[0m07:24:52.015959 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:24:52.016681 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:24:52.024707 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '105bfb50-a21a-4395-ab2f-a06fe72d6b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbe62495d0>]}
[0m07:24:52.030456 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '105bfb50-a21a-4395-ab2f-a06fe72d6b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbe6437b50>]}
[0m07:24:52.031750 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:24:52.032870 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '105bfb50-a21a-4395-ab2f-a06fe72d6b70', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbe864f850>]}
[0m07:24:52.033916 [warn ] [MainThread]: The selection criterion 'product_dimension_type_1' does not match any nodes
[0m07:24:52.035448 [info ] [MainThread]: 
[0m07:24:52.036191 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:24:52.037071 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbe64136d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbe6413d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcbe6413b90>]}
[0m07:24:52.037737 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:25:01.246950 | 0b1b4c05-4a75-4e8e-a5ac-316bf11a5bc2 ==============================
[0m07:25:01.246981 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:25:01.248427 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:25:01.249238 [debug] [MainThread]: Tracking: tracking


============================== 2023-02-19 07:25:01.249385 | 0fa116e3-3aad-4342-a4ca-575a6ac797a7 ==============================
[0m07:25:01.249416 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:25:01.250937 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0995e4d590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0995e4db90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f09b386dcd0>]}
[0m07:25:01.250865 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:25:01.251755 [debug] [MainThread]: Tracking: tracking
[0m07:25:01.253493 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4197ddc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3f7e0ec50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3f7e0ed50>]}
[0m07:25:01.741328 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:25:01.742211 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:25:01.745021 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:25:01.746209 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:25:01.753116 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0fa116e3-3aad-4342-a4ca-575a6ac797a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3f7c153d0>]}
[0m07:25:01.757886 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0b1b4c05-4a75-4e8e-a5ac-316bf11a5bc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0995c8a610>]}
[0m07:25:01.760338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0fa116e3-3aad-4342-a4ca-575a6ac797a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3f7e84ed0>]}
[0m07:25:01.761401 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:25:01.762626 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0fa116e3-3aad-4342-a4ca-575a6ac797a7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3f7e02e10>]}
[0m07:25:01.763929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0b1b4c05-4a75-4e8e-a5ac-316bf11a5bc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0995e53450>]}
[0m07:25:01.764055 [warn ] [MainThread]: The selection criterion 'test_source' does not match any nodes
[0m07:25:01.765252 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:25:01.766357 [info ] [MainThread]: 
[0m07:25:01.766392 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0b1b4c05-4a75-4e8e-a5ac-316bf11a5bc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0995e4d490>]}
[0m07:25:01.767461 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:25:01.768022 [warn ] [MainThread]: The selection criterion 'product_dimension_type_1' does not match any nodes
[0m07:25:01.768783 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3f7ddcf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3f7de3c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb3f7de3e90>]}
[0m07:25:01.769562 [debug] [MainThread]: Flushing usage events
[0m07:25:01.770383 [info ] [MainThread]: 
[0m07:25:01.771535 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:25:01.773274 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0995e539d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0995e53990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f0995e53450>]}
[0m07:25:01.774213 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:25:12.131067 | 1e789439-0b6a-4e12-944e-7e6d62d7aef2 ==============================
[0m07:25:12.131111 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:25:12.132534 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:25:12.133356 [debug] [MainThread]: Tracking: tracking
[0m07:25:12.134803 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49b4961cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49b4961dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49d2373d10>]}
[0m07:25:12.803402 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:25:12.804470 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:25:12.813232 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1e789439-0b6a-4e12-944e-7e6d62d7aef2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49b479e5d0>]}
[0m07:25:12.820226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1e789439-0b6a-4e12-944e-7e6d62d7aef2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49b48ca410>]}
[0m07:25:12.821502 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:25:12.823314 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1e789439-0b6a-4e12-944e-7e6d62d7aef2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49d2373d10>]}
[0m07:25:12.824762 [warn ] [MainThread]: The selection criterion 'test_source' does not match any nodes
[0m07:25:12.826716 [info ] [MainThread]: 
[0m07:25:12.827715 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:25:12.829603 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49b4951bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49b4951f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f49b48ca850>]}
[0m07:25:12.831111 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:25:24.611692 | c69b8189-1c11-4c51-9de1-63a952477bb0 ==============================
[0m07:25:24.611718 [info ] [MainThread]: Running with dbt=1.3.0


============================== 2023-02-19 07:25:24.611831 | 64b839bc-1939-4bc4-94ff-afa838d2e5d5 ==============================
[0m07:25:24.611861 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:25:24.612900 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:25:24.613255 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:25:24.613498 [debug] [MainThread]: Tracking: tracking
[0m07:25:24.614121 [debug] [MainThread]: Tracking: tracking
[0m07:25:24.615131 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c59fb750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7e33ab710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7e33ab790>]}
[0m07:25:24.615699 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64b80a4b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64d5abdc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64d5abd3d0>]}
[0m07:25:25.160857 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:25:25.161802 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:25:25.165309 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:25:25.166295 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:25:25.173059 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c69b8189-1c11-4c51-9de1-63a952477bb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c58382d0>]}
[0m07:25:25.177264 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '64b839bc-1939-4bc4-94ff-afa838d2e5d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64b3ed55d0>]}
[0m07:25:25.178600 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c69b8189-1c11-4c51-9de1-63a952477bb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c59cefd0>]}
[0m07:25:25.179611 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:25:25.180754 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c69b8189-1c11-4c51-9de1-63a952477bb0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c5a26d10>]}
[0m07:25:25.181999 [warn ] [MainThread]: The selection criterion 'test_source' does not match any nodes
[0m07:25:25.182961 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '64b839bc-1939-4bc4-94ff-afa838d2e5d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64b80b0dd0>]}
[0m07:25:25.183813 [info ] [MainThread]: 
[0m07:25:25.183891 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:25:25.184816 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:25:25.184915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '64b839bc-1939-4bc4-94ff-afa838d2e5d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64b80cfc10>]}
[0m07:25:25.185942 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c5a09910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c5a09e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ff7c5a09bd0>]}
[0m07:25:25.186182 [warn ] [MainThread]: The selection criterion 'product_dimension_type_1' does not match any nodes
[0m07:25:25.187311 [debug] [MainThread]: Flushing usage events
[0m07:25:25.188702 [info ] [MainThread]: 
[0m07:25:25.189781 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:25:25.190846 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64b80b0810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64b80b0c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64b80b0ad0>]}
[0m07:25:25.191938 [debug] [MainThread]: Flushing usage events
[0m07:25:30.364679 [debug] [MainThread]: Error sending anonymous usage statistics. Disabling tracking for this execution. If you wish to permanently disable tracking, see: https://docs.getdbt.com/reference/global-configs#send-anonymous-usage-stats.


============================== 2023-02-19 07:39:14.841712 | ef2da410-1daf-413f-9b64-c717be6c1375 ==============================
[0m07:39:14.841754 [info ] [MainThread]: Running with dbt=1.3.0


============================== 2023-02-19 07:39:14.841964 | a1316ea8-559c-4773-af0a-905099bfec40 ==============================
[0m07:39:14.842007 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:39:14.843495 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:39:14.844007 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:39:14.845549 [debug] [MainThread]: Tracking: tracking
[0m07:39:14.846329 [debug] [MainThread]: Tracking: tracking
[0m07:39:14.849287 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f83c5990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f83c58d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb515d6dc50>]}
[0m07:39:14.849356 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35702a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35702a050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd35702aa10>]}
[0m07:39:14.983524 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m07:39:14.983954 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m07:39:14.985153 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'a1316ea8-559c-4773-af0a-905099bfec40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd3394f3750>]}
[0m07:39:14.985437 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'ef2da410-1daf-413f-9b64-c717be6c1375', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f8233810>]}
[0m07:39:15.524864 [debug] [MainThread]: Parsing macros/etc.sql
[0m07:39:15.524788 [debug] [MainThread]: Parsing macros/etc.sql
[0m07:39:15.529723 [debug] [MainThread]: Parsing macros/catalog.sql
[0m07:39:15.529830 [debug] [MainThread]: Parsing macros/catalog.sql
[0m07:39:15.537724 [debug] [MainThread]: Parsing macros/adapters.sql
[0m07:39:15.539061 [debug] [MainThread]: Parsing macros/adapters.sql
[0m07:39:15.569437 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:39:15.570065 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:39:15.574087 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m07:39:15.574991 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m07:39:15.585790 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m07:39:15.586076 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m07:39:15.590479 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m07:39:15.590452 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m07:39:15.595882 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m07:39:15.596324 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m07:39:15.600552 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m07:39:15.602663 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m07:39:15.603683 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m07:39:15.605555 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m07:39:15.631416 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:39:15.632857 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:39:15.633401 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:39:15.634213 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m07:39:15.635303 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:39:15.636316 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:39:15.636786 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m07:39:15.637487 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:39:15.638842 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:39:15.639104 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:39:15.639904 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:39:15.640312 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:39:15.641259 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:39:15.641681 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:39:15.642633 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:39:15.642711 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:39:15.644174 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:39:15.645157 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:39:15.646633 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:39:15.649097 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:39:15.649169 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:39:15.650777 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:39:15.652202 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:39:15.652418 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:39:15.653576 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:39:15.653832 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:39:15.654813 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:39:15.655455 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:39:15.656069 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:39:15.656883 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:39:15.657312 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:39:15.657954 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:39:15.659633 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m07:39:15.659980 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:39:15.662066 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:39:15.663702 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m07:39:15.665103 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m07:39:15.666504 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m07:39:15.668032 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m07:39:15.670202 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:39:15.670777 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m07:39:15.674678 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:39:15.690885 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m07:39:15.702271 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m07:39:15.708547 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m07:39:15.709572 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m07:39:15.717543 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m07:39:15.719655 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m07:39:15.722705 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m07:39:15.727487 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m07:39:15.735145 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m07:39:15.740075 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m07:39:15.745040 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m07:39:15.750232 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m07:39:15.754929 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m07:39:15.763608 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m07:39:15.767931 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m07:39:15.771631 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m07:39:15.773142 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m07:39:15.773374 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m07:39:15.774857 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m07:39:15.776480 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m07:39:15.779593 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m07:39:15.783801 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m07:39:15.787625 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m07:39:15.789360 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m07:39:15.789369 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m07:39:15.791381 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m07:39:15.792955 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m07:39:15.793050 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m07:39:15.795984 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m07:39:15.800721 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m07:39:15.802125 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m07:39:15.806413 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m07:39:15.807164 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m07:39:15.809516 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m07:39:15.810754 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m07:39:15.818845 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m07:39:15.823907 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m07:39:15.826295 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m07:39:15.836259 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m07:39:15.838891 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m07:39:15.849358 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m07:39:15.849492 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m07:39:15.852182 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m07:39:15.861942 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m07:39:15.862200 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m07:39:15.879896 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m07:39:15.885547 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m07:39:15.900669 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m07:39:15.979418 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m07:39:15.988307 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m07:39:15.996263 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m07:39:15.997368 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql


============================== 2023-02-19 07:39:16.004780 | 6393f17e-f101-4a0a-9f2d-36cde7c54304 ==============================
[0m07:39:16.004810 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:39:16.005890 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m07:39:16.006085 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:39:16.006846 [debug] [MainThread]: Tracking: tracking
[0m07:39:16.007056 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m07:39:16.008582 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f610a9e0c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f610a9e0610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f60ed098cd0>]}
[0m07:39:16.011696 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m07:39:16.015325 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m07:39:16.017814 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m07:39:16.022411 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m07:39:16.025914 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m07:39:16.029725 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m07:39:16.030000 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m07:39:16.042957 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m07:39:16.069212 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m07:39:16.071898 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m07:39:16.077190 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m07:39:16.083375 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m07:39:16.104648 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m07:39:16.106798 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m07:39:16.108087 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '6393f17e-f101-4a0a-9f2d-36cde7c54304', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f60ece9c790>]}
[0m07:39:16.118686 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m07:39:16.128733 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m07:39:16.138990 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m07:39:16.160913 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m07:39:16.164816 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m07:39:16.178045 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m07:39:16.182446 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m07:39:16.187903 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m07:39:16.195712 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m07:39:16.197627 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m07:39:16.211956 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:39:16.214551 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:39:16.214587 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m07:39:16.217240 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:39:16.220797 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m07:39:16.223264 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:39:16.226360 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:39:16.229254 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:39:16.231591 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:39:16.234391 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:39:16.234639 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:39:16.237604 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:39:16.238766 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m07:39:16.240683 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:39:16.240869 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:39:16.244168 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:39:16.243784 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m07:39:16.248248 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:39:16.249477 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:39:16.251595 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:39:16.252837 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:39:16.253933 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:39:16.255181 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:39:16.255925 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:39:16.257901 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:39:16.258444 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m07:39:16.261717 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:39:16.263287 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m07:39:16.266619 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m07:39:16.268221 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m07:39:16.268802 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:39:16.270799 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:39:16.271298 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m07:39:16.273594 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m07:39:16.273709 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:39:16.275851 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:39:16.276770 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:39:16.279642 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m07:39:16.282644 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:39:16.285858 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:39:16.289116 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:39:16.293018 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m07:39:16.298757 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m07:39:16.301437 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m07:39:16.304152 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:39:16.306751 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m07:39:16.309004 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m07:39:16.313662 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:39:16.319030 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m07:39:16.737185 [debug] [MainThread]: Parsing macros/etc.sql
[0m07:39:16.741954 [debug] [MainThread]: Parsing macros/catalog.sql
[0m07:39:16.750102 [debug] [MainThread]: Parsing macros/adapters.sql
[0m07:39:16.784732 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:39:16.788834 [debug] [MainThread]: Parsing macros/materializations/table.sql
[0m07:39:16.799525 [debug] [MainThread]: Parsing macros/materializations/view.sql
[0m07:39:16.803672 [debug] [MainThread]: Parsing macros/materializations/copy.sql
[0m07:39:16.807841 [debug] [MainThread]: Parsing macros/materializations/seed.sql
[0m07:39:16.812197 [debug] [MainThread]: Parsing macros/materializations/snapshot.sql
[0m07:39:16.815090 [debug] [MainThread]: Parsing macros/materializations/incremental.sql
[0m07:39:16.842714 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:39:16.845366 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:39:16.847110 [debug] [MainThread]: Parsing macros/utils/timestamps.sql
[0m07:39:16.849227 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:39:16.850413 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:39:16.851742 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:39:16.852764 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:39:16.854414 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:39:16.855658 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:39:16.857455 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:39:16.860864 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:39:16.862309 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension.sql
[0m07:39:16.863529 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:39:16.865357 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:39:16.867387 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:39:16.868704 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:39:16.870303 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:39:16.872261 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:39:16.875823 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_database.sql
[0m07:39:16.880574 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_alias.sql
[0m07:39:16.884263 [debug] [MainThread]: Parsing macros/get_custom_name/get_custom_schema.sql
[0m07:39:16.889884 [debug] [MainThread]: Parsing macros/adapters/apply_grants.sql
[0m07:39:16.890523 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension.sql
[0m07:39:16.893909 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_periodic_fact.sql
[0m07:39:16.908619 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_periodic_fact.sql
[0m07:39:16.913899 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_report.sql
[0m07:39:16.914579 [debug] [MainThread]: Parsing macros/adapters/metadata.sql
[0m07:39:16.927372 [debug] [MainThread]: Parsing macros/adapters/persist_docs.sql
[0m07:39:16.932126 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_report.sql
[0m07:39:16.936035 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_transaction_fact.sql
[0m07:39:16.939364 [debug] [MainThread]: Parsing macros/adapters/timestamps.sql
[0m07:39:16.946234 [debug] [MainThread]: Parsing macros/adapters/indexes.sql
[0m07:39:16.950853 [debug] [MainThread]: Parsing macros/adapters/relation.sql
[0m07:39:16.951544 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_transaction_fact.sql
[0m07:39:16.962384 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m07:39:16.968968 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m07:39:16.974030 [debug] [MainThread]: Parsing macros/adapters/freshness.sql
[0m07:39:16.978072 [debug] [MainThread]: Parsing macros/adapters/schema.sql
[0m07:39:16.981607 [debug] [MainThread]: Parsing macros/adapters/columns.sql
[0m07:39:16.994515 [debug] [MainThread]: Parsing macros/generic_test_sql/not_null.sql
[0m07:39:16.996349 [debug] [MainThread]: Parsing macros/generic_test_sql/unique.sql
[0m07:39:16.997373 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension.sql
[0m07:39:16.998174 [debug] [MainThread]: Parsing macros/generic_test_sql/relationships.sql
[0m07:39:16.999759 [debug] [MainThread]: Parsing macros/generic_test_sql/accepted_values.sql
[0m07:39:17.001941 [debug] [MainThread]: Parsing macros/materializations/configs.sql
[0m07:39:17.005665 [debug] [MainThread]: Parsing macros/materializations/hooks.sql
[0m07:39:17.012273 [debug] [MainThread]: Parsing macros/materializations/models/view/create_view_as.sql
[0m07:39:17.017478 [debug] [MainThread]: Parsing macros/materializations/models/view/view.sql
[0m07:39:17.022353 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension.sql
[0m07:39:17.024819 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_periodic_fact.sql
[0m07:39:17.025524 [debug] [MainThread]: Parsing macros/materializations/models/view/create_or_replace_view.sql
[0m07:39:17.039666 [debug] [MainThread]: Parsing macros/materializations/models/view/helpers.sql
[0m07:39:17.043532 [debug] [MainThread]: Parsing macros/materializations/models/incremental/on_schema_change.sql
[0m07:39:17.049318 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_periodic_fact.sql
[0m07:39:17.053791 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_report.sql
[0m07:39:17.086909 [debug] [MainThread]: Parsing macros/materializations/models/incremental/is_incremental.sql
[0m07:39:17.089733 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_report.sql
[0m07:39:17.090490 [debug] [MainThread]: Parsing macros/materializations/models/incremental/strategies.sql
[0m07:39:17.092632 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_transaction_fact.sql
[0m07:39:17.104048 [debug] [MainThread]: Parsing macros/materializations/models/incremental/column_helpers.sql
[0m07:39:17.107305 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_transaction_fact.sql
[0m07:39:17.112323 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m07:39:17.123709 [debug] [MainThread]: Parsing macros/materializations/models/incremental/merge.sql
[0m07:39:17.124766 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m07:39:17.147088 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ef2da410-1daf-413f-9b64-c717be6c1375', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f81ac210>]}
[0m07:39:17.151132 [debug] [MainThread]: Parsing macros/materializations/models/incremental/incremental.sql
[0m07:39:17.151887 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ef2da410-1daf-413f-9b64-c717be6c1375', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f819fa10>]}
[0m07:39:17.153308 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:39:17.154381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ef2da410-1daf-413f-9b64-c717be6c1375', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb515d6dc50>]}
[0m07:39:17.155621 [warn ] [MainThread]: The selection criterion 'product_dimension_type_1' does not match any nodes
[0m07:39:17.157400 [info ] [MainThread]: 
[0m07:39:17.158283 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:39:17.159520 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f83145d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f8314910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb4f819ff10>]}
[0m07:39:17.160525 [debug] [MainThread]: Flushing usage events
[0m07:39:17.234483 [debug] [MainThread]: Parsing macros/materializations/models/table/table.sql
[0m07:39:17.244162 [debug] [MainThread]: Parsing macros/materializations/models/table/create_table_as.sql
[0m07:39:17.250510 [debug] [MainThread]: Parsing macros/materializations/tests/test.sql
[0m07:39:17.256835 [debug] [MainThread]: Parsing macros/materializations/tests/where_subquery.sql
[0m07:39:17.260917 [debug] [MainThread]: Parsing macros/materializations/tests/helpers.sql
[0m07:39:17.264699 [debug] [MainThread]: Parsing macros/materializations/seeds/seed.sql
[0m07:39:17.271999 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a1316ea8-559c-4773-af0a-905099bfec40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33949f310>]}
[0m07:39:17.273890 [debug] [MainThread]: Parsing macros/materializations/seeds/helpers.sql
[0m07:39:17.278250 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a1316ea8-559c-4773-af0a-905099bfec40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33949fbd0>]}
[0m07:39:17.279278 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:39:17.280221 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a1316ea8-559c-4773-af0a-905099bfec40', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd339649b50>]}
[0m07:39:17.281201 [warn ] [MainThread]: The selection criterion 'test_source' does not match any nodes
[0m07:39:17.282764 [info ] [MainThread]: 
[0m07:39:17.283670 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:39:17.284638 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd338909290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33949fbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fd33949f150>]}
[0m07:39:17.285415 [debug] [MainThread]: Flushing usage events
[0m07:39:17.297121 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot_merge.sql
[0m07:39:17.299822 [debug] [MainThread]: Parsing macros/materializations/snapshots/strategies.sql
[0m07:39:17.320604 [debug] [MainThread]: Parsing macros/materializations/snapshots/snapshot.sql
[0m07:39:17.335647 [debug] [MainThread]: Parsing macros/materializations/snapshots/helpers.sql
[0m07:39:17.351697 [debug] [MainThread]: Parsing macros/etc/datetime.sql
[0m07:39:17.365848 [debug] [MainThread]: Parsing macros/etc/statement.sql
[0m07:39:17.374872 [debug] [MainThread]: Parsing macros/python_model/python.sql
[0m07:39:17.383529 [debug] [MainThread]: Parsing macros/utils/data_types.sql
[0m07:39:17.394826 [debug] [MainThread]: Parsing macros/utils/bool_or.sql
[0m07:39:17.396784 [debug] [MainThread]: Parsing macros/utils/hash.sql
[0m07:39:17.398643 [debug] [MainThread]: Parsing macros/utils/safe_cast.sql
[0m07:39:17.401043 [debug] [MainThread]: Parsing macros/utils/cast_bool_to_text.sql
[0m07:39:17.403574 [debug] [MainThread]: Parsing macros/utils/dateadd.sql
[0m07:39:17.406570 [debug] [MainThread]: Parsing macros/utils/except.sql
[0m07:39:17.408198 [debug] [MainThread]: Parsing macros/utils/right.sql
[0m07:39:17.410207 [debug] [MainThread]: Parsing macros/utils/date_trunc.sql
[0m07:39:17.412387 [debug] [MainThread]: Parsing macros/utils/listagg.sql
[0m07:39:17.415926 [debug] [MainThread]: Parsing macros/utils/any_value.sql
[0m07:39:17.417571 [debug] [MainThread]: Parsing macros/utils/datediff.sql
[0m07:39:17.420044 [debug] [MainThread]: Parsing macros/utils/array_concat.sql
[0m07:39:17.421724 [debug] [MainThread]: Parsing macros/utils/array_construct.sql
[0m07:39:17.424007 [debug] [MainThread]: Parsing macros/utils/array_append.sql
[0m07:39:17.425837 [debug] [MainThread]: Parsing macros/utils/intersect.sql
[0m07:39:17.427498 [debug] [MainThread]: Parsing macros/utils/position.sql
[0m07:39:17.429458 [debug] [MainThread]: Parsing macros/utils/last_day.sql
[0m07:39:17.432029 [debug] [MainThread]: Parsing macros/utils/replace.sql
[0m07:39:17.434330 [debug] [MainThread]: Parsing macros/utils/concat.sql
[0m07:39:17.436296 [debug] [MainThread]: Parsing macros/utils/escape_single_quotes.sql
[0m07:39:17.438490 [debug] [MainThread]: Parsing macros/utils/length.sql
[0m07:39:17.440089 [debug] [MainThread]: Parsing macros/utils/literal.sql
[0m07:39:17.441742 [debug] [MainThread]: Parsing macros/utils/split_part.sql
[0m07:39:17.445315 [debug] [MainThread]: Parsing tests/generic/builtin.sql
[0m07:39:17.828345 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension.sql
[0m07:39:17.847168 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension.sql
[0m07:39:17.849521 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_periodic_fact.sql
[0m07:39:17.857853 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_periodic_fact.sql
[0m07:39:17.861633 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_report.sql
[0m07:39:17.873300 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_report.sql
[0m07:39:17.875530 [debug] [MainThread]: 1603: static parser failed on dimension_models/sales_transaction_fact.sql
[0m07:39:17.886082 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/sales_transaction_fact.sql
[0m07:39:17.889522 [debug] [MainThread]: 1699: static parser successfully parsed example/my_first_dbt_model.sql
[0m07:39:17.894752 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m07:39:18.018219 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '6393f17e-f101-4a0a-9f2d-36cde7c54304', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f60ece18110>]}
[0m07:39:18.023255 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '6393f17e-f101-4a0a-9f2d-36cde7c54304', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f60ece09f10>]}
[0m07:39:18.024112 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:39:18.024965 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6393f17e-f101-4a0a-9f2d-36cde7c54304', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f60ed74ca50>]}
[0m07:39:18.027760 [info ] [MainThread]: 
[0m07:39:18.029586 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:39:18.031967 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:39:18.032958 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:39:18.921684 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m07:39:18.922543 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:39:19.619252 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '6393f17e-f101-4a0a-9f2d-36cde7c54304', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f60ece72310>]}
[0m07:39:19.620514 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:39:19.621304 [info ] [MainThread]: 
[0m07:39:19.629437 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m07:39:19.630395 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.sales_transaction_fact . [RUN]
[0m07:39:19.631618 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_transaction_fact"
[0m07:39:19.632229 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m07:39:19.632846 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m07:39:19.641215 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_transaction_fact"
[0m07:39:19.659188 [debug] [Thread-1  ]: finished collecting timing info
[0m07:39:19.659963 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m07:39:19.722973 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m07:39:20.475649 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.sales_transaction_fact"
[0m07:39:20.496921 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.sales_transaction_fact: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_transaction_fact"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact` as DBT_INTERNAL_DEST
        using (
          
    






SELECT
    id,
    order_id,
    user_id,
    product_id,
    inventory_item_id,
    status,
    created_at,
    shipped_at,
    delivered_at,
    returned_at,
    sale_price
FROM (
    SELECT *, ROW_NUMBER() OVER(PARTITION BY id ORDER BY created_at DESC) AS row_num
    FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`order_items_delta`
    WHERE DATE(created_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))
)
WHERE row_num = 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and TIMESTAMP_trunc(DBT_INTERNAL_DEST.created_at, DAY) in (
              TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`id`, `order_id`, `user_id`, `product_id`, `inventory_item_id`, `status`, `created_at`, `shipped_at`, `delivered_at`, `returned_at`, `sale_price`)
    values
        (`id`, `order_id`, `user_id`, `product_id`, `inventory_item_id`, `status`, `created_at`, `shipped_at`, `delivered_at`, `returned_at`, `sale_price`)



  


    
[0m07:39:23.617620 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:7d303272-09e6-4e0d-8b67-5ba640aba1f0:US&page=queryresults
[0m07:39:23.669923 [debug] [Thread-1  ]: finished collecting timing info
[0m07:39:23.673672 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6393f17e-f101-4a0a-9f2d-36cde7c54304', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f60ec132c10>]}
[0m07:39:23.676143 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.sales_transaction_fact  [[32mMERGE (0.0 rows, 0 processed)[0m in 4.04s]
[0m07:39:23.678196 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m07:39:23.775250 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:39:23.780019 [info ] [MainThread]: 
[0m07:39:23.782320 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 5.75 seconds (5.75s).
[0m07:39:23.784091 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:39:23.785143 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:39:23.787069 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_transaction_fact' was properly closed.
[0m07:39:23.789714 [info ] [MainThread]: 
[0m07:39:23.796846 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:39:23.799010 [info ] [MainThread]: 
[0m07:39:23.802249 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m07:39:23.803884 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f60ece18350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f60ec11a810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f60ec11a0d0>]}
[0m07:39:23.805467 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:39:33.876153 | cb8119a2-5cfc-4394-b2e3-1f91663d6836 ==============================
[0m07:39:33.876209 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:39:33.878803 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:39:33.879776 [debug] [MainThread]: Tracking: tracking
[0m07:39:33.883022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24d5d70c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24d5d70b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24d5d70b10>]}


============================== 2023-02-19 07:39:34.008138 | a78a10fa-c8bf-44e5-86c0-d337c4614dc6 ==============================
[0m07:39:34.008202 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:39:34.012701 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:39:34.016062 [debug] [MainThread]: Tracking: tracking
[0m07:39:34.018318 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719f460bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719f460dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719f4601d0>]}
[0m07:39:34.623065 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:39:34.624008 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:39:34.645466 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'cb8119a2-5cfc-4394-b2e3-1f91663d6836', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24db708910>]}
[0m07:39:34.653671 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'cb8119a2-5cfc-4394-b2e3-1f91663d6836', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24d5d44850>]}
[0m07:39:34.655159 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:39:34.656462 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cb8119a2-5cfc-4394-b2e3-1f91663d6836', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24d5d3d990>]}
[0m07:39:34.659216 [info ] [MainThread]: 
[0m07:39:34.661668 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:39:34.717184 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:39:34.718699 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:39:34.752034 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:39:34.754782 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:39:34.782572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'a78a10fa-c8bf-44e5-86c0-d337c4614dc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719fd26690>]}
[0m07:39:34.796890 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'a78a10fa-c8bf-44e5-86c0-d337c4614dc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719f46d690>]}
[0m07:39:34.798363 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:39:34.800436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a78a10fa-c8bf-44e5-86c0-d337c4614dc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719f510c50>]}
[0m07:39:34.805285 [info ] [MainThread]: 
[0m07:39:34.810180 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:39:34.826426 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:39:34.827456 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:39:35.666855 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m07:39:35.668013 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:39:35.883241 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m07:39:35.884192 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:39:36.366335 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'cb8119a2-5cfc-4394-b2e3-1f91663d6836', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24d5caf550>]}
[0m07:39:36.367789 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:39:36.368841 [info ] [MainThread]: 
[0m07:39:36.379136 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.product_dimension
[0m07:39:36.380654 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.product_dimension ...... [RUN]
[0m07:39:36.382961 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.product_dimension"
[0m07:39:36.384023 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.product_dimension
[0m07:39:36.385014 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.product_dimension
[0m07:39:36.402853 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.product_dimension"
[0m07:39:36.424195 [debug] [Thread-1  ]: finished collecting timing info
[0m07:39:36.425065 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.product_dimension
[0m07:39:36.540490 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m07:39:36.620343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'a78a10fa-c8bf-44e5-86c0-d337c4614dc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719f3ea250>]}
[0m07:39:36.623573 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:39:36.625375 [info ] [MainThread]: 
[0m07:39:36.636717 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m07:39:36.637776 [info ] [Thread-1  ]: 1 of 1 START sql table model bigquery_example_dbt.my_first_dbt_model ........... [RUN]
[0m07:39:36.639356 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_first_dbt_model"
[0m07:39:36.640077 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m07:39:36.640888 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m07:39:36.649238 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
[0m07:39:36.667712 [debug] [Thread-1  ]: finished collecting timing info
[0m07:39:36.668744 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m07:39:36.704581 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m07:39:37.526465 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
[0m07:39:37.542367 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.product_dimension"
[0m07:39:37.555728 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_first_dbt_model"} */

  
    

    create or replace table `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m07:39:37.571274 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.product_dimension: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.product_dimension"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension` as DBT_INTERNAL_DEST
        using (
          
    






SELECT id, brand, department, category, updated_at
FROM (
    SELECT id, brand, department, category, updated_at,
        ROW_NUMBER() OVER(PARTITION BY id ORDER BY updated_at DESC) AS row_num
    FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`products_delta`
    WHERE DATE(updated_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))
)
WHERE row_num = 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and TIMESTAMP_trunc(DBT_INTERNAL_DEST.updated_at, DAY) in (
              TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`id`, `brand`, `department`, `category`, `updated_at`)
    values
        (`id`, `brand`, `department`, `category`, `updated_at`)



  


    
[0m07:39:40.071462 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:01cc5f92-af26-47a5-89ff-d2a007a5dfa7:US&page=queryresults
[0m07:39:40.170620 [debug] [Thread-1  ]: finished collecting timing info
[0m07:39:40.174710 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a78a10fa-c8bf-44e5-86c0-d337c4614dc6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719f007d50>]}
[0m07:39:40.176953 [info ] [Thread-1  ]: 1 of 1 OK created sql table model bigquery_example_dbt.my_first_dbt_model ...... [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 3.54s]
[0m07:39:40.179362 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m07:39:40.271441 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:39:40.274273 [info ] [MainThread]: 
[0m07:39:40.287918 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 5.46 seconds (5.46s).
[0m07:39:40.290094 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:39:40.291238 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_first_dbt_model' was properly closed.
[0m07:39:40.292949 [info ] [MainThread]: 
[0m07:39:40.294974 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:39:40.296513 [info ] [MainThread]: 
[0m07:39:40.297903 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m07:39:40.307897 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719f010910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719f019d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f719f0197d0>]}
[0m07:39:40.310460 [debug] [MainThread]: Flushing usage events
[0m07:39:41.593557 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:fbc9190c-72b2-4ef7-a6e1-9f9b23d88849:US&page=queryresults
[0m07:39:41.649303 [debug] [Thread-1  ]: finished collecting timing info
[0m07:39:41.656828 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cb8119a2-5cfc-4394-b2e3-1f91663d6836', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24d5c6bc90>]}
[0m07:39:41.659555 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.product_dimension . [[32mMERGE (0.0 rows, 44.0 Bytes processed)[0m in 5.27s]
[0m07:39:41.665365 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.product_dimension
[0m07:39:41.680172 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:39:41.682098 [info ] [MainThread]: 
[0m07:39:41.685645 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.02 seconds (7.02s).
[0m07:39:41.689422 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:39:41.694241 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:39:41.696264 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.product_dimension' was properly closed.
[0m07:39:41.697845 [info ] [MainThread]: 
[0m07:39:41.700386 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:39:41.701976 [info ] [MainThread]: 
[0m07:39:41.704512 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m07:39:41.706832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24d5d44d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24d5aa2ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f24d5aa2c10>]}
[0m07:39:41.712726 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:39:42.098724 | 317f2529-8776-41d9-92dc-07858ee19bc5 ==============================
[0m07:39:42.098755 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:39:42.100176 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_periodic_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:39:42.101037 [debug] [MainThread]: Tracking: tracking
[0m07:39:42.102849 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fff784390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fff784c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fff784e10>]}
[0m07:39:43.046151 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:39:43.047965 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:39:43.075072 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '317f2529-8776-41d9-92dc-07858ee19bc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe1ba3510>]}
[0m07:39:43.080943 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '317f2529-8776-41d9-92dc-07858ee19bc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe1d70990>]}
[0m07:39:43.082913 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:39:43.084953 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '317f2529-8776-41d9-92dc-07858ee19bc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe1d66550>]}
[0m07:39:43.089768 [info ] [MainThread]: 
[0m07:39:43.093123 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:39:43.095872 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:39:43.097062 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:39:43.995250 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m07:39:43.996238 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:39:44.637253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '317f2529-8776-41d9-92dc-07858ee19bc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe1cdcc90>]}
[0m07:39:44.639674 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:39:44.640839 [info ] [MainThread]: 
[0m07:39:44.648076 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m07:39:44.648903 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.sales_periodic_fact .... [RUN]
[0m07:39:44.650218 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_periodic_fact"
[0m07:39:44.650861 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m07:39:44.651586 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m07:39:44.662307 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_periodic_fact"
[0m07:39:44.679769 [debug] [Thread-1  ]: finished collecting timing info
[0m07:39:44.680464 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m07:39:44.747940 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m07:39:45.565360 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.sales_periodic_fact"
[0m07:39:45.585580 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.sales_periodic_fact: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_periodic_fact"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_periodic_fact` as DBT_INTERNAL_DEST
        using (
          
    







SELECT
  DATE(created_at) AS transaction_date,
  SUM(IF(returned_at IS NULL, sale_price, sale_price * -1)) AS total_sale
FROM `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact`
WHERE DATE(created_at) = DATE(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY))
GROUP BY 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and DBT_INTERNAL_DEST.transaction_date in (
              DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`transaction_date`, `total_sale`)
    values
        (`transaction_date`, `total_sale`)



  


    
[0m07:39:48.374842 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:75533a7e-3d73-4ca8-8d86-eb943c3762fd:US&page=queryresults
[0m07:39:48.401468 [debug] [Thread-1  ]: finished collecting timing info
[0m07:39:48.406079 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '317f2529-8776-41d9-92dc-07858ee19bc5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe1cdc550>]}
[0m07:39:48.408743 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.sales_periodic_fact  [[32mMERGE (0.0 rows, 0 processed)[0m in 3.76s]
[0m07:39:48.411835 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m07:39:48.470297 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:39:48.471691 [info ] [MainThread]: 
[0m07:39:48.472636 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 5.38 seconds (5.38s).
[0m07:39:48.473635 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:39:48.474387 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_periodic_fact' was properly closed.
[0m07:39:48.475112 [info ] [MainThread]: 
[0m07:39:48.476019 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:39:48.477191 [info ] [MainThread]: 
[0m07:39:48.478182 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m07:39:48.479487 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe1dc5e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe1dc5fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3fe1dc5110>]}
[0m07:39:48.480309 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:39:51.738224 | c4122962-37d6-4dcc-9f6d-892d1affa1cd ==============================
[0m07:39:51.738269 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:39:51.740462 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_second_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:39:51.741435 [debug] [MainThread]: Tracking: tracking
[0m07:39:51.743052 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa08e424810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0abdd9bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa0abdd9090>]}
[0m07:39:52.843650 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:39:52.845261 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:39:52.876377 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c4122962-37d6-4dcc-9f6d-892d1affa1cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa094a34e90>]}
[0m07:39:52.887350 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c4122962-37d6-4dcc-9f6d-892d1affa1cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa08e3f6c50>]}
[0m07:39:52.888365 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:39:52.889445 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c4122962-37d6-4dcc-9f6d-892d1affa1cd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa08f65c8d0>]}
[0m07:39:52.890894 [warn ] [MainThread]: The selection criterion 'my_second_dbt_model' does not match any nodes
[0m07:39:52.893759 [info ] [MainThread]: 
[0m07:39:52.894992 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:39:52.896324 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa08e42aa50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa08e42a050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa08e417b90>]}
[0m07:39:52.897297 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:39:53.622074 | 3dc0cd1e-0685-466d-9515-2e62fbac1693 ==============================
[0m07:39:53.622119 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:39:53.624395 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_report'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:39:53.625722 [debug] [MainThread]: Tracking: tracking
[0m07:39:53.629001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72d2ca89d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72d2d3b890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72d2d3bc90>]}
[0m07:39:54.549141 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:39:54.550411 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:39:54.570968 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3dc0cd1e-0685-466d-9515-2e62fbac1693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72d2aad290>]}
[0m07:39:54.579907 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3dc0cd1e-0685-466d-9515-2e62fbac1693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72d2c57150>]}
[0m07:39:54.583143 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:39:54.584678 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3dc0cd1e-0685-466d-9515-2e62fbac1693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72d32b1590>]}
[0m07:39:54.587690 [info ] [MainThread]: 
[0m07:39:54.591148 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:39:54.595716 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:39:54.598521 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:39:55.476136 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m07:39:55.477258 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:39:56.254776 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3dc0cd1e-0685-466d-9515-2e62fbac1693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72d2d1fb90>]}
[0m07:39:56.256366 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:39:56.257542 [info ] [MainThread]: 
[0m07:39:56.267608 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.sales_report
[0m07:39:56.268700 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.sales_report ........... [RUN]
[0m07:39:56.270300 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_report"
[0m07:39:56.271136 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.sales_report
[0m07:39:56.271832 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.sales_report
[0m07:39:56.282613 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_report"
[0m07:39:56.300876 [debug] [Thread-1  ]: finished collecting timing info
[0m07:39:56.302103 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.sales_report
[0m07:39:56.390826 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m07:39:57.260120 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.sales_report"
[0m07:39:57.279927 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.sales_report: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_report"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_report` as DBT_INTERNAL_DEST
        using (
          
    






WITH sales_transaction_data AS (
    SELECT *
    FROM `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact` sales_trans
    WHERE DATE(created_at) = DATE(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY))
)
SELECT DATE(created_at) AS transaction_date, category, brand, department, SUM(sale_price) AS total_sales
FROM (
 SELECT * EXCEPT(row_num)
 FROM (
   SELECT created_at, category, brand, department, sale_price,
   ROW_NUMBER() OVER(PARTITION BY sales_trans.id ORDER BY product_dim.updated_at DESC) AS row_num
   FROM sales_transaction_data sales_trans
     LEFT JOIN `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension` product_dim
       ON sales_trans.product_id = product_dim.id and sales_trans.created_at >= product_dim.updated_at
 )
 WHERE row_num = 1
)
GROUP BY transaction_date, category, brand, department
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and DBT_INTERNAL_DEST.transaction_date in (
              DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`transaction_date`, `category`, `brand`, `department`, `total_sales`)
    values
        (`transaction_date`, `category`, `brand`, `department`, `total_sales`)



  


    
[0m07:40:00.374157 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:e3659bcd-8e92-4982-af94-a7fe49f865bc:US&page=queryresults
[0m07:40:00.398972 [debug] [Thread-1  ]: finished collecting timing info
[0m07:40:00.400636 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3dc0cd1e-0685-466d-9515-2e62fbac1693', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72d2bf6850>]}
[0m07:40:00.401736 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.sales_report ...... [[32mMERGE (0.0 rows, 0 processed)[0m in 4.13s]
[0m07:40:00.403258 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.sales_report
[0m07:40:00.457149 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:40:00.458602 [info ] [MainThread]: 
[0m07:40:00.459767 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 5.87 seconds (5.87s).
[0m07:40:00.460755 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:40:00.461477 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m07:40:00.462414 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_report' was properly closed.
[0m07:40:00.463146 [info ] [MainThread]: 
[0m07:40:00.464117 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:40:00.465172 [info ] [MainThread]: 
[0m07:40:00.465984 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m07:40:00.466951 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72d2ba2150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72d2c75850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f72d293d1d0>]}
[0m07:40:00.467773 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:40:00.786325 | 7eb50fde-e0b2-4867-9881-8d09c1a081ab ==============================
[0m07:40:00.786351 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:40:00.787881 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:40:00.788578 [debug] [MainThread]: Tracking: tracking
[0m07:40:00.790107 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5ed933850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5edf23610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5ed933410>]}
[0m07:40:01.360277 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:40:01.361106 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:40:01.371152 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7eb50fde-e0b2-4867-9881-8d09c1a081ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5ed70a310>]}
[0m07:40:01.377355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7eb50fde-e0b2-4867-9881-8d09c1a081ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5ed8b4590>]}
[0m07:40:01.378408 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:40:01.379384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7eb50fde-e0b2-4867-9881-8d09c1a081ab', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5edf23610>]}
[0m07:40:01.380530 [warn ] [MainThread]: The selection criterion 'test_source' does not match any nodes
[0m07:40:01.382258 [info ] [MainThread]: 
[0m07:40:01.383249 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:40:01.384416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5ed8d1590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5ed8d1b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fe5ed905b10>]}
[0m07:40:01.385435 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:40:03.778696 | db5bee2c-201e-4616-b3b2-398a9d4985c7 ==============================
[0m07:40:03.779045 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:40:03.780656 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:40:03.781535 [debug] [MainThread]: Tracking: tracking
[0m07:40:03.783684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d69e64450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d87872c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d878724d0>]}
[0m07:40:04.411487 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:40:04.412465 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:40:04.421731 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'db5bee2c-201e-4616-b3b2-398a9d4985c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d69ca15d0>]}
[0m07:40:04.427684 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'db5bee2c-201e-4616-b3b2-398a9d4985c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d69e70950>]}
[0m07:40:04.428615 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:40:04.429660 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'db5bee2c-201e-4616-b3b2-398a9d4985c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d69e8f6d0>]}
[0m07:40:04.431013 [warn ] [MainThread]: The selection criterion 'product_dimension_type_1' does not match any nodes
[0m07:40:04.432846 [info ] [MainThread]: 
[0m07:40:04.433884 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:40:04.435178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d69e70cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d69e70dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d69e70950>]}
[0m07:40:04.436020 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:40:13.910415 | 3c8fffe8-e728-4dd0-89d7-f3d409f6a26c ==============================
[0m07:40:13.910441 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:40:13.911675 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_second_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:40:13.912314 [debug] [MainThread]: Tracking: tracking
[0m07:40:13.913595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a6b9d5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a6b9d7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a6c69b10>]}
[0m07:40:14.522872 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:40:14.523728 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:40:14.532468 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3c8fffe8-e728-4dd0-89d7-f3d409f6a26c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a69db4d0>]}
[0m07:40:14.537446 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3c8fffe8-e728-4dd0-89d7-f3d409f6a26c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a6c4dad0>]}
[0m07:40:14.538215 [info ] [MainThread]: Found 6 models, 0 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:40:14.539134 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3c8fffe8-e728-4dd0-89d7-f3d409f6a26c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84c85bac90>]}
[0m07:40:14.540221 [warn ] [MainThread]: The selection criterion 'my_second_dbt_model' does not match any nodes
[0m07:40:14.541785 [info ] [MainThread]: 
[0m07:40:14.542471 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:40:14.543321 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a6b90f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a6baa490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f84a6baad90>]}
[0m07:40:14.543925 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:45:03.126700 | e33afe66-fceb-4e4b-bfad-3d3084a97d62 ==============================
[0m07:45:03.126756 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:45:03.128171 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_second_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:45:03.128974 [debug] [MainThread]: Tracking: tracking
[0m07:45:03.130355 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03ea6ce050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03ea6cec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03ea6ced10>]}
[0m07:45:03.690907 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m07:45:03.692696 [debug] [MainThread]: Partial parsing: update schema file: data_warehouse_analytics_engineer://models/example/schema.yml
[0m07:45:03.815537 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e33afe66-fceb-4e4b-bfad-3d3084a97d62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03ec1a2ad0>]}
[0m07:45:03.821009 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e33afe66-fceb-4e4b-bfad-3d3084a97d62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03ccc24690>]}
[0m07:45:03.821872 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:45:03.822771 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e33afe66-fceb-4e4b-bfad-3d3084a97d62', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03ccd87710>]}
[0m07:45:03.823781 [warn ] [MainThread]: The selection criterion 'my_second_dbt_model' does not match any nodes
[0m07:45:03.826221 [info ] [MainThread]: 
[0m07:45:03.827249 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:45:03.828343 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03ccc24e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03ccc24490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f03ccc24f90>]}
[0m07:45:03.829218 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:45:23.112201 | edd9f041-a56d-45e0-b90f-61147425b286 ==============================
[0m07:45:23.112233 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:45:23.113609 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_second_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:45:23.114365 [debug] [MainThread]: Tracking: tracking
[0m07:45:23.116253 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45e1a4f310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45e1a4f690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45c4107bd0>]}
[0m07:45:23.717487 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m07:45:23.718187 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m07:45:23.726858 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'edd9f041-a56d-45e0-b90f-61147425b286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45bfe68310>]}
[0m07:45:23.731047 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'edd9f041-a56d-45e0-b90f-61147425b286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45c4048a50>]}
[0m07:45:23.731818 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:45:23.732637 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'edd9f041-a56d-45e0-b90f-61147425b286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45c4074910>]}
[0m07:45:23.733685 [warn ] [MainThread]: The selection criterion 'my_second_dbt_model' does not match any nodes
[0m07:45:23.735323 [info ] [MainThread]: 
[0m07:45:23.736019 [warn ] [MainThread]: [[33mWARNING[0m]: Nothing to do. Try checking your model configs and model specification args
[0m07:45:23.736848 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45c4041090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45c4048d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f45c4048fd0>]}
[0m07:45:23.737444 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:47:41.735298 | 5c21bdea-1f5e-49bf-9f54-c7c07fb9369e ==============================
[0m07:47:41.735340 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:47:41.737804 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_second_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:47:41.739037 [debug] [MainThread]: Tracking: tracking
[0m07:47:41.741103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc000605e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc00062ac50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc00062a490>]}
[0m07:47:42.395760 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m07:47:42.397208 [debug] [MainThread]: Partial parsing: updated file: data_warehouse_analytics_engineer://models/example/my_second_dbt_model.sql
[0m07:47:42.428961 [debug] [MainThread]: 1699: static parser successfully parsed example/my_second_dbt_model.sql
[0m07:47:42.602538 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5c21bdea-1f5e-49bf-9f54-c7c07fb9369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdeae9790>]}
[0m07:47:42.610342 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5c21bdea-1f5e-49bf-9f54-c7c07fb9369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdeb7a590>]}
[0m07:47:42.611743 [info ] [MainThread]: Found 6 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:47:42.613114 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c21bdea-1f5e-49bf-9f54-c7c07fb9369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdec0ffd0>]}
[0m07:47:42.615784 [info ] [MainThread]: 
[0m07:47:42.617979 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:47:42.620700 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:47:42.622053 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:47:43.541848 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m07:47:43.542705 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:47:44.229412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5c21bdea-1f5e-49bf-9f54-c7c07fb9369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdeb7ad90>]}
[0m07:47:44.230910 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:47:44.232142 [info ] [MainThread]: 
[0m07:47:44.238877 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m07:47:44.240017 [info ] [Thread-1  ]: 1 of 1 START sql view model bigquery_example_dbt.my_second_dbt_model ........... [RUN]
[0m07:47:44.241405 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model"
[0m07:47:44.242353 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m07:47:44.243046 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m07:47:44.246323 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
[0m07:47:44.269324 [debug] [Thread-1  ]: finished collecting timing info
[0m07:47:44.270375 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m07:47:44.310574 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
[0m07:47:44.335071 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m07:47:44.344428 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
where id = 1;


[0m07:47:45.740097 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:29195170-8ec4-4391-baea-0c122edbd105:US&page=queryresults
[0m07:47:45.762081 [debug] [Thread-1  ]: finished collecting timing info
[0m07:47:45.763521 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5c21bdea-1f5e-49bf-9f54-c7c07fb9369e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdd66dad0>]}
[0m07:47:45.764599 [info ] [Thread-1  ]: 1 of 1 OK created sql view model bigquery_example_dbt.my_second_dbt_model ...... [[32mCREATE VIEW (0 processed)[0m in 1.52s]
[0m07:47:45.766165 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m07:47:45.849447 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:47:45.851207 [info ] [MainThread]: 
[0m07:47:45.852490 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 3.23 seconds (3.23s).
[0m07:47:45.853457 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:47:45.854122 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_second_dbt_model' was properly closed.
[0m07:47:45.854913 [info ] [MainThread]: 
[0m07:47:45.855929 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:47:45.856832 [info ] [MainThread]: 
[0m07:47:45.857658 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m07:47:45.858640 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdea23990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdc5d5d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fbfdc5d5910>]}
[0m07:47:45.859484 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:55:58.716273 | 7c307195-3db6-436a-b8e8-b0142a0ed6d0 ==============================
[0m07:55:58.716303 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:55:58.717659 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:55:58.718633 [debug] [MainThread]: Tracking: tracking
[0m07:55:58.721183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79631b7b10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7963920890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f79631b74d0>]}
[0m07:55:59.353582 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m07:55:59.354895 [debug] [MainThread]: Partial parsing: added file: data_warehouse_analytics_engineer://models/dimension_models/product_dimension_type_1.sql
[0m07:55:59.371649 [debug] [MainThread]: 1603: static parser failed on dimension_models/product_dimension_type_1.sql
[0m07:55:59.394083 [debug] [MainThread]: 1602: parser fallback to jinja rendering on dimension_models/product_dimension_type_1.sql
[0m07:55:59.483798 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '7c307195-3db6-436a-b8e8-b0142a0ed6d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7985aa36d0>]}
[0m07:55:59.489394 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '7c307195-3db6-436a-b8e8-b0142a0ed6d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f796319a890>]}
[0m07:55:59.490290 [info ] [MainThread]: Found 7 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:55:59.491297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7c307195-3db6-436a-b8e8-b0142a0ed6d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7963920890>]}
[0m07:55:59.493652 [info ] [MainThread]: 
[0m07:55:59.495022 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:55:59.496556 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:55:59.497205 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:56:00.378923 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m07:56:00.379706 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:56:01.052484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '7c307195-3db6-436a-b8e8-b0142a0ed6d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f796319a3d0>]}
[0m07:56:01.054379 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:56:01.055882 [info ] [MainThread]: 
[0m07:56:01.062172 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m07:56:01.063433 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.product_dimension_type_1  [RUN]
[0m07:56:01.064816 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.product_dimension_type_1"
[0m07:56:01.065647 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m07:56:01.066436 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m07:56:01.074365 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.product_dimension_type_1"
[0m07:56:01.093696 [debug] [Thread-1  ]: finished collecting timing info
[0m07:56:01.094583 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m07:56:01.131742 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m07:56:01.851281 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.product_dimension_type_1"
[0m07:56:01.867072 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.product_dimension_type_1: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.product_dimension_type_1"} */

        
            
                
                
            
        
    

    

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension_type_1` as DBT_INTERNAL_DEST
        using (
          

SELECT id, brand, department, category, updated_at
FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`products_main`
WHERE

    DATE(updated_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))

        ) as DBT_INTERNAL_SOURCE
        on 
                    DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
                

    
    when matched then update set
        `id` = DBT_INTERNAL_SOURCE.`id`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`department` = DBT_INTERNAL_SOURCE.`department`,`category` = DBT_INTERNAL_SOURCE.`category`,`updated_at` = DBT_INTERNAL_SOURCE.`updated_at`
    

    when not matched then insert
        (`id`, `brand`, `department`, `category`, `updated_at`)
    values
        (`id`, `brand`, `department`, `category`, `updated_at`)


    
[0m07:56:05.066558 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:71cbd107-0196-4ca4-89de-b78819edf1b9:US&page=queryresults
[0m07:56:05.082991 [debug] [Thread-1  ]: finished collecting timing info
[0m07:56:05.084156 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7c307195-3db6-436a-b8e8-b0142a0ed6d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f796368d3d0>]}
[0m07:56:05.085068 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.product_dimension_type_1  [[32mMERGE (0.0 rows, 2.6 MB processed)[0m in 4.02s]
[0m07:56:05.086233 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m07:56:05.182944 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:56:05.186224 [info ] [MainThread]: 
[0m07:56:05.188898 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 5.69 seconds (5.69s).
[0m07:56:05.191390 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:56:05.193192 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.product_dimension_type_1' was properly closed.
[0m07:56:05.195176 [info ] [MainThread]: 
[0m07:56:05.197287 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:56:05.199451 [info ] [MainThread]: 
[0m07:56:05.201371 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m07:56:05.203380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7963019d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7962605490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7962605cd0>]}
[0m07:56:05.204708 [debug] [MainThread]: Flushing usage events


============================== 2023-02-19 07:57:14.002072 | 89adf610-4b12-4b90-8200-4d886de46aff ==============================
[0m07:57:14.002107 [info ] [MainThread]: Running with dbt=1.3.0
[0m07:57:14.003394 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m07:57:14.003986 [debug] [MainThread]: Tracking: tracking
[0m07:57:14.005263 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6d37c590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6d37c390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6d4479d0>]}
[0m07:57:14.635624 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 1 files added, 0 files changed.
[0m07:57:14.636699 [debug] [MainThread]: Partial parsing: added file: data_warehouse_analytics_engineer://models/example/test_source.sql
[0m07:57:14.668413 [debug] [MainThread]: 1699: static parser successfully parsed example/test_source.sql
[0m07:57:14.789412 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '89adf610-4b12-4b90-8200-4d886de46aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6eac2650>]}
[0m07:57:14.794453 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '89adf610-4b12-4b90-8200-4d886de46aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6d2ec6d0>]}
[0m07:57:14.795315 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m07:57:14.796174 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '89adf610-4b12-4b90-8200-4d886de46aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6d4475d0>]}
[0m07:57:14.798623 [info ] [MainThread]: 
[0m07:57:14.800032 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:57:14.802107 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m07:57:14.802751 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m07:57:15.661651 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m07:57:15.662553 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m07:57:16.348423 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '89adf610-4b12-4b90-8200-4d886de46aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6d2a8b50>]}
[0m07:57:16.350331 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m07:57:16.351121 [info ] [MainThread]: 
[0m07:57:16.357660 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.test_source
[0m07:57:16.360637 [info ] [Thread-1  ]: 1 of 1 START sql view model bigquery_example_dbt.test_source ................... [RUN]
[0m07:57:16.363949 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.test_source"
[0m07:57:16.365962 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.test_source
[0m07:57:16.366935 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.test_source
[0m07:57:16.370601 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.test_source"
[0m07:57:16.393352 [debug] [Thread-1  ]: finished collecting timing info
[0m07:57:16.394220 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.test_source
[0m07:57:16.428186 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.test_source"
[0m07:57:16.453240 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m07:57:16.464923 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.test_source: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.test_source"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt`.`test_source`
  OPTIONS()
  as SELECT *
FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`order_items_delta`;


[0m07:57:17.963264 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:24f7a172-3cbc-471b-b389-42eb457b5135:US&page=queryresults
[0m07:57:17.981497 [debug] [Thread-1  ]: finished collecting timing info
[0m07:57:17.982728 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89adf610-4b12-4b90-8200-4d886de46aff', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6d388890>]}
[0m07:57:17.983721 [info ] [Thread-1  ]: 1 of 1 OK created sql view model bigquery_example_dbt.test_source .............. [[32mCREATE VIEW (0 processed)[0m in 1.62s]
[0m07:57:17.984887 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.test_source
[0m07:57:18.063808 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m07:57:18.066561 [info ] [MainThread]: 
[0m07:57:18.068405 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 3.27 seconds (3.27s).
[0m07:57:18.070065 [debug] [MainThread]: Connection 'master' was properly closed.
[0m07:57:18.071439 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.test_source' was properly closed.
[0m07:57:18.072712 [info ] [MainThread]: 
[0m07:57:18.074022 [info ] [MainThread]: [32mCompleted successfully[0m
[0m07:57:18.075357 [info ] [MainThread]: 
[0m07:57:18.076406 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m07:57:18.077464 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6d3d7d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6c5d5710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5f6c5d5ed0>]}
[0m07:57:18.078349 [debug] [MainThread]: Flushing usage events


============================== 2023-02-24 01:50:25.679944 | fb836921-475a-4188-98e2-afddb32b3f12 ==============================
[0m01:50:25.679992 [info ] [MainThread]: Running with dbt=1.3.0


============================== 2023-02-24 01:50:25.680122 | dc04be48-6ff7-47ba-81d9-fcb08c881fef ==============================
[0m01:50:25.680160 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:50:25.682324 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:50:25.682470 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:50:25.683640 [debug] [MainThread]: Tracking: tracking
[0m01:50:25.684254 [debug] [MainThread]: Tracking: tracking
[0m01:50:25.686176 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974b388790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974b3ec5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974b3ec650>]}
[0m01:50:25.686661 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1ac41a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1ac41ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1acb8c50>]}
[0m01:50:26.460519 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:50:26.461553 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:50:26.461803 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:50:26.462624 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:50:26.479381 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'dc04be48-6ff7-47ba-81d9-fcb08c881fef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1aa602d0>]}
[0m01:50:26.479841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'fb836921-475a-4188-98e2-afddb32b3f12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974b17a0d0>]}
[0m01:50:26.487053 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'dc04be48-6ff7-47ba-81d9-fcb08c881fef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1abdaf10>]}
[0m01:50:26.488295 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:50:26.489672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dc04be48-6ff7-47ba-81d9-fcb08c881fef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1acd4d10>]}
[0m01:50:26.491078 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'fb836921-475a-4188-98e2-afddb32b3f12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974b32cc50>]}
[0m01:50:26.492292 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:50:26.492853 [info ] [MainThread]: 
[0m01:50:26.494008 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fb836921-475a-4188-98e2-afddb32b3f12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974b34bb10>]}
[0m01:50:26.496315 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:50:26.497191 [info ] [MainThread]: 
[0m01:50:26.499636 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:50:26.499706 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:50:26.500758 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:26.504914 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:50:26.506058 [debug] [ThreadPool]: Opening a new connection, currently in state init


============================== 2023-02-24 01:50:27.172151 | 82318c94-a64f-4b67-b54f-a480c73a9375 ==============================
[0m01:50:27.172192 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:50:27.173889 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:50:27.174830 [debug] [MainThread]: Tracking: tracking
[0m01:50:27.176915 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f649b5796d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64bcef0b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64bcef0350>]}
[0m01:50:28.064953 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:50:28.066091 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:28.175218 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:50:28.176447 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:50:28.187978 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '82318c94-a64f-4b67-b54f-a480c73a9375', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f649bb4e550>]}
[0m01:50:28.194641 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '82318c94-a64f-4b67-b54f-a480c73a9375', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f649b51da10>]}
[0m01:50:28.195672 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:50:28.196812 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '82318c94-a64f-4b67-b54f-a480c73a9375', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f64a4ee9a10>]}
[0m01:50:28.199392 [info ] [MainThread]: 
[0m01:50:28.201188 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:50:28.203625 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:50:28.204590 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:28.363954 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:50:28.365244 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:50:29.112879 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'dc04be48-6ff7-47ba-81d9-fcb08c881fef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1ab83550>]}
[0m01:50:29.114808 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:50:29.116123 [info ] [MainThread]: 
[0m01:50:29.148567 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.test_source
[0m01:50:29.149810 [info ] [Thread-1  ]: 1 of 1 START sql view model bigquery_example_dbt.test_source ................... [RUN]
[0m01:50:29.154971 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.test_source"
[0m01:50:29.157083 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.test_source
[0m01:50:29.158618 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.test_source
[0m01:50:29.164327 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:50:29.166215 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.test_source"
[0m01:50:29.166344 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:50:29.213734 [debug] [Thread-1  ]: finished collecting timing info
[0m01:50:29.215078 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.test_source
[0m01:50:29.358471 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.test_source"
[0m01:50:29.384163 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'fb836921-475a-4188-98e2-afddb32b3f12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974b326e90>]}
[0m01:50:29.386042 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:50:29.387809 [info ] [MainThread]: 
[0m01:50:29.388977 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:50:29.398882 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m01:50:29.400252 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.product_dimension_type_1  [RUN]
[0m01:50:29.403186 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.product_dimension_type_1"
[0m01:50:29.403470 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.test_source: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.test_source"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt`.`test_source`
  OPTIONS()
  as SELECT *
FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`order_items_delta`;


[0m01:50:29.404273 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m01:50:29.405600 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m01:50:29.441322 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.product_dimension_type_1"
[0m01:50:29.464292 [debug] [Thread-1  ]: finished collecting timing info
[0m01:50:29.465427 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m01:50:29.617195 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:50:30.096929 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '82318c94-a64f-4b67-b54f-a480c73a9375', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f649b4ac210>]}
[0m01:50:30.098550 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:50:30.099908 [info ] [MainThread]: 
[0m01:50:30.110299 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m01:50:30.111814 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.sales_transaction_fact . [RUN]
[0m01:50:30.113824 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_transaction_fact"
[0m01:50:30.114703 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m01:50:30.115590 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m01:50:30.127089 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_transaction_fact"
[0m01:50:30.148910 [debug] [Thread-1  ]: finished collecting timing info
[0m01:50:30.150024 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m01:50:30.298565 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:50:30.725879 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.product_dimension_type_1"
[0m01:50:30.753886 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.product_dimension_type_1: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.product_dimension_type_1"} */

        
            
                
                
            
        
    

    

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension_type_1` as DBT_INTERNAL_DEST
        using (
          

SELECT id, brand, department, category, updated_at
FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`products_main`
WHERE

    DATE(updated_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))

        ) as DBT_INTERNAL_SOURCE
        on 
                    DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
                

    
    when matched then update set
        `id` = DBT_INTERNAL_SOURCE.`id`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`department` = DBT_INTERNAL_SOURCE.`department`,`category` = DBT_INTERNAL_SOURCE.`category`,`updated_at` = DBT_INTERNAL_SOURCE.`updated_at`
    

    when not matched then insert
        (`id`, `brand`, `department`, `category`, `updated_at`)
    values
        (`id`, `brand`, `department`, `category`, `updated_at`)


    
[0m01:50:31.290103 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:21009ffd-4fda-415e-aa5f-e2f4f1ae25b2:US&page=queryresults
[0m01:50:31.441832 [debug] [Thread-1  ]: finished collecting timing info
[0m01:50:31.443926 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'dc04be48-6ff7-47ba-81d9-fcb08c881fef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1ad61b90>]}
[0m01:50:31.445470 [info ] [Thread-1  ]: 1 of 1 OK created sql view model bigquery_example_dbt.test_source .............. [[32mCREATE VIEW (0 processed)[0m in 2.29s]
[0m01:50:31.447960 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.test_source
[0m01:50:31.519186 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:50:31.520893 [info ] [MainThread]: 
[0m01:50:31.522389 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 5.03 seconds (5.03s).
[0m01:50:31.523601 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:50:31.524588 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m01:50:31.525861 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.test_source' was properly closed.
[0m01:50:31.527070 [info ] [MainThread]: 
[0m01:50:31.528601 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:50:31.531108 [info ] [MainThread]: 
[0m01:50:31.532443 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:50:31.533914 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1a064710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1a064910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f9e1a064e10>]}
[0m01:50:31.535067 [debug] [MainThread]: Flushing usage events
[0m01:50:31.538192 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.sales_transaction_fact"
[0m01:50:31.560811 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.sales_transaction_fact: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_transaction_fact"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact` as DBT_INTERNAL_DEST
        using (
          
    






SELECT
    id,
    order_id,
    user_id,
    product_id,
    inventory_item_id,
    status,
    created_at,
    shipped_at,
    delivered_at,
    returned_at,
    sale_price
FROM (
    SELECT *, ROW_NUMBER() OVER(PARTITION BY id ORDER BY created_at DESC) AS row_num
    FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`order_items_delta`
    WHERE DATE(created_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))
)
WHERE row_num = 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and TIMESTAMP_trunc(DBT_INTERNAL_DEST.created_at, DAY) in (
              TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`id`, `order_id`, `user_id`, `product_id`, `inventory_item_id`, `status`, `created_at`, `shipped_at`, `delivered_at`, `returned_at`, `sale_price`)
    values
        (`id`, `order_id`, `user_id`, `product_id`, `inventory_item_id`, `status`, `created_at`, `shipped_at`, `delivered_at`, `returned_at`, `sale_price`)



  


    
[0m01:50:35.078761 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:3742930b-8050-42a3-96c3-f050e36ee2f0:US&page=queryresults
[0m01:50:35.116854 [debug] [Thread-1  ]: finished collecting timing info
[0m01:50:35.121199 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fb836921-475a-4188-98e2-afddb32b3f12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974b4840d0>]}
[0m01:50:35.122967 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.product_dimension_type_1  [[32mMERGE (0.0 rows, 2.6 MB processed)[0m in 5.72s]
[0m01:50:35.124590 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m01:50:35.138111 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:50:35.140529 [info ] [MainThread]: 
[0m01:50:35.142034 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 8.64 seconds (8.64s).
[0m01:50:35.143358 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:50:35.144231 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.product_dimension_type_1' was properly closed.
[0m01:50:35.145211 [info ] [MainThread]: 
[0m01:50:35.146681 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:50:35.148011 [info ] [MainThread]: 
[0m01:50:35.149377 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:50:35.151178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974a7cc7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974b484050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f974a7b96d0>]}
[0m01:50:35.153185 [debug] [MainThread]: Flushing usage events
[0m01:50:35.368045 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:efb1dad5-4015-4d2c-b7d2-583e0dac3845:US&page=queryresults
[0m01:50:35.429840 [debug] [Thread-1  ]: finished collecting timing info
[0m01:50:35.432441 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82318c94-a64f-4b67-b54f-a480c73a9375', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f649b507710>]}
[0m01:50:35.434434 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.sales_transaction_fact  [[32mMERGE (0.0 rows, 0 processed)[0m in 5.32s]
[0m01:50:35.436161 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m01:50:35.494781 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:50:35.496727 [info ] [MainThread]: 
[0m01:50:35.498084 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.30 seconds (7.30s).
[0m01:50:35.499688 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:50:35.500765 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_transaction_fact' was properly closed.
[0m01:50:35.502004 [info ] [MainThread]: 
[0m01:50:35.503265 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:50:35.504990 [info ] [MainThread]: 
[0m01:50:35.506440 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:50:35.508035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f649a85a810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f649a85a590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f649a85afd0>]}
[0m01:50:35.509489 [debug] [MainThread]: Flushing usage events


============================== 2023-02-24 01:50:52.440843 | e9b40ae7-2765-43c2-ad2b-941d8feba00d ==============================
[0m01:50:52.440927 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:50:52.477139 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:50:52.486871 [debug] [MainThread]: Tracking: tracking
[0m01:50:52.490866 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1dbadb4b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1dbadb4450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9d41bc90>]}
[0m01:50:54.069637 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:50:54.085192 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:50:54.136790 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e9b40ae7-2765-43c2-ad2b-941d8feba00d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9d23b250>]}
[0m01:50:54.214658 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e9b40ae7-2765-43c2-ad2b-941d8feba00d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9d3d1310>]}
[0m01:50:54.218998 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:50:54.221060 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e9b40ae7-2765-43c2-ad2b-941d8feba00d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9d41bc50>]}
[0m01:50:54.225377 [info ] [MainThread]: 
[0m01:50:54.240921 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:50:54.263926 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:50:54.272823 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:55.654981 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:50:55.673477 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:50:56.699932 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e9b40ae7-2765-43c2-ad2b-941d8feba00d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9e5fe750>]}
[0m01:50:56.710818 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:50:56.724769 [info ] [MainThread]: 
[0m01:50:56.747420 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m01:50:56.750476 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.sales_transaction_fact . [RUN]
[0m01:50:56.754214 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_transaction_fact"
[0m01:50:56.755527 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m01:50:56.756869 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m01:50:56.788871 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_transaction_fact"
[0m01:50:56.858451 [debug] [Thread-1  ]: finished collecting timing info
[0m01:50:56.860917 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m01:50:57.028962 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:50:58.149702 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.sales_transaction_fact"
[0m01:50:58.179689 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.sales_transaction_fact: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_transaction_fact"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact` as DBT_INTERNAL_DEST
        using (
          
    






SELECT
    id,
    order_id,
    user_id,
    product_id,
    inventory_item_id,
    status,
    created_at,
    shipped_at,
    delivered_at,
    returned_at,
    sale_price
FROM (
    SELECT *, ROW_NUMBER() OVER(PARTITION BY id ORDER BY created_at DESC) AS row_num
    FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`order_items_delta`
    WHERE DATE(created_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))
)
WHERE row_num = 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and TIMESTAMP_trunc(DBT_INTERNAL_DEST.created_at, DAY) in (
              TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`id`, `order_id`, `user_id`, `product_id`, `inventory_item_id`, `status`, `created_at`, `shipped_at`, `delivered_at`, `returned_at`, `sale_price`)
    values
        (`id`, `order_id`, `user_id`, `product_id`, `inventory_item_id`, `status`, `created_at`, `shipped_at`, `delivered_at`, `returned_at`, `sale_price`)



  


    


============================== 2023-02-24 01:50:59.032066 | eacde610-dd5e-4fb7-bff8-18fdbd6c1173 ==============================
[0m01:50:59.032107 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:50:59.033822 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:50:59.034816 [debug] [MainThread]: Tracking: tracking
[0m01:50:59.037674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb96124b5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb97ebc3b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb97ebc3990>]}


============================== 2023-02-24 01:50:59.078428 | c0bed5d3-ecd0-4c8c-94db-2b4848071e8f ==============================
[0m01:50:59.078484 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:50:59.080507 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:50:59.081792 [debug] [MainThread]: Tracking: tracking
[0m01:50:59.084503 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa26d033510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa28a9e8290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa28a9e8650>]}
[0m01:50:59.963515 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:50:59.964674 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:50:59.982233 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'eacde610-dd5e-4fb7-bff8-18fdbd6c1173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb960ffc150>]}
[0m01:50:59.989565 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'eacde610-dd5e-4fb7-bff8-18fdbd6c1173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9611c0f90>]}
[0m01:50:59.990983 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:50:59.992108 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:50:59.992765 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eacde610-dd5e-4fb7-bff8-18fdbd6c1173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb96121c910>]}
[0m01:50:59.993136 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:50:59.997041 [info ] [MainThread]: 
[0m01:50:59.999634 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:00.002312 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:51:00.003681 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:51:00.011204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c0bed5d3-ecd0-4c8c-94db-2b4848071e8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa26ce8b590>]}
[0m01:51:00.024417 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c0bed5d3-ecd0-4c8c-94db-2b4848071e8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa26d010410>]}
[0m01:51:00.026787 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:51:00.029780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c0bed5d3-ecd0-4c8c-94db-2b4848071e8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa26d06d890>]}
[0m01:51:00.037140 [info ] [MainThread]: 
[0m01:51:00.040925 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:00.043770 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:51:00.045129 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:51:00.975430 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:51:00.976990 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:51:01.261061 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:51:01.262302 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:51:01.788650 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c0bed5d3-ecd0-4c8c-94db-2b4848071e8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa26d0212d0>]}
[0m01:51:01.790365 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:51:01.791575 [info ] [MainThread]: 
[0m01:51:01.857804 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.product_dimension
[0m01:51:01.859104 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.product_dimension ...... [RUN]
[0m01:51:01.861171 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.product_dimension"
[0m01:51:01.862111 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.product_dimension
[0m01:51:01.863135 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.product_dimension
[0m01:51:01.874422 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.product_dimension"
[0m01:51:01.899082 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:01.900300 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.product_dimension
[0m01:51:02.015579 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m01:51:02.077702 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:7257fa0f-518e-400b-b91b-898e681b9146:US&page=queryresults
[0m01:51:02.082649 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'eacde610-dd5e-4fb7-bff8-18fdbd6c1173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb961151d10>]}
[0m01:51:02.088619 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:51:02.091639 [info ] [MainThread]: 
[0m01:51:02.137169 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m01:51:02.140063 [info ] [Thread-1  ]: 1 of 1 START sql table model bigquery_example_dbt.my_first_dbt_model ........... [RUN]
[0m01:51:02.148399 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_first_dbt_model"
[0m01:51:02.149846 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m01:51:02.151151 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m01:51:02.166810 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:02.170454 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e9b40ae7-2765-43c2-ad2b-941d8feba00d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9d44a850>]}
[0m01:51:02.171620 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
[0m01:51:02.172794 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.sales_transaction_fact  [[32mMERGE (0.0 rows, 0 processed)[0m in 5.42s]
[0m01:51:02.176481 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m01:51:02.187093 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:02.190794 [info ] [MainThread]: 
[0m01:51:02.192824 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.96 seconds (7.96s).
[0m01:51:02.204479 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:51:02.208704 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m01:51:02.211976 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_transaction_fact' was properly closed.
[0m01:51:02.221070 [info ] [MainThread]: 
[0m01:51:02.226631 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:51:02.246017 [info ] [MainThread]: 
[0m01:51:02.248953 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:51:02.252682 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9d3b5e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9d36da50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f1d9d44a510>]}
[0m01:51:02.263684 [debug] [MainThread]: Flushing usage events
[0m01:51:02.274352 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:02.276581 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m01:51:02.341835 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:51:03.014791 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.product_dimension"
[0m01:51:03.036561 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.product_dimension: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.product_dimension"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension` as DBT_INTERNAL_DEST
        using (
          
    






SELECT id, brand, department, category, updated_at
FROM (
    SELECT id, brand, department, category, updated_at,
        ROW_NUMBER() OVER(PARTITION BY id ORDER BY updated_at DESC) AS row_num
    FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`products_delta`
    WHERE DATE(updated_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))
)
WHERE row_num = 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and TIMESTAMP_trunc(DBT_INTERNAL_DEST.updated_at, DAY) in (
              TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`id`, `brand`, `department`, `category`, `updated_at`)
    values
        (`id`, `brand`, `department`, `category`, `updated_at`)



  


    
[0m01:51:03.218852 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
[0m01:51:03.239809 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_first_dbt_model"} */

  
    

    create or replace table `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  
[0m01:51:06.574131 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:d441ec86-22d4-45c4-ac73-13ac669b5e47:US&page=queryresults
[0m01:51:06.666739 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:06.668650 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'eacde610-dd5e-4fb7-bff8-18fdbd6c1173', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb98068a590>]}
[0m01:51:06.669894 [info ] [Thread-1  ]: 1 of 1 OK created sql table model bigquery_example_dbt.my_first_dbt_model ...... [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.52s]
[0m01:51:06.671478 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m01:51:06.761946 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:06.764191 [info ] [MainThread]: 
[0m01:51:06.766404 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 6.77 seconds (6.77s).
[0m01:51:06.768222 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:51:06.769657 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_first_dbt_model' was properly closed.
[0m01:51:06.771293 [info ] [MainThread]: 
[0m01:51:06.772999 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:51:06.774781 [info ] [MainThread]: 
[0m01:51:06.776249 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:51:06.778180 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb9606454d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb960645d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb960645950>]}
[0m01:51:06.779994 [debug] [MainThread]: Flushing usage events
[0m01:51:06.873741 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:b008eb8d-d8ee-4256-b520-05383969b59a:US&page=queryresults
[0m01:51:06.906035 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:06.907632 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0bed5d3-ecd0-4c8c-94db-2b4848071e8f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa26ce95250>]}
[0m01:51:06.908804 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.product_dimension . [[32mMERGE (0.0 rows, 44.0 Bytes processed)[0m in 5.05s]
[0m01:51:06.910457 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.product_dimension
[0m01:51:07.002605 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:07.004545 [info ] [MainThread]: 
[0m01:51:07.005865 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 6.96 seconds (6.96s).
[0m01:51:07.007095 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:51:07.008114 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt' was properly closed.
[0m01:51:07.008952 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.product_dimension' was properly closed.
[0m01:51:07.009952 [info ] [MainThread]: 
[0m01:51:07.011175 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:51:07.012697 [info ] [MainThread]: 
[0m01:51:07.013830 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:51:07.015147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa26ce90690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa26cd12850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa26cd12490>]}
[0m01:51:07.016184 [debug] [MainThread]: Flushing usage events


============================== 2023-02-24 01:51:20.346486 | 58b052d2-411b-4698-bad1-1c00b3eea739 ==============================
[0m01:51:20.346526 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:51:20.348690 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:51:20.349624 [debug] [MainThread]: Tracking: tracking
[0m01:51:20.351921 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdcb592b6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc93fa4690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc93fa4710>]}
[0m01:51:21.259190 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:51:21.260632 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:51:21.282566 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '58b052d2-411b-4698-bad1-1c00b3eea739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc93cef1d0>]}
[0m01:51:21.308575 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '58b052d2-411b-4698-bad1-1c00b3eea739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc93ee4d10>]}
[0m01:51:21.310527 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:51:21.312690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '58b052d2-411b-4698-bad1-1c00b3eea739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc987b5050>]}
[0m01:51:21.316459 [info ] [MainThread]: 
[0m01:51:21.322879 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:21.331310 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:51:21.332752 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:51:22.360517 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:51:22.362578 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:51:23.303155 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '58b052d2-411b-4698-bad1-1c00b3eea739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc98560610>]}
[0m01:51:23.305336 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:51:23.306932 [info ] [MainThread]: 
[0m01:51:23.317414 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m01:51:23.318941 [info ] [Thread-1  ]: 1 of 1 START sql table model bigquery_example_dbt.my_first_dbt_model ........... [RUN]
[0m01:51:23.320989 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_first_dbt_model"
[0m01:51:23.322242 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m01:51:23.323503 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m01:51:23.331555 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
[0m01:51:23.355757 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:23.356848 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m01:51:23.397765 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:51:24.412434 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
[0m01:51:24.477060 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_first_dbt_model"} */

  
    

    create or replace table `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  


============================== 2023-02-24 01:51:26.112385 | ad6d4a07-2338-47e1-9c55-37fb0392e680 ==============================
[0m01:51:26.112474 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:51:26.115662 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:51:26.116966 [debug] [MainThread]: Tracking: tracking
[0m01:51:26.119297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa80827b650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa80a4b5b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa825c52590>]}
[0m01:51:27.442127 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:51:27.446110 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:51:27.477459 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ad6d4a07-2338-47e1-9c55-37fb0392e680', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8080d4110>]}
[0m01:51:27.487724 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ad6d4a07-2338-47e1-9c55-37fb0392e680', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa808288ed0>]}
[0m01:51:27.489179 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:51:27.492282 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ad6d4a07-2338-47e1-9c55-37fb0392e680', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa825c52590>]}
[0m01:51:27.500914 [info ] [MainThread]: 
[0m01:51:27.504063 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:27.507219 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:51:27.511526 [debug] [ThreadPool]: Opening a new connection, currently in state init


============================== 2023-02-24 01:51:27.521582 | 081ff3fb-5d7d-4c1f-9ee1-ada6195919ef ==============================
[0m01:51:27.521633 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:51:27.523768 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_report'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:51:27.524893 [debug] [MainThread]: Tracking: tracking
[0m01:51:27.527338 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f82586828d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8236d67850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8236d678d0>]}
[0m01:51:27.949736 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:90466cc5-b01e-4b3d-a355-2b8018aff7d2:US&page=queryresults
[0m01:51:28.127280 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:28.129535 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '58b052d2-411b-4698-bad1-1c00b3eea739', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc93367690>]}
[0m01:51:28.131075 [info ] [Thread-1  ]: 1 of 1 OK created sql table model bigquery_example_dbt.my_first_dbt_model ...... [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.81s]
[0m01:51:28.132846 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m01:51:28.200131 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:28.201726 [info ] [MainThread]: 
[0m01:51:28.203083 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 6.88 seconds (6.88s).
[0m01:51:28.204673 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:51:28.205858 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_first_dbt_model' was properly closed.
[0m01:51:28.206941 [info ] [MainThread]: 
[0m01:51:28.208476 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:51:28.209933 [info ] [MainThread]: 
[0m01:51:28.211442 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:51:28.213001 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc9806cc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc9806c650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fdc9806ce10>]}
[0m01:51:28.214185 [debug] [MainThread]: Flushing usage events
[0m01:51:28.498061 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:51:28.499377 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:51:28.535249 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:51:28.536887 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:51:28.571051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '081ff3fb-5d7d-4c1f-9ee1-ada6195919ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8236af24d0>]}
[0m01:51:28.580987 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '081ff3fb-5d7d-4c1f-9ee1-ada6195919ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8236c773d0>]}
[0m01:51:28.582509 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:51:28.584160 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '081ff3fb-5d7d-4c1f-9ee1-ada6195919ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f823cee5890>]}
[0m01:51:28.587946 [info ] [MainThread]: 
[0m01:51:28.590323 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:28.593665 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:51:28.595469 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:51:29.332923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ad6d4a07-2338-47e1-9c55-37fb0392e680', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa80825bd90>]}
[0m01:51:29.334621 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:51:29.335856 [info ] [MainThread]: 
[0m01:51:29.343736 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.product_dimension
[0m01:51:29.344922 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.product_dimension ...... [RUN]
[0m01:51:29.346707 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.product_dimension"
[0m01:51:29.347693 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.product_dimension
[0m01:51:29.348623 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.product_dimension
[0m01:51:29.356962 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.product_dimension"
[0m01:51:29.390649 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:29.392091 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.product_dimension
[0m01:51:29.439152 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:51:29.440358 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:51:29.494570 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:51:30.207843 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '081ff3fb-5d7d-4c1f-9ee1-ada6195919ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8236c77690>]}
[0m01:51:30.209642 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:51:30.210944 [info ] [MainThread]: 
[0m01:51:30.218753 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.sales_report
[0m01:51:30.220205 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.sales_report ........... [RUN]
[0m01:51:30.221994 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_report"
[0m01:51:30.222837 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.sales_report
[0m01:51:30.223826 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.sales_report
[0m01:51:30.232620 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_report"
[0m01:51:30.267425 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:30.268915 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.sales_report
[0m01:51:30.357259 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:51:30.454624 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.product_dimension"
[0m01:51:30.487136 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.product_dimension: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.product_dimension"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension` as DBT_INTERNAL_DEST
        using (
          
    






SELECT id, brand, department, category, updated_at
FROM (
    SELECT id, brand, department, category, updated_at,
        ROW_NUMBER() OVER(PARTITION BY id ORDER BY updated_at DESC) AS row_num
    FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`products_delta`
    WHERE DATE(updated_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))
)
WHERE row_num = 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and TIMESTAMP_trunc(DBT_INTERNAL_DEST.updated_at, DAY) in (
              TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`id`, `brand`, `department`, `category`, `updated_at`)
    values
        (`id`, `brand`, `department`, `category`, `updated_at`)



  


    
[0m01:51:31.274052 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.sales_report"
[0m01:51:31.298788 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.sales_report: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_report"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_report` as DBT_INTERNAL_DEST
        using (
          
    






WITH sales_transaction_data AS (
    SELECT *
    FROM `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact` sales_trans
    WHERE DATE(created_at) = DATE(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY))
)
SELECT DATE(created_at) AS transaction_date, category, brand, department, SUM(sale_price) AS total_sales
FROM (
 SELECT * EXCEPT(row_num)
 FROM (
   SELECT created_at, category, brand, department, sale_price,
   ROW_NUMBER() OVER(PARTITION BY sales_trans.id ORDER BY product_dim.updated_at DESC) AS row_num
   FROM sales_transaction_data sales_trans
     LEFT JOIN `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension` product_dim
       ON sales_trans.product_id = product_dim.id and sales_trans.created_at >= product_dim.updated_at
 )
 WHERE row_num = 1
)
GROUP BY transaction_date, category, brand, department
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and DBT_INTERNAL_DEST.transaction_date in (
              DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`transaction_date`, `category`, `brand`, `department`, `total_sales`)
    values
        (`transaction_date`, `category`, `brand`, `department`, `total_sales`)



  


    
[0m01:51:34.349056 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:d8ac7d99-1dea-4964-a1f2-87b35507d1d1:US&page=queryresults
[0m01:51:34.380839 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:34.382981 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad6d4a07-2338-47e1-9c55-37fb0392e680', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa803f52150>]}
[0m01:51:34.384437 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.product_dimension . [[32mMERGE (0.0 rows, 44.0 Bytes processed)[0m in 5.04s]
[0m01:51:34.385946 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.product_dimension
[0m01:51:34.428393 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:34.430952 [info ] [MainThread]: 
[0m01:51:34.432877 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 6.93 seconds (6.93s).
[0m01:51:34.434427 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:51:34.435529 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.product_dimension' was properly closed.
[0m01:51:34.437154 [info ] [MainThread]: 
[0m01:51:34.438454 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:51:34.439896 [info ] [MainThread]: 
[0m01:51:34.441390 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:51:34.443125 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8080d8d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8080dfbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fa8080df210>]}
[0m01:51:34.444512 [debug] [MainThread]: Flushing usage events
[0m01:51:35.675152 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:53784c51-0398-465c-9a77-8c6c16f070a9:US&page=queryresults
[0m01:51:35.705186 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:35.706988 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '081ff3fb-5d7d-4c1f-9ee1-ada6195919ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8236126f90>]}
[0m01:51:35.708564 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.sales_report ...... [[32mMERGE (0.0 rows, 0 processed)[0m in 5.49s]
[0m01:51:35.710549 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.sales_report
[0m01:51:35.766782 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:35.768664 [info ] [MainThread]: 
[0m01:51:35.769994 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.18 seconds (7.18s).
[0m01:51:35.771468 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:51:35.773476 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_report' was properly closed.
[0m01:51:35.774588 [info ] [MainThread]: 
[0m01:51:35.775941 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:51:35.777313 [info ] [MainThread]: 
[0m01:51:35.779157 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:51:35.781349 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f823614a5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8236148bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f8236148790>]}
[0m01:51:35.782510 [debug] [MainThread]: Flushing usage events


============================== 2023-02-24 01:51:44.473059 | c0ad9a14-5955-4b8e-9f75-1409fb2588d8 ==============================
[0m01:51:44.473107 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:51:44.476792 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_second_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:51:44.478060 [debug] [MainThread]: Tracking: tracking
[0m01:51:44.480602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43038ff050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43038ff910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4303963c90>]}
[0m01:51:45.897446 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:51:45.898701 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:51:45.918200 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'c0ad9a14-5955-4b8e-9f75-1409fb2588d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43036ef610>]}
[0m01:51:45.925243 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'c0ad9a14-5955-4b8e-9f75-1409fb2588d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43038a3c90>]}
[0m01:51:45.926762 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:51:45.927925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c0ad9a14-5955-4b8e-9f75-1409fb2588d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4325274c10>]}
[0m01:51:45.930447 [info ] [MainThread]: 
[0m01:51:45.932094 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:45.934134 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:51:45.935191 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:51:46.837177 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:51:46.838449 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:51:47.645903 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'c0ad9a14-5955-4b8e-9f75-1409fb2588d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4303832ad0>]}
[0m01:51:47.647949 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:51:47.649441 [info ] [MainThread]: 
[0m01:51:47.658900 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m01:51:47.660160 [info ] [Thread-1  ]: 1 of 1 START sql view model bigquery_example_dbt.my_second_dbt_model ........... [RUN]
[0m01:51:47.662841 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model"
[0m01:51:47.664060 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m01:51:47.665254 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m01:51:47.673679 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
[0m01:51:47.699251 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:47.700454 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m01:51:47.781716 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
[0m01:51:47.801847 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:51:47.815347 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
where id = 1;


[0m01:51:49.690051 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:3eb58be0-be94-4ce0-8523-a15e59c3a0ec:US&page=queryresults
[0m01:51:49.829649 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:49.833169 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c0ad9a14-5955-4b8e-9f75-1409fb2588d8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4303cefc10>]}
[0m01:51:49.834733 [info ] [Thread-1  ]: 1 of 1 OK created sql view model bigquery_example_dbt.my_second_dbt_model ...... [[32mCREATE VIEW (0 processed)[0m in 2.17s]
[0m01:51:49.836779 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m01:51:49.907875 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:49.909646 [info ] [MainThread]: 
[0m01:51:49.911009 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 3.98 seconds (3.98s).
[0m01:51:49.912177 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:51:49.912863 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m01:51:49.913959 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_second_dbt_model' was properly closed.
[0m01:51:49.915001 [info ] [MainThread]: 
[0m01:51:49.916241 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:51:49.917398 [info ] [MainThread]: 
[0m01:51:49.918717 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:51:49.919979 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f43038128d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4302cf72d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4302cf7b90>]}
[0m01:51:49.920992 [debug] [MainThread]: Flushing usage events


============================== 2023-02-24 01:51:52.298181 | f4ccebcf-dab0-47f2-8aa8-6861bded4d0f ==============================
[0m01:51:52.298212 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:51:52.299817 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_periodic_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:51:52.300740 [debug] [MainThread]: Tracking: tracking
[0m01:51:52.303000 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd43affbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd43aff790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd43aff350>]}
[0m01:51:53.216391 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:51:53.217842 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing


============================== 2023-02-24 01:51:53.237268 | 0919be5b-ff1d-4e46-a691-3d4d851574b7 ==============================
[0m01:51:53.237314 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:51:53.238040 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f4ccebcf-dab0-47f2-8aa8-6861bded4d0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd438f0150>]}
[0m01:51:53.240436 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_second_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:51:53.246750 [debug] [MainThread]: Tracking: tracking
[0m01:51:53.249384 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce921da50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce92af890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce92afd10>]}
[0m01:51:53.256786 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f4ccebcf-dab0-47f2-8aa8-6861bded4d0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd43a766d0>]}
[0m01:51:53.258362 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:51:53.260183 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f4ccebcf-dab0-47f2-8aa8-6861bded4d0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd43a9e3d0>]}
[0m01:51:53.264451 [info ] [MainThread]: 
[0m01:51:53.267482 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:53.272202 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:51:53.273539 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:51:54.282016 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:51:54.286823 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:51:54.705269 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:51:54.706755 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:51:54.734235 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '0919be5b-ff1d-4e46-a691-3d4d851574b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce903b2d0>]}
[0m01:51:54.744554 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '0919be5b-ff1d-4e46-a691-3d4d851574b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce91e3a10>]}
[0m01:51:54.746161 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:51:54.748147 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0919be5b-ff1d-4e46-a691-3d4d851574b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce90c30d0>]}
[0m01:51:54.752900 [info ] [MainThread]: 
[0m01:51:54.758825 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:54.762873 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:51:54.764259 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:51:55.104112 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f4ccebcf-dab0-47f2-8aa8-6861bded4d0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd43a13f50>]}
[0m01:51:55.106089 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:51:55.107627 [info ] [MainThread]: 
[0m01:51:55.116378 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m01:51:55.117642 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.sales_periodic_fact .... [RUN]
[0m01:51:55.119880 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_periodic_fact"
[0m01:51:55.120779 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m01:51:55.121794 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m01:51:55.135369 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_periodic_fact"
[0m01:51:55.160320 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:55.161498 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m01:51:55.262310 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:51:55.627202 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:51:55.628658 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:51:56.274326 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.sales_periodic_fact"
[0m01:51:56.297536 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.sales_periodic_fact: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_periodic_fact"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_periodic_fact` as DBT_INTERNAL_DEST
        using (
          
    







SELECT
  DATE(created_at) AS transaction_date,
  SUM(IF(returned_at IS NULL, sale_price, sale_price * -1)) AS total_sale
FROM `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact`
WHERE DATE(created_at) = DATE(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY))
GROUP BY 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and DBT_INTERNAL_DEST.transaction_date in (
              DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`transaction_date`, `total_sale`)
    values
        (`transaction_date`, `total_sale`)



  


    
[0m01:51:56.458016 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '0919be5b-ff1d-4e46-a691-3d4d851574b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcceb425650>]}
[0m01:51:56.460385 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:51:56.461937 [info ] [MainThread]: 
[0m01:51:56.472451 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m01:51:56.474036 [info ] [Thread-1  ]: 1 of 1 START sql view model bigquery_example_dbt.my_second_dbt_model ........... [RUN]
[0m01:51:56.476700 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model"
[0m01:51:56.477640 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m01:51:56.478680 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m01:51:56.485483 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
[0m01:51:56.509983 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:56.511486 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m01:51:56.580779 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
[0m01:51:56.601834 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:51:56.615841 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
where id = 1;


[0m01:51:58.406711 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:58e5546a-1ee8-44f7-9a2c-150098f1bac9:US&page=queryresults
[0m01:51:58.553010 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:58.555125 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0919be5b-ff1d-4e46-a691-3d4d851574b7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce8660f50>]}
[0m01:51:58.557761 [info ] [Thread-1  ]: 1 of 1 OK created sql view model bigquery_example_dbt.my_second_dbt_model ...... [[32mCREATE VIEW (0 processed)[0m in 2.08s]
[0m01:51:58.559561 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m01:51:58.627950 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:58.649877 [info ] [MainThread]: 
[0m01:51:58.661138 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 3.89 seconds (3.89s).
[0m01:51:58.663396 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:51:58.665135 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m01:51:58.666792 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_second_dbt_model' was properly closed.
[0m01:51:58.668371 [info ] [MainThread]: 
[0m01:51:58.675569 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:51:58.678456 [info ] [MainThread]: 
[0m01:51:58.680179 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:51:58.682022 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce94280d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce9344810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcce93445d0>]}
[0m01:51:58.683459 [debug] [MainThread]: Flushing usage events
[0m01:51:59.736898 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:e19b8726-1840-4ce2-a660-97d610c3c3a5:US&page=queryresults
[0m01:51:59.779389 [debug] [Thread-1  ]: finished collecting timing info
[0m01:51:59.781166 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f4ccebcf-dab0-47f2-8aa8-6861bded4d0f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd43971a90>]}
[0m01:51:59.782635 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.sales_periodic_fact  [[32mMERGE (0.0 rows, 0 processed)[0m in 4.66s]
[0m01:51:59.784362 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m01:51:59.852963 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:51:59.854587 [info ] [MainThread]: 
[0m01:51:59.855856 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 6.59 seconds (6.59s).
[0m01:51:59.857248 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:51:59.858195 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_periodic_fact' was properly closed.
[0m01:51:59.859185 [info ] [MainThread]: 
[0m01:51:59.860456 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:51:59.861867 [info ] [MainThread]: 
[0m01:51:59.863147 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:51:59.864523 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd4834ce90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd43a9d650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fcd43a9d410>]}
[0m01:51:59.865680 [debug] [MainThread]: Flushing usage events


============================== 2023-02-24 01:52:05.415885 | 1c36bfef-4605-4989-82a7-13c5357795b2 ==============================
[0m01:52:05.415922 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:52:05.417432 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:52:05.418491 [debug] [MainThread]: Tracking: tracking
[0m01:52:05.420552 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32948cb410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32b2293bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32b22933d0>]}
[0m01:52:06.299966 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:52:06.301209 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:52:06.312020 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '1c36bfef-4605-4989-82a7-13c5357795b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32946bd250>]}
[0m01:52:06.319780 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '1c36bfef-4605-4989-82a7-13c5357795b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3294870ad0>]}
[0m01:52:06.321396 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:52:06.322715 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1c36bfef-4605-4989-82a7-13c5357795b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3295a99610>]}
[0m01:52:06.326364 [info ] [MainThread]: 
[0m01:52:06.328750 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:52:06.331347 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:52:06.332428 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:52:07.306322 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:52:07.307600 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:52:08.082908 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '1c36bfef-4605-4989-82a7-13c5357795b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32947d1510>]}
[0m01:52:08.084905 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:52:08.086401 [info ] [MainThread]: 
[0m01:52:08.097202 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m01:52:08.098407 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.product_dimension_type_1  [RUN]
[0m01:52:08.100678 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.product_dimension_type_1"
[0m01:52:08.102060 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m01:52:08.103087 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m01:52:08.132400 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.product_dimension_type_1"
[0m01:52:08.152695 [debug] [Thread-1  ]: finished collecting timing info
[0m01:52:08.153885 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m01:52:08.237936 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:52:09.213107 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.product_dimension_type_1"
[0m01:52:09.240907 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.product_dimension_type_1: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.product_dimension_type_1"} */

        
            
                
                
            
        
    

    

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension_type_1` as DBT_INTERNAL_DEST
        using (
          

SELECT id, brand, department, category, updated_at
FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`products_main`
WHERE

    DATE(updated_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))

        ) as DBT_INTERNAL_SOURCE
        on 
                    DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
                

    
    when matched then update set
        `id` = DBT_INTERNAL_SOURCE.`id`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`department` = DBT_INTERNAL_SOURCE.`department`,`category` = DBT_INTERNAL_SOURCE.`category`,`updated_at` = DBT_INTERNAL_SOURCE.`updated_at`
    

    when not matched then insert
        (`id`, `brand`, `department`, `category`, `updated_at`)
    values
        (`id`, `brand`, `department`, `category`, `updated_at`)


    


============================== 2023-02-24 01:52:12.738734 | e12808d6-2c5d-42da-af87-85b9dbb57d92 ==============================
[0m01:52:12.738783 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:52:12.740583 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:52:12.741623 [debug] [MainThread]: Tracking: tracking
[0m01:52:12.743923 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa58c8cc50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa58c8c650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa765fdcd0>]}
[0m01:52:13.168407 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:1e4b9a2e-0bf2-42d5-8956-b8de7ace6942:US&page=queryresults
[0m01:52:13.242332 [debug] [Thread-1  ]: finished collecting timing info
[0m01:52:13.259076 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1c36bfef-4605-4989-82a7-13c5357795b2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32946c4210>]}
[0m01:52:13.265504 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.product_dimension_type_1  [[32mMERGE (0.0 rows, 2.6 MB processed)[0m in 5.16s]
[0m01:52:13.269578 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m01:52:13.360219 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:52:13.362566 [info ] [MainThread]: 
[0m01:52:13.364633 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.03 seconds (7.03s).
[0m01:52:13.366545 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:52:13.369415 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.product_dimension_type_1' was properly closed.
[0m01:52:13.370936 [info ] [MainThread]: 
[0m01:52:13.372883 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:52:13.374967 [info ] [MainThread]: 
[0m01:52:13.376667 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:52:13.378533 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32949c8290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32948b5e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f32948b5b90>]}
[0m01:52:13.380059 [debug] [MainThread]: Flushing usage events
[0m01:52:13.848769 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:52:13.850006 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:52:13.869239 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'e12808d6-2c5d-42da-af87-85b9dbb57d92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa58a7c590>]}
[0m01:52:13.878607 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'e12808d6-2c5d-42da-af87-85b9dbb57d92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa58c4fad0>]}
[0m01:52:13.880043 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:52:13.881664 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e12808d6-2c5d-42da-af87-85b9dbb57d92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa765fdcd0>]}
[0m01:52:13.885188 [info ] [MainThread]: 
[0m01:52:13.887556 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:52:13.890305 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:52:13.891471 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:52:14.803907 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:52:14.805184 [debug] [ThreadPool]: Opening a new connection, currently in state closed


============================== 2023-02-24 01:52:15.460174 | 83fd98fa-728b-457e-95a6-d493f4815552 ==============================
[0m01:52:15.460699 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:52:15.462854 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_periodic_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:52:15.464236 [debug] [MainThread]: Tracking: tracking
[0m01:52:15.467618 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4691f4c490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4691f4ca50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4691f4c590>]}
[0m01:52:15.707878 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'e12808d6-2c5d-42da-af87-85b9dbb57d92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa58baebd0>]}
[0m01:52:15.710456 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:52:15.714858 [info ] [MainThread]: 
[0m01:52:15.732098 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.test_source
[0m01:52:15.733915 [info ] [Thread-1  ]: 1 of 1 START sql view model bigquery_example_dbt.test_source ................... [RUN]
[0m01:52:15.737351 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.test_source"
[0m01:52:15.738638 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.test_source
[0m01:52:15.748786 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.test_source
[0m01:52:15.769645 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.test_source"
[0m01:52:15.803029 [debug] [Thread-1  ]: finished collecting timing info
[0m01:52:15.804370 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.test_source
[0m01:52:16.000525 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.test_source"
[0m01:52:16.026495 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:52:16.043027 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.test_source: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.test_source"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt`.`test_source`
  OPTIONS()
  as SELECT *
FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`order_items_delta`;


[0m01:52:16.517074 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:52:16.518730 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:52:16.537804 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '83fd98fa-728b-457e-95a6-d493f4815552', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4691d3d550>]}
[0m01:52:16.544610 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '83fd98fa-728b-457e-95a6-d493f4815552', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4691ec1a10>]}
[0m01:52:16.545796 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:52:16.547079 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '83fd98fa-728b-457e-95a6-d493f4815552', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4691eead10>]}
[0m01:52:16.551104 [info ] [MainThread]: 
[0m01:52:16.553913 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:52:16.556320 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:52:16.557355 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:52:17.381087 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:52:17.382301 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:52:17.687903 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:f43edb0f-d0b6-4e01-941e-08bcec90d204:US&page=queryresults
[0m01:52:17.918548 [debug] [Thread-1  ]: finished collecting timing info
[0m01:52:17.920974 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e12808d6-2c5d-42da-af87-85b9dbb57d92', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa7a48fa90>]}
[0m01:52:17.922522 [info ] [Thread-1  ]: 1 of 1 OK created sql view model bigquery_example_dbt.test_source .............. [[32mCREATE VIEW (0 processed)[0m in 2.18s]
[0m01:52:17.924431 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.test_source
[0m01:52:17.999861 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:52:18.001971 [info ] [MainThread]: 
[0m01:52:18.003547 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 4.12 seconds (4.12s).
[0m01:52:18.005135 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:52:18.006190 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.test_source' was properly closed.
[0m01:52:18.007497 [info ] [MainThread]: 
[0m01:52:18.008968 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:52:18.010687 [info ] [MainThread]: 
[0m01:52:18.012288 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:52:18.015266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa58c728d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa780e3110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7ffa58d88e90>]}
[0m01:52:18.017349 [debug] [MainThread]: Flushing usage events
[0m01:52:18.263110 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '83fd98fa-728b-457e-95a6-d493f4815552', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4691e52c90>]}
[0m01:52:18.265392 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:52:18.267071 [info ] [MainThread]: 
[0m01:52:18.279290 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m01:52:18.280912 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.sales_periodic_fact .... [RUN]
[0m01:52:18.283517 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_periodic_fact"
[0m01:52:18.284615 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m01:52:18.285796 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m01:52:18.300137 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_periodic_fact"
[0m01:52:18.325119 [debug] [Thread-1  ]: finished collecting timing info
[0m01:52:18.326455 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m01:52:18.479311 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:52:19.573631 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.sales_periodic_fact"
[0m01:52:19.621864 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.sales_periodic_fact: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_periodic_fact"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_periodic_fact` as DBT_INTERNAL_DEST
        using (
          
    







SELECT
  DATE(created_at) AS transaction_date,
  SUM(IF(returned_at IS NULL, sale_price, sale_price * -1)) AS total_sale
FROM `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact`
WHERE DATE(created_at) = DATE(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY))
GROUP BY 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and DBT_INTERNAL_DEST.transaction_date in (
              DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`transaction_date`, `total_sale`)
    values
        (`transaction_date`, `total_sale`)



  


    
[0m01:52:23.289534 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:cde397b0-f989-4306-b251-f4e63242ae7f:US&page=queryresults
[0m01:52:23.320980 [debug] [Thread-1  ]: finished collecting timing info
[0m01:52:23.322989 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '83fd98fa-728b-457e-95a6-d493f4815552', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4692044d10>]}
[0m01:52:23.324275 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.sales_periodic_fact  [[32mMERGE (0.0 rows, 0 processed)[0m in 5.04s]
[0m01:52:23.325640 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m01:52:23.421474 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:52:23.423130 [info ] [MainThread]: 
[0m01:52:23.424403 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 6.87 seconds (6.87s).
[0m01:52:23.425718 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:52:23.426591 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_periodic_fact' was properly closed.
[0m01:52:23.427984 [info ] [MainThread]: 
[0m01:52:23.429209 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:52:23.430785 [info ] [MainThread]: 
[0m01:52:23.431980 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:52:23.433435 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4691f4c2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4691c51990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4691ed0ad0>]}
[0m01:52:23.434475 [debug] [MainThread]: Flushing usage events


============================== 2023-02-24 01:52:31.077941 | f9c24fba-1333-4291-85d3-1d6e7750f2a8 ==============================
[0m01:52:31.077995 [info ] [MainThread]: Running with dbt=1.3.0
[0m01:52:31.080153 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_report'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m01:52:31.081322 [debug] [MainThread]: Tracking: tracking
[0m01:52:31.083559 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc49af35790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4a0159050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc49b002a50>]}
[0m01:52:31.961964 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m01:52:31.963135 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m01:52:31.978602 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f9c24fba-1333-4291-85d3-1d6e7750f2a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc49ad8e310>]}
[0m01:52:31.986749 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f9c24fba-1333-4291-85d3-1d6e7750f2a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc49af60c50>]}
[0m01:52:31.988378 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m01:52:31.990204 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9c24fba-1333-4291-85d3-1d6e7750f2a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc49af609d0>]}
[0m01:52:31.993272 [info ] [MainThread]: 
[0m01:52:31.995674 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:52:32.004736 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m01:52:32.005900 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m01:52:32.889547 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m01:52:32.890498 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m01:52:33.727904 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f9c24fba-1333-4291-85d3-1d6e7750f2a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc4a0159390>]}
[0m01:52:33.729669 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m01:52:33.730932 [info ] [MainThread]: 
[0m01:52:33.740469 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.sales_report
[0m01:52:33.741750 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.sales_report ........... [RUN]
[0m01:52:33.744357 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_report"
[0m01:52:33.745182 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.sales_report
[0m01:52:33.746053 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.sales_report
[0m01:52:33.758061 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_report"
[0m01:52:33.777896 [debug] [Thread-1  ]: finished collecting timing info
[0m01:52:33.779001 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.sales_report
[0m01:52:33.889957 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m01:52:34.824919 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.sales_report"
[0m01:52:34.849841 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.sales_report: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_report"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_report` as DBT_INTERNAL_DEST
        using (
          
    






WITH sales_transaction_data AS (
    SELECT *
    FROM `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact` sales_trans
    WHERE DATE(created_at) = DATE(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY))
)
SELECT DATE(created_at) AS transaction_date, category, brand, department, SUM(sale_price) AS total_sales
FROM (
 SELECT * EXCEPT(row_num)
 FROM (
   SELECT created_at, category, brand, department, sale_price,
   ROW_NUMBER() OVER(PARTITION BY sales_trans.id ORDER BY product_dim.updated_at DESC) AS row_num
   FROM sales_transaction_data sales_trans
     LEFT JOIN `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension` product_dim
       ON sales_trans.product_id = product_dim.id and sales_trans.created_at >= product_dim.updated_at
 )
 WHERE row_num = 1
)
GROUP BY transaction_date, category, brand, department
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and DBT_INTERNAL_DEST.transaction_date in (
              DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`transaction_date`, `category`, `brand`, `department`, `total_sales`)
    values
        (`transaction_date`, `category`, `brand`, `department`, `total_sales`)



  


    
[0m01:52:38.848407 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:2d17df08-cb28-4860-aa4f-853cdb7627b4:US&page=queryresults
[0m01:52:38.922679 [debug] [Thread-1  ]: finished collecting timing info
[0m01:52:38.925384 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f9c24fba-1333-4291-85d3-1d6e7750f2a8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc49a3b6bd0>]}
[0m01:52:38.927308 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.sales_report ...... [[32mMERGE (0.0 rows, 0 processed)[0m in 5.18s]
[0m01:52:38.933705 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.sales_report
[0m01:52:39.025090 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m01:52:39.027316 [info ] [MainThread]: 
[0m01:52:39.028725 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 7.03 seconds (7.03s).
[0m01:52:39.030098 [debug] [MainThread]: Connection 'master' was properly closed.
[0m01:52:39.031275 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_report' was properly closed.
[0m01:52:39.032464 [info ] [MainThread]: 
[0m01:52:39.033688 [info ] [MainThread]: [32mCompleted successfully[0m
[0m01:52:39.035360 [info ] [MainThread]: 
[0m01:52:39.036696 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m01:52:39.038258 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc49b094e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc49a3c7410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fc49a3c7d90>]}
[0m01:52:39.039500 [debug] [MainThread]: Flushing usage events


============================== 2023-02-24 02:00:16.918237 | 48b8db7d-0e08-4e70-b857-ab9edf7c9995 ==============================
[0m02:00:16.918294 [info ] [MainThread]: Running with dbt=1.3.0


============================== 2023-02-24 02:00:16.918867 | 09b027c6-6381-4cc6-bc64-fd6171686907 ==============================
[0m02:00:16.918917 [info ] [MainThread]: Running with dbt=1.3.0
[0m02:00:16.921833 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension_type_1'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m02:00:16.922393 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['test_source'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m02:00:16.923126 [debug] [MainThread]: Tracking: tracking
[0m02:00:16.923582 [debug] [MainThread]: Tracking: tracking
[0m02:00:16.928178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c8b97f810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c8b951910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c8b951850>]}
[0m02:00:16.928199 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c89930d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c89930550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c899308d0>]}
[0m02:00:18.597263 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:00:18.599385 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:00:18.599220 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:00:18.601617 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:00:18.628267 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '09b027c6-6381-4cc6-bc64-fd6171686907', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c8b730550>]}
[0m02:00:18.630363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '48b8db7d-0e08-4e70-b857-ab9edf7c9995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c89723550>]}
[0m02:00:18.638709 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '09b027c6-6381-4cc6-bc64-fd6171686907', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c8b922bd0>]}
[0m02:00:18.642424 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m02:00:18.643674 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '48b8db7d-0e08-4e70-b857-ab9edf7c9995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c898bda50>]}
[0m02:00:18.645083 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m02:00:18.645164 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '09b027c6-6381-4cc6-bc64-fd6171686907', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c8b97f810>]}
[0m02:00:18.647363 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48b8db7d-0e08-4e70-b857-ab9edf7c9995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c898f4d10>]}
[0m02:00:18.649175 [info ] [MainThread]: 
[0m02:00:18.650967 [info ] [MainThread]: 
[0m02:00:18.655099 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:00:18.654446 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:00:18.658602 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m02:00:18.660528 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:00:18.666935 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m02:00:18.669210 [debug] [ThreadPool]: Opening a new connection, currently in state init


============================== 2023-02-24 02:00:19.745924 | 771dd5f0-8962-4557-a6f7-921696366c9e ==============================
[0m02:00:19.745972 [info ] [MainThread]: Running with dbt=1.3.0
[0m02:00:19.748008 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_transaction_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m02:00:19.749793 [debug] [MainThread]: Tracking: tracking
[0m02:00:19.752391 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1d7ded90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1d805bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a1d8054d0>]}
[0m02:00:19.847351 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m02:00:19.849308 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:00:20.116077 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m02:00:20.117861 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:00:20.664185 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '48b8db7d-0e08-4e70-b857-ab9edf7c9995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c898a66d0>]}
[0m02:00:20.666784 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m02:00:20.669599 [info ] [MainThread]: 
[0m02:00:20.688360 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m02:00:20.689856 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.product_dimension_type_1  [RUN]
[0m02:00:20.692417 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.product_dimension_type_1"
[0m02:00:20.693625 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m02:00:20.696578 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m02:00:20.747572 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.product_dimension_type_1"
[0m02:00:20.780943 [debug] [Thread-1  ]: finished collecting timing info
[0m02:00:20.783546 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m02:00:20.943226 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '09b027c6-6381-4cc6-bc64-fd6171686907', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c8b942950>]}
[0m02:00:20.955341 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m02:00:20.957285 [info ] [MainThread]: 
[0m02:00:20.992950 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.test_source
[0m02:00:20.996213 [info ] [Thread-1  ]: 1 of 1 START sql view model bigquery_example_dbt.test_source ................... [RUN]
[0m02:00:20.999756 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.test_source"
[0m02:00:20.999379 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m02:00:21.001816 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.test_source
[0m02:00:21.003507 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.test_source
[0m02:00:21.015649 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.test_source"
[0m02:00:21.075845 [debug] [Thread-1  ]: finished collecting timing info
[0m02:00:21.079101 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.test_source
[0m02:00:21.161582 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:00:21.163519 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:00:21.190408 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '771dd5f0-8962-4557-a6f7-921696366c9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f5a0209df50>]}
[0m02:00:21.211563 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '771dd5f0-8962-4557-a6f7-921696366c9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59fbe24f50>]}
[0m02:00:21.213721 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m02:00:21.216201 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '771dd5f0-8962-4557-a6f7-921696366c9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59fbe05790>]}
[0m02:00:21.220952 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.test_source"
[0m02:00:21.222491 [info ] [MainThread]: 
[0m02:00:21.225244 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:00:21.229430 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m02:00:21.230979 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:00:21.248271 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m02:00:21.272056 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.test_source: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.test_source"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt`.`test_source`
  OPTIONS()
  as SELECT *
FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`order_items_delta`;


[0m02:00:21.942571 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.product_dimension_type_1"
[0m02:00:21.965845 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.product_dimension_type_1: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.product_dimension_type_1"} */

        
            
                
                
            
        
    

    

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension_type_1` as DBT_INTERNAL_DEST
        using (
          

SELECT id, brand, department, category, updated_at
FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`products_main`
WHERE

    DATE(updated_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))

        ) as DBT_INTERNAL_SOURCE
        on 
                    DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
                

    
    when matched then update set
        `id` = DBT_INTERNAL_SOURCE.`id`,`brand` = DBT_INTERNAL_SOURCE.`brand`,`department` = DBT_INTERNAL_SOURCE.`department`,`category` = DBT_INTERNAL_SOURCE.`category`,`updated_at` = DBT_INTERNAL_SOURCE.`updated_at`
    

    when not matched then insert
        (`id`, `brand`, `department`, `category`, `updated_at`)
    values
        (`id`, `brand`, `department`, `category`, `updated_at`)


    
[0m02:00:22.045781 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m02:00:22.046841 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:00:22.753266 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '771dd5f0-8962-4557-a6f7-921696366c9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59fbdf5b10>]}
[0m02:00:22.755707 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m02:00:22.757464 [info ] [MainThread]: 
[0m02:00:22.773409 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m02:00:22.774902 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.sales_transaction_fact . [RUN]
[0m02:00:22.777016 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_transaction_fact"
[0m02:00:22.777946 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m02:00:22.779144 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m02:00:22.791379 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_transaction_fact"
[0m02:00:22.816924 [debug] [Thread-1  ]: finished collecting timing info
[0m02:00:22.817779 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m02:00:22.852603 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:72fcda8d-d69e-49b5-b54e-c530d4686c0b:US&page=queryresults
[0m02:00:22.901332 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m02:00:22.996430 [debug] [Thread-1  ]: finished collecting timing info
[0m02:00:22.998425 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '09b027c6-6381-4cc6-bc64-fd6171686907', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c8bd3e990>]}
[0m02:00:23.000063 [info ] [Thread-1  ]: 1 of 1 OK created sql view model bigquery_example_dbt.test_source .............. [[32mCREATE VIEW (0 processed)[0m in 2.00s]
[0m02:00:23.002020 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.test_source
[0m02:00:23.081087 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:00:23.082729 [info ] [MainThread]: 
[0m02:00:23.084247 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 4.43 seconds (4.43s).
[0m02:00:23.085578 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:00:23.086595 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.test_source' was properly closed.
[0m02:00:23.088107 [info ] [MainThread]: 
[0m02:00:23.089362 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:00:23.090829 [info ] [MainThread]: 
[0m02:00:23.092362 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:00:23.094029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c8ba75dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c8bbe67d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f7c8bbe6910>]}
[0m02:00:23.095206 [debug] [MainThread]: Flushing usage events
[0m02:00:23.807643 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.sales_transaction_fact"
[0m02:00:23.829363 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.sales_transaction_fact: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_transaction_fact"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact` as DBT_INTERNAL_DEST
        using (
          
    






SELECT
    id,
    order_id,
    user_id,
    product_id,
    inventory_item_id,
    status,
    created_at,
    shipped_at,
    delivered_at,
    returned_at,
    sale_price
FROM (
    SELECT *, ROW_NUMBER() OVER(PARTITION BY id ORDER BY created_at DESC) AS row_num
    FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`order_items_delta`
    WHERE DATE(created_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))
)
WHERE row_num = 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and TIMESTAMP_trunc(DBT_INTERNAL_DEST.created_at, DAY) in (
              TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`id`, `order_id`, `user_id`, `product_id`, `inventory_item_id`, `status`, `created_at`, `shipped_at`, `delivered_at`, `returned_at`, `sale_price`)
    values
        (`id`, `order_id`, `user_id`, `product_id`, `inventory_item_id`, `status`, `created_at`, `shipped_at`, `delivered_at`, `returned_at`, `sale_price`)



  


    
[0m02:00:26.748184 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:a6a22481-0b81-4587-a122-941e10cf6596:US&page=queryresults
[0m02:00:26.779098 [debug] [Thread-1  ]: finished collecting timing info
[0m02:00:26.781023 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '48b8db7d-0e08-4e70-b857-ab9edf7c9995', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c895bf390>]}
[0m02:00:26.782365 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.product_dimension_type_1  [[32mMERGE (0.0 rows, 2.6 MB processed)[0m in 6.09s]
[0m02:00:26.784345 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.product_dimension_type_1
[0m02:00:26.825239 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:00:26.827112 [info ] [MainThread]: 
[0m02:00:26.828298 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 8.17 seconds (8.17s).
[0m02:00:26.829331 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:00:26.830144 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m02:00:26.831141 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.product_dimension_type_1' was properly closed.
[0m02:00:26.832258 [info ] [MainThread]: 
[0m02:00:26.833268 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:00:26.834284 [info ] [MainThread]: 
[0m02:00:26.835191 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:00:26.836380 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c8991ae90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c89930950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f4c899300d0>]}
[0m02:00:26.837487 [debug] [MainThread]: Flushing usage events
[0m02:00:28.067808 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:81f107d8-85ab-4e7a-8101-f3d9cd557736:US&page=queryresults
[0m02:00:28.098179 [debug] [Thread-1  ]: finished collecting timing info
[0m02:00:28.099850 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '771dd5f0-8962-4557-a6f7-921696366c9e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59fbda2d10>]}
[0m02:00:28.101211 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.sales_transaction_fact  [[32mMERGE (0.0 rows, 0 processed)[0m in 5.32s]
[0m02:00:28.102958 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.sales_transaction_fact
[0m02:00:28.199880 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:00:28.201649 [info ] [MainThread]: 
[0m02:00:28.202916 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 6.98 seconds (6.98s).
[0m02:00:28.204197 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:00:28.205180 [debug] [MainThread]: Connection 'list_data-analytics-engineer' was properly closed.
[0m02:00:28.206178 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_transaction_fact' was properly closed.
[0m02:00:28.207294 [info ] [MainThread]: 
[0m02:00:28.208592 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:00:28.210169 [info ] [MainThread]: 
[0m02:00:28.211472 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:00:28.212853 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59fbdf5f90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59fbafe510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f59fbafe5d0>]}
[0m02:00:28.214578 [debug] [MainThread]: Flushing usage events


============================== 2023-02-24 02:00:36.589425 | 04a8652e-fe4c-49c4-b7aa-89fae0609536 ==============================
[0m02:00:36.589469 [info ] [MainThread]: Running with dbt=1.3.0
[0m02:00:36.591401 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_first_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m02:00:36.592372 [debug] [MainThread]: Tracking: tracking
[0m02:00:36.594713 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd2474550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd2474b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcefe25cd0>]}
[0m02:00:37.589046 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:00:37.590235 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:00:37.603436 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '04a8652e-fe4c-49c4-b7aa-89fae0609536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd2265550>]}
[0m02:00:37.611045 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '04a8652e-fe4c-49c4-b7aa-89fae0609536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd23eb810>]}
[0m02:00:37.612418 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m02:00:37.613794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04a8652e-fe4c-49c4-b7aa-89fae0609536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcefe25cd0>]}
[0m02:00:37.616486 [info ] [MainThread]: 
[0m02:00:37.618434 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:00:37.620325 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m02:00:37.621222 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:00:38.471432 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m02:00:38.472619 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:00:39.234063 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '04a8652e-fe4c-49c4-b7aa-89fae0609536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd464b350>]}
[0m02:00:39.236247 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m02:00:39.237615 [info ] [MainThread]: 
[0m02:00:39.305724 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m02:00:39.317097 [info ] [Thread-1  ]: 1 of 1 START sql table model bigquery_example_dbt.my_first_dbt_model ........... [RUN]
[0m02:00:39.320036 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_first_dbt_model"
[0m02:00:39.321582 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m02:00:39.323159 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m02:00:39.334016 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
[0m02:00:39.375984 [debug] [Thread-1  ]: finished collecting timing info
[0m02:00:39.379544 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m02:00:39.445449 [debug] [Thread-1  ]: Opening a new connection, currently in state init
[0m02:00:40.305639 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.my_first_dbt_model"
[0m02:00:40.333224 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_first_dbt_model"} */

  
    

    create or replace table `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
    
    
    OPTIONS()
    as (
      /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
    );
  


============================== 2023-02-24 02:00:41.497930 | 47728766-3891-47e4-af13-8ae528092a87 ==============================
[0m02:00:41.497958 [info ] [MainThread]: Running with dbt=1.3.0
[0m02:00:41.499655 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['product_dimension'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m02:00:41.500650 [debug] [MainThread]: Tracking: tracking
[0m02:00:41.502288 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec539fcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec539ff90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec5404cd0>]}
[0m02:00:42.452681 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:00:42.453996 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:00:42.463353 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '47728766-3891-47e4-af13-8ae528092a87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec51902d0>]}
[0m02:00:42.470447 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '47728766-3891-47e4-af13-8ae528092a87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec5315f50>]}
[0m02:00:42.471604 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m02:00:42.473142 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47728766-3891-47e4-af13-8ae528092a87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faee2d09c90>]}
[0m02:00:42.475734 [info ] [MainThread]: 
[0m02:00:42.477236 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:00:42.479283 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m02:00:42.480144 [debug] [ThreadPool]: Opening a new connection, currently in state init


============================== 2023-02-24 02:00:43.154117 | f3600d59-385a-4990-baff-c49bf9db9c3d ==============================
[0m02:00:43.154146 [info ] [MainThread]: Running with dbt=1.3.0
[0m02:00:43.155944 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_periodic_fact'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m02:00:43.157013 [debug] [MainThread]: Tracking: tracking
[0m02:00:43.159035 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67aacae650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67aacae4d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67aacaeb10>]}
[0m02:00:43.290684 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m02:00:43.292280 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:00:43.540860 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:bc02f350-a844-493d-9ae0-b0c8e03e4cde:US&page=queryresults
[0m02:00:43.639998 [debug] [Thread-1  ]: finished collecting timing info
[0m02:00:43.641612 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '04a8652e-fe4c-49c4-b7aa-89fae0609536', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcefc62b10>]}
[0m02:00:43.642903 [info ] [Thread-1  ]: 1 of 1 OK created sql table model bigquery_example_dbt.my_first_dbt_model ...... [[32mCREATE TABLE (2.0 rows, 0 processed)[0m in 4.32s]
[0m02:00:43.650720 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.my_first_dbt_model
[0m02:00:43.735233 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:00:43.738105 [info ] [MainThread]: 
[0m02:00:43.739466 [info ] [MainThread]: Finished running 1 table model in 0 hours 0 minutes and 6.12 seconds (6.12s).
[0m02:00:43.740723 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:00:43.741748 [debug] [MainThread]: Connection 'list_data-analytics-engineer_bigquery_example_dbt' was properly closed.
[0m02:00:43.742670 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_first_dbt_model' was properly closed.
[0m02:00:43.743555 [info ] [MainThread]: 
[0m02:00:43.744640 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:00:43.745880 [info ] [MainThread]: 
[0m02:00:43.746997 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:00:43.748297 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd2570110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd256c5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7efcd256ced0>]}
[0m02:00:43.749546 [debug] [MainThread]: Flushing usage events
[0m02:00:44.029028 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '47728766-3891-47e4-af13-8ae528092a87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec52c3210>]}
[0m02:00:44.034481 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m02:00:44.037720 [info ] [MainThread]: 
[0m02:00:44.057817 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.product_dimension
[0m02:00:44.059844 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.product_dimension ...... [RUN]
[0m02:00:44.063128 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.product_dimension"
[0m02:00:44.064716 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.product_dimension
[0m02:00:44.066384 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.product_dimension
[0m02:00:44.088128 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.product_dimension"
[0m02:00:44.114897 [debug] [Thread-1  ]: finished collecting timing info
[0m02:00:44.115980 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.product_dimension
[0m02:00:44.187911 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:00:44.190457 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:00:44.195259 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m02:00:44.203513 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'f3600d59-385a-4990-baff-c49bf9db9c3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67b011e490>]}
[0m02:00:44.216857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'f3600d59-385a-4990-baff-c49bf9db9c3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67aac238d0>]}
[0m02:00:44.217888 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m02:00:44.219178 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f3600d59-385a-4990-baff-c49bf9db9c3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67ab2886d0>]}
[0m02:00:44.222131 [info ] [MainThread]: 
[0m02:00:44.223862 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:00:44.227054 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m02:00:44.228162 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:00:44.977657 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m02:00:44.978708 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:00:45.034821 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.product_dimension"
[0m02:00:45.053868 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.product_dimension: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.product_dimension"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension` as DBT_INTERNAL_DEST
        using (
          
    






SELECT id, brand, department, category, updated_at
FROM (
    SELECT id, brand, department, category, updated_at,
        ROW_NUMBER() OVER(PARTITION BY id ORDER BY updated_at DESC) AS row_num
    FROM `data-analytics-engineer`.`bigquery_change_data_capture_example`.`products_delta`
    WHERE DATE(updated_at) = DATE(TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY))
)
WHERE row_num = 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and TIMESTAMP_trunc(DBT_INTERNAL_DEST.updated_at, DAY) in (
              TIMESTAMP_SUB(TIMESTAMP(CURRENT_DATE()), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`id`, `brand`, `department`, `category`, `updated_at`)
    values
        (`id`, `brand`, `department`, `category`, `updated_at`)



  


    
[0m02:00:45.744558 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'f3600d59-385a-4990-baff-c49bf9db9c3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67ccda3650>]}
[0m02:00:45.746227 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m02:00:45.747439 [info ] [MainThread]: 
[0m02:00:45.757960 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m02:00:45.759287 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.sales_periodic_fact .... [RUN]
[0m02:00:45.761375 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_periodic_fact"
[0m02:00:45.762227 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m02:00:45.763102 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m02:00:45.773244 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_periodic_fact"
[0m02:00:45.795606 [debug] [Thread-1  ]: finished collecting timing info
[0m02:00:45.796696 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m02:00:45.888936 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m02:00:46.885786 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.sales_periodic_fact"
[0m02:00:46.908817 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.sales_periodic_fact: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_periodic_fact"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_periodic_fact` as DBT_INTERNAL_DEST
        using (
          
    







SELECT
  DATE(created_at) AS transaction_date,
  SUM(IF(returned_at IS NULL, sale_price, sale_price * -1)) AS total_sale
FROM `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact`
WHERE DATE(created_at) = DATE(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY))
GROUP BY 1
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and DBT_INTERNAL_DEST.transaction_date in (
              DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`transaction_date`, `total_sale`)
    values
        (`transaction_date`, `total_sale`)



  


    
[0m02:00:48.554703 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:b1a83d8f-7899-45ce-baa2-904a28974ae0:US&page=queryresults
[0m02:00:48.587303 [debug] [Thread-1  ]: finished collecting timing info
[0m02:00:48.589410 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '47728766-3891-47e4-af13-8ae528092a87', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec539f610>]}
[0m02:00:48.591072 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.product_dimension . [[32mMERGE (0.0 rows, 44.0 Bytes processed)[0m in 4.53s]
[0m02:00:48.592980 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.product_dimension
[0m02:00:48.600758 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:00:48.602419 [info ] [MainThread]: 
[0m02:00:48.603795 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 6.13 seconds (6.13s).
[0m02:00:48.605117 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:00:48.606178 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.product_dimension' was properly closed.
[0m02:00:48.607059 [info ] [MainThread]: 
[0m02:00:48.608405 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:00:48.609924 [info ] [MainThread]: 
[0m02:00:48.611442 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:00:48.613225 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec5195d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec5195910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7faec5195090>]}
[0m02:00:48.614407 [debug] [MainThread]: Flushing usage events
[0m02:00:50.603013 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:e87e9903-53b2-43c7-a316-d9d30d87f8cd:US&page=queryresults
[0m02:00:50.639089 [debug] [Thread-1  ]: finished collecting timing info
[0m02:00:50.641080 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f3600d59-385a-4990-baff-c49bf9db9c3d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67aac8ced0>]}
[0m02:00:50.642273 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.sales_periodic_fact  [[32mMERGE (0.0 rows, 0 processed)[0m in 4.88s]
[0m02:00:50.643668 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.sales_periodic_fact
[0m02:00:50.654592 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:00:50.656388 [info ] [MainThread]: 
[0m02:00:50.657685 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 6.43 seconds (6.43s).
[0m02:00:50.658922 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:00:50.659793 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_periodic_fact' was properly closed.
[0m02:00:50.660969 [info ] [MainThread]: 
[0m02:00:50.662211 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:00:50.663608 [info ] [MainThread]: 
[0m02:00:50.664815 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:00:50.666120 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67aa0e7990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67aa082a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f67aa0825d0>]}
[0m02:00:50.667269 [debug] [MainThread]: Flushing usage events


============================== 2023-02-24 02:01:00.696060 | 5fac5941-01b9-4720-b883-33034ccaed9d ==============================
[0m02:01:00.696108 [info ] [MainThread]: Running with dbt=1.3.0
[0m02:01:00.698422 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['my_second_dbt_model'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m02:01:00.700514 [debug] [MainThread]: Tracking: tracking
[0m02:01:00.703620 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9f73c790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9f73c850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9f807b10>]}
[0m02:01:01.963807 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:01:01.965227 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:01:01.990841 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '5fac5941-01b9-4720-b883-33034ccaed9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9f594110>]}
[0m02:01:01.999663 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '5fac5941-01b9-4720-b883-33034ccaed9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9f748e10>]}
[0m02:01:02.001408 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m02:01:02.003794 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5fac5941-01b9-4720-b883-33034ccaed9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3dc111db90>]}
[0m02:01:02.008314 [info ] [MainThread]: 
[0m02:01:02.011120 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:01:02.014568 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m02:01:02.016085 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:01:02.924040 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m02:01:02.926331 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:01:03.701839 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '5fac5941-01b9-4720-b883-33034ccaed9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9f6b7fd0>]}
[0m02:01:03.703524 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m02:01:03.704737 [info ] [MainThread]: 
[0m02:01:03.714524 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m02:01:03.716120 [info ] [Thread-1  ]: 1 of 1 START sql view model bigquery_example_dbt.my_second_dbt_model ........... [RUN]
[0m02:01:03.719407 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.my_second_dbt_model"
[0m02:01:03.720340 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m02:01:03.721481 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m02:01:03.727673 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
[0m02:01:03.749405 [debug] [Thread-1  ]: finished collecting timing info
[0m02:01:03.750372 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m02:01:03.837071 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.my_second_dbt_model"
[0m02:01:03.858288 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m02:01:03.877445 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.my_second_dbt_model"} */


  create or replace view `data-analytics-engineer`.`bigquery_example_dbt`.`my_second_dbt_model`
  OPTIONS()
  as -- Use the `ref` function to select from other models

select *
from `data-analytics-engineer`.`bigquery_example_dbt`.`my_first_dbt_model`
where id = 1;


[0m02:01:05.870395 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:43534767-9013-46d6-bc16-427a14431d94:US&page=queryresults
[0m02:01:06.213201 [debug] [Thread-1  ]: finished collecting timing info
[0m02:01:06.215600 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5fac5941-01b9-4720-b883-33034ccaed9d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9eb94450>]}
[0m02:01:06.217218 [info ] [Thread-1  ]: 1 of 1 OK created sql view model bigquery_example_dbt.my_second_dbt_model ...... [[32mCREATE VIEW (0 processed)[0m in 2.50s]
[0m02:01:06.219118 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.my_second_dbt_model
[0m02:01:06.290453 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:01:06.292303 [info ] [MainThread]: 
[0m02:01:06.293599 [info ] [MainThread]: Finished running 1 view model in 0 hours 0 minutes and 4.28 seconds (4.28s).
[0m02:01:06.301700 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:01:06.310147 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.my_second_dbt_model' was properly closed.
[0m02:01:06.311400 [info ] [MainThread]: 
[0m02:01:06.314693 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:01:06.317364 [info ] [MainThread]: 
[0m02:01:06.323484 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:01:06.326383 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9eb94cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9eb8de50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7f3d9eb8d450>]}
[0m02:01:06.327645 [debug] [MainThread]: Flushing usage events


============================== 2023-02-24 02:01:07.595696 | ca6d3789-1313-44ab-a3e2-9350de683020 ==============================
[0m02:01:07.595746 [info ] [MainThread]: Running with dbt=1.3.0
[0m02:01:07.597708 [debug] [MainThread]: running dbt with arguments {'write_json': False, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/opt/airflow/dags/dbt_modules', 'send_anonymous_usage_stats': True, 'event_buffer_size': 100000, 'quiet': False, 'no_print': False, 'project_dir': '/opt/airflow/dags/dbt_modules/data_warehouse_analytics_engineer', 'target': 'dev', 'select': ['sales_report'], 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m02:01:07.599160 [debug] [MainThread]: Tracking: tracking
[0m02:01:07.602033 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb89f2fd2d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb89f2fd7d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8819edbd0>]}
[0m02:01:08.941848 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m02:01:08.943106 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m02:01:08.957578 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'ca6d3789-1313-44ab-a3e2-9350de683020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb88177a590>]}
[0m02:01:08.964357 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'ca6d3789-1313-44ab-a3e2-9350de683020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb8818fe510>]}
[0m02:01:08.965553 [info ] [MainThread]: Found 8 models, 4 tests, 0 snapshots, 0 analyses, 319 macros, 0 operations, 1 seed file, 3 sources, 0 exposures, 0 metrics
[0m02:01:08.966760 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ca6d3789-1313-44ab-a3e2-9350de683020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb88194cd90>]}
[0m02:01:08.969197 [info ] [MainThread]: 
[0m02:01:08.971160 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:01:08.973253 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer"
[0m02:01:08.974282 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m02:01:09.856114 [debug] [ThreadPool]: Acquiring new bigquery connection "list_data-analytics-engineer_bigquery_example_dbt"
[0m02:01:09.857403 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m02:01:10.671676 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'ca6d3789-1313-44ab-a3e2-9350de683020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb883b61910>]}
[0m02:01:10.673562 [info ] [MainThread]: Concurrency: 1 threads (target='dev')
[0m02:01:10.675357 [info ] [MainThread]: 
[0m02:01:10.684956 [debug] [Thread-1  ]: Began running node model.data_warehouse_analytics_engineer.sales_report
[0m02:01:10.686655 [info ] [Thread-1  ]: 1 of 1 START sql incremental model bigquery_example_dbt.sales_report ........... [RUN]
[0m02:01:10.688854 [debug] [Thread-1  ]: Acquiring new bigquery connection "model.data_warehouse_analytics_engineer.sales_report"
[0m02:01:10.689974 [debug] [Thread-1  ]: Began compiling node model.data_warehouse_analytics_engineer.sales_report
[0m02:01:10.691153 [debug] [Thread-1  ]: Compiling model.data_warehouse_analytics_engineer.sales_report
[0m02:01:10.700464 [debug] [Thread-1  ]: Writing injected SQL for node "model.data_warehouse_analytics_engineer.sales_report"
[0m02:01:10.724598 [debug] [Thread-1  ]: finished collecting timing info
[0m02:01:10.725689 [debug] [Thread-1  ]: Began executing node model.data_warehouse_analytics_engineer.sales_report
[0m02:01:10.810361 [debug] [Thread-1  ]: Opening a new connection, currently in state closed
[0m02:01:11.682721 [debug] [Thread-1  ]: Writing runtime sql for node "model.data_warehouse_analytics_engineer.sales_report"
[0m02:01:11.713816 [debug] [Thread-1  ]: On model.data_warehouse_analytics_engineer.sales_report: /* {"app": "dbt", "dbt_version": "1.3.0", "profile_name": "data_warehouse_analytics_engineer", "target_name": "dev", "node_id": "model.data_warehouse_analytics_engineer.sales_report"} */


   

      
      

    merge into `data-analytics-engineer`.`bigquery_example_dbt`.`sales_report` as DBT_INTERNAL_DEST
        using (
          
    






WITH sales_transaction_data AS (
    SELECT *
    FROM `data-analytics-engineer`.`bigquery_example_dbt`.`sales_transaction_fact` sales_trans
    WHERE DATE(created_at) = DATE(DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY))
)
SELECT DATE(created_at) AS transaction_date, category, brand, department, SUM(sale_price) AS total_sales
FROM (
 SELECT * EXCEPT(row_num)
 FROM (
   SELECT created_at, category, brand, department, sale_price,
   ROW_NUMBER() OVER(PARTITION BY sales_trans.id ORDER BY product_dim.updated_at DESC) AS row_num
   FROM sales_transaction_data sales_trans
     LEFT JOIN `data-analytics-engineer`.`bigquery_example_dbt`.`product_dimension` product_dim
       ON sales_trans.product_id = product_dim.id and sales_trans.created_at >= product_dim.updated_at
 )
 WHERE row_num = 1
)
GROUP BY transaction_date, category, brand, department
        ) as DBT_INTERNAL_SOURCE
        on FALSE

    when not matched by source
         and DBT_INTERNAL_DEST.transaction_date in (
              DATE_SUB(CURRENT_DATE(), INTERVAL 1 DAY)
          ) 
        then delete

    when not matched then insert
        (`transaction_date`, `category`, `brand`, `department`, `total_sales`)
    values
        (`transaction_date`, `category`, `brand`, `department`, `total_sales`)



  


    
[0m02:01:15.703953 [debug] [Thread-1  ]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=data-analytics-engineer&j=bq:980c94be-7b16-40f0-aa81-205166e4b0a7:US&page=queryresults
[0m02:01:15.740743 [debug] [Thread-1  ]: finished collecting timing info
[0m02:01:15.742906 [debug] [Thread-1  ]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ca6d3789-1313-44ab-a3e2-9350de683020', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb89f3348d0>]}
[0m02:01:15.744268 [info ] [Thread-1  ]: 1 of 1 OK created sql incremental model bigquery_example_dbt.sales_report ...... [[32mMERGE (0.0 rows, 0 processed)[0m in 5.05s]
[0m02:01:15.745777 [debug] [Thread-1  ]: Finished running node model.data_warehouse_analytics_engineer.sales_report
[0m02:01:15.772180 [debug] [MainThread]: Acquiring new bigquery connection "master"
[0m02:01:15.774012 [info ] [MainThread]: 
[0m02:01:15.776057 [info ] [MainThread]: Finished running 1 incremental model in 0 hours 0 minutes and 6.80 seconds (6.80s).
[0m02:01:15.777884 [debug] [MainThread]: Connection 'master' was properly closed.
[0m02:01:15.779101 [debug] [MainThread]: Connection 'model.data_warehouse_analytics_engineer.sales_report' was properly closed.
[0m02:01:15.780118 [info ] [MainThread]: 
[0m02:01:15.781649 [info ] [MainThread]: [32mCompleted successfully[0m
[0m02:01:15.783126 [info ] [MainThread]: 
[0m02:01:15.785235 [info ] [MainThread]: Done. PASS=1 WARN=0 ERROR=0 SKIP=0 TOTAL=1
[0m02:01:15.786992 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb881927190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb880daeb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x7fb880dae0d0>]}
[0m02:01:15.788192 [debug] [MainThread]: Flushing usage events
